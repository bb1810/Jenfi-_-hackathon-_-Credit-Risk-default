{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8a9a592",
   "metadata": {},
   "source": [
    "#####  Name      : BHARATH BOMMEESHWAR K  \n",
    "#####  Roll_no  : D22012\n",
    "#####  Date       : 07-04-2023\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfaaaeb",
   "metadata": {},
   "source": [
    "# <div style=\"color:white;display:fill;border-radius:10px;background-color:#8ABEB9;overflow:hidden\"><p style=\"padding:20px;color:WHITE;overflow:hidden;font-size:75%;margin:0;text-align:CENTER\">JENFI HACKATHON</p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15320ac",
   "metadata": {},
   "source": [
    "### 1. IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2033,
   "id": "9cf60e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas helps in analyzing,cleaning,exploring and manipulating tabular dataset\n",
    "import pandas as pd\n",
    "\n",
    "# numpy helps to make wide varieties of mathematical computations in arrays\n",
    "import numpy as np\n",
    "\n",
    "# importing matplot library to plot interactive visualization graph\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to hide harmless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# time module helps to work with time computation related jobs\n",
    "import time\n",
    "\n",
    "# Resampling techiniques helps to adjust class imbalanceness in dataset \n",
    "from imblearn import under_sampling, over_sampling\n",
    "\n",
    "# SMOTE - synthetic minorty oversampling technique helps to oversample the minority class\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Collection_counter helps to count the frequency of elements \n",
    "from collections import Counter\n",
    "\n",
    "# Sklearn library contains various modules for machines learning and data preprocessing \n",
    "# StandardScaler helps to rescale the distribution\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Minmax scaler helps to normalizes the values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# importing Knn imputer to fill the missing data in the dataset\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# importing Logistic regression algorithm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# importing Knn Classifier algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# importing decision tree Classifier algorithm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# importing random forest Classifier algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# importing adaboost classifier algorithm\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# importing gradient boosting Classifier algorithm\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# importing Linear discriminant analysis classifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# import XGboost classifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# import Bagging model\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#Support vector machines\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "# importing Voting Classifier to ensemble multiple models\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# importing pipeline to assembly various steps together\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# importing Grid searchCV for identfying the model's best hyperparameters by different combinations of parameter search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# importing Kfold cross validation to validate the model performance\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# to get the cross validation scores\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# import Scoring metric like f1_score,auroc,recall,Classification Report\n",
    "import sklearn.metrics as mat\n",
    "from sklearn.metrics import f1_score,classification_report,roc_auc_score,accuracy_score,recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04a5900",
   "metadata": {},
   "source": [
    "### 2. PRELIMINARY ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2034,
   "id": "b8f019d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting to display number of rows and columns in notebook\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2035,
   "id": "6c147bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing training data\n",
    "raw_data = pd.read_csv(\"Training_data_Jenfi_assessment_070423.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2036,
   "id": "9093f027",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>M5</th>\n",
       "      <th>M6</th>\n",
       "      <th>M7</th>\n",
       "      <th>M8</th>\n",
       "      <th>M9</th>\n",
       "      <th>M10</th>\n",
       "      <th>M11</th>\n",
       "      <th>M12</th>\n",
       "      <th>M13</th>\n",
       "      <th>M14</th>\n",
       "      <th>M15</th>\n",
       "      <th>M16</th>\n",
       "      <th>M17</th>\n",
       "      <th>M18</th>\n",
       "      <th>M19</th>\n",
       "      <th>M20</th>\n",
       "      <th>M21</th>\n",
       "      <th>M22</th>\n",
       "      <th>M23</th>\n",
       "      <th>M24</th>\n",
       "      <th>M25</th>\n",
       "      <th>M26</th>\n",
       "      <th>M27</th>\n",
       "      <th>M28</th>\n",
       "      <th>M29</th>\n",
       "      <th>M30</th>\n",
       "      <th>M31</th>\n",
       "      <th>M32</th>\n",
       "      <th>M33</th>\n",
       "      <th>M34</th>\n",
       "      <th>M35</th>\n",
       "      <th>M36</th>\n",
       "      <th>M37</th>\n",
       "      <th>M38</th>\n",
       "      <th>M39</th>\n",
       "      <th>M40</th>\n",
       "      <th>M41</th>\n",
       "      <th>M42</th>\n",
       "      <th>M43</th>\n",
       "      <th>M44</th>\n",
       "      <th>M45</th>\n",
       "      <th>M46</th>\n",
       "      <th>M47</th>\n",
       "      <th>M48</th>\n",
       "      <th>M49</th>\n",
       "      <th>M50</th>\n",
       "      <th>M51</th>\n",
       "      <th>M52</th>\n",
       "      <th>M53</th>\n",
       "      <th>M54</th>\n",
       "      <th>M55</th>\n",
       "      <th>M56</th>\n",
       "      <th>M57</th>\n",
       "      <th>M58</th>\n",
       "      <th>M59</th>\n",
       "      <th>M60</th>\n",
       "      <th>M61</th>\n",
       "      <th>M62</th>\n",
       "      <th>M63</th>\n",
       "      <th>M64</th>\n",
       "      <th>M65</th>\n",
       "      <th>M66</th>\n",
       "      <th>M67</th>\n",
       "      <th>M68</th>\n",
       "      <th>M69</th>\n",
       "      <th>M70</th>\n",
       "      <th>M71</th>\n",
       "      <th>M72</th>\n",
       "      <th>M73</th>\n",
       "      <th>M74</th>\n",
       "      <th>M75</th>\n",
       "      <th>M76</th>\n",
       "      <th>M77</th>\n",
       "      <th>M78</th>\n",
       "      <th>M79</th>\n",
       "      <th>M80</th>\n",
       "      <th>M81</th>\n",
       "      <th>M82</th>\n",
       "      <th>M83</th>\n",
       "      <th>M84</th>\n",
       "      <th>M85</th>\n",
       "      <th>M86</th>\n",
       "      <th>M87</th>\n",
       "      <th>M88</th>\n",
       "      <th>M89</th>\n",
       "      <th>M90</th>\n",
       "      <th>M91</th>\n",
       "      <th>M92</th>\n",
       "      <th>M93</th>\n",
       "      <th>M94</th>\n",
       "      <th>M95</th>\n",
       "      <th>M96</th>\n",
       "      <th>M97</th>\n",
       "      <th>M98</th>\n",
       "      <th>M99</th>\n",
       "      <th>M100</th>\n",
       "      <th>M101</th>\n",
       "      <th>M102</th>\n",
       "      <th>M103</th>\n",
       "      <th>M104</th>\n",
       "      <th>M105</th>\n",
       "      <th>M106</th>\n",
       "      <th>M107</th>\n",
       "      <th>M108</th>\n",
       "      <th>M109</th>\n",
       "      <th>M110</th>\n",
       "      <th>M111</th>\n",
       "      <th>M112</th>\n",
       "      <th>M113</th>\n",
       "      <th>M114</th>\n",
       "      <th>M115</th>\n",
       "      <th>M116</th>\n",
       "      <th>M117</th>\n",
       "      <th>M118</th>\n",
       "      <th>M119</th>\n",
       "      <th>M120</th>\n",
       "      <th>M121</th>\n",
       "      <th>M122</th>\n",
       "      <th>M123</th>\n",
       "      <th>M124</th>\n",
       "      <th>M125</th>\n",
       "      <th>M126</th>\n",
       "      <th>M127</th>\n",
       "      <th>M128</th>\n",
       "      <th>M129</th>\n",
       "      <th>M130</th>\n",
       "      <th>M131</th>\n",
       "      <th>M132</th>\n",
       "      <th>M133</th>\n",
       "      <th>M134</th>\n",
       "      <th>M135</th>\n",
       "      <th>M136</th>\n",
       "      <th>M137</th>\n",
       "      <th>M138</th>\n",
       "      <th>M139</th>\n",
       "      <th>M140</th>\n",
       "      <th>M141</th>\n",
       "      <th>M142</th>\n",
       "      <th>M143</th>\n",
       "      <th>M144</th>\n",
       "      <th>M145</th>\n",
       "      <th>M146</th>\n",
       "      <th>M147</th>\n",
       "      <th>M148</th>\n",
       "      <th>M149</th>\n",
       "      <th>M150</th>\n",
       "      <th>M151</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320</td>\n",
       "      <td>2.240789e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.142857</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>2.387105</td>\n",
       "      <td>5.720456e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>651246451.0</td>\n",
       "      <td>65792507.0</td>\n",
       "      <td>1.430925e+09</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>6.285714</td>\n",
       "      <td>2.285474e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>2.910818e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47000000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.358491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127860679.5</td>\n",
       "      <td>1000979.0</td>\n",
       "      <td>2.773771e+17</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.040450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.760618</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>4.709144e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.594152e+07</td>\n",
       "      <td>1.934286e+08</td>\n",
       "      <td>1</td>\n",
       "      <td>119903530.0</td>\n",
       "      <td>345000000.0</td>\n",
       "      <td>1045041.0</td>\n",
       "      <td>1.646418e+08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1.002027e+09</td>\n",
       "      <td>63.619048</td>\n",
       "      <td>829863679.0</td>\n",
       "      <td>5.169929e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>2561926.0</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>1.168908e+08</td>\n",
       "      <td>4.476974e+14</td>\n",
       "      <td>-78000000.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-4.826130e+07</td>\n",
       "      <td>850824335.0</td>\n",
       "      <td>25859.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>96000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>22269145.0</td>\n",
       "      <td>1.203129e+09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.229919e+08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>250420668.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.049770e+07</td>\n",
       "      <td>1.931810e+16</td>\n",
       "      <td>596624.0</td>\n",
       "      <td>34</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>7560272.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1000979.0</td>\n",
       "      <td>5.078871e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.901621e+06</td>\n",
       "      <td>12333435.0</td>\n",
       "      <td>2.970188e+08</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>3.875934e+07</td>\n",
       "      <td>2.901706e+17</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.144689e+08</td>\n",
       "      <td>1.504233e+07</td>\n",
       "      <td>2.532710e+08</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>9.225540e+07</td>\n",
       "      <td>3.051623e+08</td>\n",
       "      <td>3.765203e+05</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>6.938591e+07</td>\n",
       "      <td>1.842534e+08</td>\n",
       "      <td>2.107143</td>\n",
       "      <td>1.249568e+08</td>\n",
       "      <td>7383944.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.824199e+08</td>\n",
       "      <td>2.767568</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>265529069.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1636035.0</td>\n",
       "      <td>4299092.0</td>\n",
       "      <td>61656900.5</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>112896975.0</td>\n",
       "      <td>3.306454e+05</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>5.943793e+06</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.137554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.426000</td>\n",
       "      <td>0.914831</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>556</td>\n",
       "      <td>5.454261e+06</td>\n",
       "      <td>6138990.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.029878</td>\n",
       "      <td>1.694720e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>402015474.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.112340e+08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>8.080173e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.391304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>1.079069e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.803985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.221445e+06</td>\n",
       "      <td>24.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.887793e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>76967931.0</td>\n",
       "      <td>48000000.0</td>\n",
       "      <td>1509417.0</td>\n",
       "      <td>1.303709e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>3228097.0</td>\n",
       "      <td>1.482683e+07</td>\n",
       "      <td>1</td>\n",
       "      <td>1885318.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.906536e+06</td>\n",
       "      <td>1.536911e+15</td>\n",
       "      <td>-56080986.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.317400e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60744214.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.852903e+08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.611567e+05</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>5303368.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>2.760024e+06</td>\n",
       "      <td>1.246726e+16</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>9523538.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1240690.0</td>\n",
       "      <td>5.242413e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.950768e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.341153e+07</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>7.594195e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.026874e+07</td>\n",
       "      <td>1.073313e+07</td>\n",
       "      <td>5.213575e+07</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>5.129105e+06</td>\n",
       "      <td>1.682865e+07</td>\n",
       "      <td>2.557691e+07</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>2.879922e+06</td>\n",
       "      <td>1.023804e+07</td>\n",
       "      <td>1.783784</td>\n",
       "      <td>1.077655e+07</td>\n",
       "      <td>22135868.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2.322849e+07</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>58451772.0</td>\n",
       "      <td>1.462500</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>58451772.0</td>\n",
       "      <td>77572353.0</td>\n",
       "      <td>3115525.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.694206e+06</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>4.264630e+06</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.940661</td>\n",
       "      <td>2.000506</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.016467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>421</td>\n",
       "      <td>2.359738e+07</td>\n",
       "      <td>1272552.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.103578</td>\n",
       "      <td>1.852271e+07</td>\n",
       "      <td>16.0</td>\n",
       "      <td>124910611.0</td>\n",
       "      <td>44371332.0</td>\n",
       "      <td>5.518678e+08</td>\n",
       "      <td>12.142857</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>1.918874e+07</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>3.017980e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.582734</td>\n",
       "      <td>1542674.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83612.0</td>\n",
       "      <td>1.670457e+15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.181445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.806219e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>30856358.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>424182.0</td>\n",
       "      <td>4.291304e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.366557e+07</td>\n",
       "      <td>45.809524</td>\n",
       "      <td>166079328.0</td>\n",
       "      <td>3.245014e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>1887248.0</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>8.836247e+05</td>\n",
       "      <td>3.481712e+12</td>\n",
       "      <td>-18218386.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-1.120641e+07</td>\n",
       "      <td>39115783.0</td>\n",
       "      <td>1892955.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>21299777.0</td>\n",
       "      <td>9.205353e+07</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.160983e+07</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1204331.0</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>3.877527e+07</td>\n",
       "      <td>1.635350e+15</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>22</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>38571267.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>83612.0</td>\n",
       "      <td>9.469418e-01</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.522318e+06</td>\n",
       "      <td>1531113.0</td>\n",
       "      <td>1.643879e+07</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.753703e+07</td>\n",
       "      <td>1.903991e+14</td>\n",
       "      <td>7.6</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.044444</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.880631e+07</td>\n",
       "      <td>1.803011e+07</td>\n",
       "      <td>3.397465e+07</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>4.851505e+06</td>\n",
       "      <td>2.532838e+07</td>\n",
       "      <td>1.625583e+07</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>4.013703e+07</td>\n",
       "      <td>3.549669e+06</td>\n",
       "      <td>5.407407</td>\n",
       "      <td>1.415032e+07</td>\n",
       "      <td>48455690.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.142857</td>\n",
       "      <td>1.144816e+07</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>2601462.0</td>\n",
       "      <td>15.207977</td>\n",
       "      <td>6.142857</td>\n",
       "      <td>2601462.0</td>\n",
       "      <td>4373831.0</td>\n",
       "      <td>5132224.5</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1639704.0</td>\n",
       "      <td>4.640223e+06</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>9.142857</td>\n",
       "      <td>1.321201e+07</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.007713</td>\n",
       "      <td>0.502552</td>\n",
       "      <td>1.157555</td>\n",
       "      <td>0.988912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184</td>\n",
       "      <td>2.243215e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.714286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.050155e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1362655.0</td>\n",
       "      <td>231557103.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.428571</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.661335e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.824500e+08</td>\n",
       "      <td>52564750.0</td>\n",
       "      <td>75400000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.570909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63750400.0</td>\n",
       "      <td>825784.0</td>\n",
       "      <td>3.538264e+16</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1.015880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240000000.0</td>\n",
       "      <td>1.446328e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.289131e+07</td>\n",
       "      <td>8.285714e+06</td>\n",
       "      <td>8</td>\n",
       "      <td>375228605.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>992655.0</td>\n",
       "      <td>3.364729e+05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.053503e+08</td>\n",
       "      <td>745.066667</td>\n",
       "      <td>961740449.0</td>\n",
       "      <td>8.779180e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.714286</td>\n",
       "      <td>-1.147068e+07</td>\n",
       "      <td>8.827755e+15</td>\n",
       "      <td>-75434670.0</td>\n",
       "      <td>3.428571e+07</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.509527e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>356689731.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>6.285714</td>\n",
       "      <td>402269314.0</td>\n",
       "      <td>1.720669e+08</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1.035969e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>280752742.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.861510e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3463893.0</td>\n",
       "      <td>22</td>\n",
       "      <td>11.142857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>825784.0</td>\n",
       "      <td>3.317987e-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.985428e+08</td>\n",
       "      <td>365870082.0</td>\n",
       "      <td>9.647028e+07</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.120377e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.635622e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.569189e+08</td>\n",
       "      <td>3.861157e+05</td>\n",
       "      <td>5.221550e+05</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.007674e+08</td>\n",
       "      <td>2.398642e+08</td>\n",
       "      <td>11.232558</td>\n",
       "      <td>2.332816e+08</td>\n",
       "      <td>702263143.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.180810e+08</td>\n",
       "      <td>0.634589</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>387362557.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>25037468.0</td>\n",
       "      <td>209680005.0</td>\n",
       "      <td>117190720.0</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.857143</td>\n",
       "      <td>342582008.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.029361e+08</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.504471</td>\n",
       "      <td>2.827495</td>\n",
       "      <td>0.670929</td>\n",
       "      <td>0.483688</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>496</td>\n",
       "      <td>6.892245e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400018121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.800000e+06</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.871429e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.101114e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69121.0</td>\n",
       "      <td>54821.0</td>\n",
       "      <td>1.008468e+15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.236488e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.013714e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>5787060.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3936371.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>16254955.0</td>\n",
       "      <td>3.721497e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>1786609.0</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1.504529e+07</td>\n",
       "      <td>1.423000e+13</td>\n",
       "      <td>-4000000.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.818941e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>17618015.0</td>\n",
       "      <td>4.054821e+06</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1435898.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.137634e+06</td>\n",
       "      <td>3.002813e+14</td>\n",
       "      <td>14300.0</td>\n",
       "      <td>65</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>369121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>54821.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1185898.0</td>\n",
       "      <td>2.821947e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.873712e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.020590e+07</td>\n",
       "      <td>7.881900e+06</td>\n",
       "      <td>7.633217e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2.095534e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.480881e+06</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>2.139076e+06</td>\n",
       "      <td>2.545055e+06</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>8.719328e+06</td>\n",
       "      <td>1400447.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>2.051488e+06</td>\n",
       "      <td>4.843137</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>3435898.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1042936.0</td>\n",
       "      <td>3049821.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.154725e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.230383e+06</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       M1          M2      M3      M4     M5      M6         M7          M8        M9       M10          M11           M12         M13      M14  M15     M16     M17     M18        M19          M20      M21     M22         M23          M24         M25     M26  M27     M28       M29         M30      \\\n",
       "0      320     2.240789e+08        0.0  0.0  8.142857  1.5   2.857143  2.387105  5.720456e+07   0.0  651246451.0   65792507.0  1.430925e+09   5.000000  15.0   0   0.571429   6.0   5.285714   6.285714  2.285474e+07  0.0  1.142857  2.910818e+07         0.0  47000000.0   1    1   2.358491        0.0  127860679.5   \n",
       "1      556     5.454261e+06  6138990.0  0.0  5.142857  NaN   0.285714  1.029878  1.694720e+08   0.0  402015474.0          0.0  0.000000e+00   7.142857  22.0   4   0.714286   9.0   2.142857   3.000000  2.112340e+08  1.0  0.571429  8.080173e+06         0.0         NaN   4    0   3.391304        0.0          NaN   \n",
       "2      421     2.359738e+07  1272552.0  0.0  3.428571  NaN   4.000000  1.103578  1.852271e+07  16.0  124910611.0   44371332.0  5.518678e+08  12.142857  28.0   0   1.857143  28.0   1.571429   1.285714  1.918874e+07  3.0  1.142857  3.017980e+06         0.0         NaN   9    3   0.582734  1542674.0          NaN   \n",
       "3      184     2.243215e+08        0.0  0.0  3.285714  NaN  10.714286       NaN  1.050155e+06   0.0    1362655.0  231557103.0  0.000000e+00   8.428571   3.0   1   0.285714  24.0  13.000000  12.000000  4.661335e+06  0.0  0.285714  1.824500e+08  52564750.0  75400000.0   0    0   0.570909        0.0   63750400.0   \n",
       "4      496     6.892245e+07        0.0  0.0  3.285714  1.0   1.857143  0.000000           NaN   0.0  400018121.0          0.0  1.800000e+06   0.428571   2.0   0   0.000000   4.0   5.857143   2.142857  2.871429e+05  0.0  0.000000  2.101114e+06         0.0  30000000.0   0    0   6.909091        0.0      69121.0   \n",
       "\n",
       "      M31          M32       M33     M34    M35     M36       M37    M38      M39           M40       M41   M42   M43   M44       M45           M46      M47      M48          M49         M50          M51      M52     M53         M54          M55         M56           M57      M58     M59        M60          M61      \\\n",
       "0  1000979.0  2.773771e+17   1.5  0.040450  0.0  7.760618  0.142857  1.0    4000000.0  4.709144e+08   NaN  18.0  11.0   6.0  9.594152e+07  1.934286e+08   1   119903530.0  345000000.0  1045041.0  1.646418e+08  3.0  7.500000  1.002027e+09   63.619048  829863679.0  5.169929e+07   0   2561926.0   2.714286  1.168908e+08   \n",
       "1  1000000.0  1.079069e+12   NaN  1.803985  0.0  1.000000  0.285714  0.0          NaN  1.221445e+06  24.0  34.0   9.0   8.0  4.887793e+06           NaN   0    76967931.0   48000000.0  1509417.0  1.303709e+08  0.0       inf  0.000000e+00   10.333333    3228097.0  1.482683e+07   1   1885318.0   0.285714  1.906536e+06   \n",
       "2    83612.0  1.670457e+15   NaN  1.181445  0.0       NaN  4.285714  6.0          NaN           NaN   5.0  16.0   9.0  10.0  6.806219e+07           NaN   0    30856358.0          NaN   424182.0  4.291304e+06  0.0  0.066667  1.366557e+07   45.809524  166079328.0  3.245014e+07   0   1887248.0   4.285714  8.836247e+05   \n",
       "3   825784.0  3.538264e+16  12.5  1.015880  0.0       NaN  0.000000  0.0  240000000.0  1.446328e+06   NaN   2.0   7.0   5.0  4.289131e+07  8.285714e+06   8   375228605.0          NaN   992655.0  3.364729e+05  2.0  0.200000  1.053503e+08  745.066667  961740449.0  8.779180e+07   0         0.0  10.714286 -1.147068e+07   \n",
       "4    54821.0  1.008468e+15   0.0       NaN  NaN  0.000000  0.000000  0.0          NaN  1.236488e+07   NaN   NaN   3.0   2.0  4.013714e+06  0.000000e+00   0     5787060.0          NaN  3936371.0  0.000000e+00  0.0  1.000000  0.000000e+00    1.600000   16254955.0  3.721497e+06   0   1786609.0   1.714286  1.504529e+07   \n",
       "\n",
       "        M62          M63          M64       M65       M66          M67          M68      M69  M70   M71      M72     M73     M74       M75       M76        M77           M78       M79       M80       M81     M82        M83         M84         M85           M86         M87     M88     M89         M90      M91   M92  \\\n",
       "0  4.476974e+14 -78000000.0  0.000000e+00  19.0 -4.826130e+07  850824335.0      25859.0   1    2   29.0  96000000.0  0.0  0.666667  1.142857  2.428571   22269145.0  1.203129e+09   3.0  2.229919e+08   1.0  0.142857  250420668.0  0.000000  3.049770e+07  1.931810e+16   596624.0  34    2.857143   7560272.0   0.0   7.0   \n",
       "1  1.536911e+15 -56080986.0           NaN  25.0  5.317400e+04          0.0   60744214.0   2    0    3.0         NaN  0.0  0.833333  1.428571  0.571429          0.0  1.852903e+08   3.0  4.611567e+05   3.0  0.285714    5303368.0  0.285714  2.760024e+06  1.246726e+16    22000.0  80    1.428571   9523538.0   0.0  11.0   \n",
       "2  3.481712e+12 -18218386.0           NaN  36.0 -1.120641e+07   39115783.0    1892955.0   1    6    1.0         NaN  3.0  7.400000  5.857143  5.857143   21299777.0  9.205353e+07   4.0  5.160983e+07  38.0  3.000000    1204331.0  6.714286  3.877527e+07  1.635350e+15     3300.0  22    5.142857  38571267.0  10.0  10.0   \n",
       "3  8.827755e+15 -75434670.0  3.428571e+07  50.0  2.509527e+07          0.0  356689731.0   1   10   10.0         NaN  1.0  0.666667  7.571429  6.285714  402269314.0  1.720669e+08  11.5  1.035969e+06   NaN  0.000000  280752742.0  0.000000  4.861510e+08           NaN -3463893.0  22   11.142857         NaN   0.0   1.0   \n",
       "4  1.423000e+13  -4000000.0  0.000000e+00  10.0  6.818941e+07          0.0          0.0   2    0    7.0         0.0  0.0       NaN  0.571429  0.285714   17618015.0  4.054821e+06   0.5  0.000000e+00   1.0  0.285714    1435898.0  0.000000  1.137634e+06  3.002813e+14    14300.0  65    1.285714    369121.0   0.0   2.0   \n",
       "\n",
       "      M93       M94          M95      M96       M97          M98           M99        M100        M101          M102      M103    M104      M105     M106    M107     M108  M109      M110          M111          M112      M113    M114        M115          M116          M117        M118        M119          M120      \\\n",
       "0  1.714286  1000979.0  5.078871e-02  NaN  3.901621e+06   12333435.0  2.970188e+08  0.428571  3.875934e+07  2.901706e+17   0.5  1.571429   2.000000   0.0   0.666667   0.5   1.0  1.144689e+08  1.504233e+07  2.532710e+08  13.0  1.714286  9.225540e+07  3.051623e+08  3.765203e+05  2.142857  6.938591e+07  1.842534e+08   \n",
       "1  1.428571  1240690.0  5.242413e-01  1.0  5.950768e+06          0.0  1.341153e+07  0.285714  7.594195e+07           NaN   1.5  1.000000   1.142857   0.0   0.566667   1.0   0.0  1.026874e+07  1.073313e+07  5.213575e+07  10.0  0.857143  5.129105e+06  1.682865e+07  2.557691e+07  0.285714  2.879922e+06  1.023804e+07   \n",
       "2  3.714286    83612.0  9.469418e-01  6.0  1.522318e+06    1531113.0  1.643879e+07  5.000000  1.753703e+07  1.903991e+14   7.6  3.857143  10.500000   3.0  26.044444   5.0   6.0  1.880631e+07  1.803011e+07  3.397465e+07  34.0  7.571429  4.851505e+06  2.532838e+07  1.625583e+07  3.857143  4.013703e+07  3.549669e+06   \n",
       "3  9.000000   825784.0  3.317987e-08  1.0  1.985428e+08  365870082.0  9.647028e+07  0.142857  0.000000e+00           NaN   0.8  3.142857   8.200000   1.0   0.333333   1.0   NaN  2.120377e+08  0.000000e+00  3.635622e+06   1.0  8.000000  4.569189e+08  3.861157e+05  5.221550e+05  8.000000  4.007674e+08  2.398642e+08   \n",
       "4  0.285714    54821.0           NaN  NaN           NaN    1185898.0  2.821947e+06  0.000000  1.873712e+07  0.000000e+00   NaN  0.428571   0.333333   0.0        NaN   NaN   NaN  7.020590e+07  7.881900e+06  7.633217e+07   NaN  0.428571  2.095534e+06  0.000000e+00  3.480881e+06  0.714286  2.139076e+06  2.545055e+06   \n",
       "\n",
       "     M121         M122         M123      M124    M125        M126        M127    M128  M129  M130    M131       M132        M133       M134       M135        M136         M137        M138      M139      M140       M141          M142        M143      M144        M145        M146     M147    M148      M149      M150    \\\n",
       "0   2.107143  1.249568e+08    7383944.0   6.0  0.000000  2.824199e+08  2.767568    2    0.0   0.0  3.571429  265529069.0   0.571429  0.000000   1636035.0    4299092.0   61656900.5  2.285714  1.285714  2.000000  112896975.0  3.306454e+05  0.142857  1.428571  5.943793e+06   3.714286   8.0  1.137554       NaN  8.426000   \n",
       "1   1.783784  1.077655e+07   22135868.0   1.0  0.428571  2.322849e+07  3.300000    0    1.0   0.0  0.428571   58451772.0   1.462500  1.428571  58451772.0   77572353.0    3115525.0  0.285714  0.000000  0.142857          0.0  2.694206e+06  0.285714  1.285714  4.264630e+06   2.600000  10.0  0.940661  2.000506       inf   \n",
       "2   5.407407  1.415032e+07   48455690.0   0.0  6.142857  1.144816e+07  0.432432    9    7.0   0.0  2.857143    2601462.0  15.207977  6.142857   2601462.0    4373831.0    5132224.5  4.142857  7.285714  6.000000    1639704.0  4.640223e+06  6.714286  9.142857  1.321201e+07   6.500000  13.0  1.007713  0.502552  1.157555   \n",
       "3  11.232558  2.332816e+08  702263143.0  12.0  0.000000  1.180810e+08  0.634589   12    0.0   0.0  7.714286  387362557.5   0.500000  0.142857  25037468.0  209680005.0  117190720.0  7.714286  7.000000  8.857143  342582008.0  0.000000e+00  0.000000  6.000000  7.029361e+08  11.500000   0.0  1.504471  2.827495  0.670929   \n",
       "4   0.640000  8.719328e+06    1400447.0  20.0  0.142857  2.051488e+06  4.843137    1    1.0   0.0  0.571429    3435898.0        NaN  0.000000         NaN    1042936.0    3049821.0  0.714286  0.142857  0.285714          0.0  7.154725e+07  0.000000  0.142857  1.230383e+06   0.833333   2.0       inf       inf       NaN   \n",
       "\n",
       "     M151    target  \n",
       "0  0.914831     0    \n",
       "1  1.016467     1    \n",
       "2  0.988912     0    \n",
       "3  0.483688     0    \n",
       "4  0.600029     1    "
      ]
     },
     "execution_count": 2036,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a copy of original dataset\n",
    "df1 = raw_data.copy()\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2037,
   "id": "85dbfba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(326, 153)"
      ]
     },
     "execution_count": 2037,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of the training dataset\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2038,
   "id": "10c4c581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      int64\n",
       "M1            float64\n",
       "M2            float64\n",
       "M3            float64\n",
       "M4            float64\n",
       "M5            float64\n",
       "M6            float64\n",
       "M7            float64\n",
       "M8            float64\n",
       "M9            float64\n",
       "M10           float64\n",
       "M11           float64\n",
       "M12           float64\n",
       "M13           float64\n",
       "M14           float64\n",
       "M15             int64\n",
       "M16           float64\n",
       "M17           float64\n",
       "M18           float64\n",
       "M19           float64\n",
       "M20           float64\n",
       "M21           float64\n",
       "M22           float64\n",
       "M23           float64\n",
       "M24           float64\n",
       "M25           float64\n",
       "M26             int64\n",
       "M27             int64\n",
       "M28           float64\n",
       "M29           float64\n",
       "M30           float64\n",
       "M31           float64\n",
       "M32           float64\n",
       "M33           float64\n",
       "M34           float64\n",
       "M35           float64\n",
       "M36           float64\n",
       "M37           float64\n",
       "M38           float64\n",
       "M39           float64\n",
       "M40           float64\n",
       "M41           float64\n",
       "M42           float64\n",
       "M43           float64\n",
       "M44           float64\n",
       "M45           float64\n",
       "M46           float64\n",
       "M47             int64\n",
       "M48           float64\n",
       "M49           float64\n",
       "M50           float64\n",
       "M51           float64\n",
       "M52           float64\n",
       "M53           float64\n",
       "M54           float64\n",
       "M55           float64\n",
       "M56           float64\n",
       "M57           float64\n",
       "M58             int64\n",
       "M59           float64\n",
       "M60           float64\n",
       "M61           float64\n",
       "M62           float64\n",
       "M63           float64\n",
       "M64           float64\n",
       "M65           float64\n",
       "M66           float64\n",
       "M67           float64\n",
       "M68           float64\n",
       "M69             int64\n",
       "M70             int64\n",
       "M71           float64\n",
       "M72           float64\n",
       "M73           float64\n",
       "M74           float64\n",
       "M75           float64\n",
       "M76           float64\n",
       "M77           float64\n",
       "M78           float64\n",
       "M79           float64\n",
       "M80           float64\n",
       "M81           float64\n",
       "M82           float64\n",
       "M83           float64\n",
       "M84           float64\n",
       "M85           float64\n",
       "M86           float64\n",
       "M87           float64\n",
       "M88             int64\n",
       "M89           float64\n",
       "M90           float64\n",
       "M91           float64\n",
       "M92           float64\n",
       "M93           float64\n",
       "M94           float64\n",
       "M95           float64\n",
       "M96           float64\n",
       "M97           float64\n",
       "M98           float64\n",
       "M99           float64\n",
       "M100          float64\n",
       "M101          float64\n",
       "M102          float64\n",
       "M103          float64\n",
       "M104          float64\n",
       "M105          float64\n",
       "M106          float64\n",
       "M107          float64\n",
       "M108          float64\n",
       "M109          float64\n",
       "M110          float64\n",
       "M111          float64\n",
       "M112          float64\n",
       "M113          float64\n",
       "M114          float64\n",
       "M115          float64\n",
       "M116          float64\n",
       "M117          float64\n",
       "M118          float64\n",
       "M119          float64\n",
       "M120          float64\n",
       "M121          float64\n",
       "M122          float64\n",
       "M123          float64\n",
       "M124          float64\n",
       "M125          float64\n",
       "M126          float64\n",
       "M127          float64\n",
       "M128            int64\n",
       "M129          float64\n",
       "M130          float64\n",
       "M131          float64\n",
       "M132          float64\n",
       "M133          float64\n",
       "M134          float64\n",
       "M135          float64\n",
       "M136          float64\n",
       "M137          float64\n",
       "M138          float64\n",
       "M139          float64\n",
       "M140          float64\n",
       "M141          float64\n",
       "M142          float64\n",
       "M143          float64\n",
       "M144          float64\n",
       "M145          float64\n",
       "M146          float64\n",
       "M147          float64\n",
       "M148          float64\n",
       "M149          float64\n",
       "M150          float64\n",
       "M151          float64\n",
       "target          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2038,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identying the datatypes\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2039,
   "id": "401bc3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    245\n",
       "0     81\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 2039,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check the class distribution in train data\n",
    "df1[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2040,
   "id": "0087c5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    63\n",
       "0    25\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 2040,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check the class distribution of test/validation data \n",
    "test_data = pd.read_csv(\"Test_data_Jenfi_assessment_070423.csv\")\n",
    "test_data[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2041,
   "id": "bea6e9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifying the null values in each variable\n",
    "null = pd.DataFrame(df1.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2042,
   "id": "7fcbc66e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>M5</th>\n",
       "      <th>M6</th>\n",
       "      <th>M7</th>\n",
       "      <th>M8</th>\n",
       "      <th>M9</th>\n",
       "      <th>M10</th>\n",
       "      <th>M11</th>\n",
       "      <th>M12</th>\n",
       "      <th>M13</th>\n",
       "      <th>M14</th>\n",
       "      <th>M15</th>\n",
       "      <th>M16</th>\n",
       "      <th>M17</th>\n",
       "      <th>M18</th>\n",
       "      <th>M19</th>\n",
       "      <th>M20</th>\n",
       "      <th>M21</th>\n",
       "      <th>M22</th>\n",
       "      <th>M23</th>\n",
       "      <th>M24</th>\n",
       "      <th>M25</th>\n",
       "      <th>M26</th>\n",
       "      <th>M27</th>\n",
       "      <th>M28</th>\n",
       "      <th>M29</th>\n",
       "      <th>M30</th>\n",
       "      <th>M31</th>\n",
       "      <th>M32</th>\n",
       "      <th>M33</th>\n",
       "      <th>M34</th>\n",
       "      <th>M35</th>\n",
       "      <th>M36</th>\n",
       "      <th>M37</th>\n",
       "      <th>M38</th>\n",
       "      <th>M39</th>\n",
       "      <th>M40</th>\n",
       "      <th>M41</th>\n",
       "      <th>M42</th>\n",
       "      <th>M43</th>\n",
       "      <th>M44</th>\n",
       "      <th>M45</th>\n",
       "      <th>M46</th>\n",
       "      <th>M47</th>\n",
       "      <th>M48</th>\n",
       "      <th>M49</th>\n",
       "      <th>M50</th>\n",
       "      <th>M51</th>\n",
       "      <th>M52</th>\n",
       "      <th>M53</th>\n",
       "      <th>M54</th>\n",
       "      <th>M55</th>\n",
       "      <th>M56</th>\n",
       "      <th>M57</th>\n",
       "      <th>M58</th>\n",
       "      <th>M59</th>\n",
       "      <th>M60</th>\n",
       "      <th>M61</th>\n",
       "      <th>M62</th>\n",
       "      <th>M63</th>\n",
       "      <th>M64</th>\n",
       "      <th>M65</th>\n",
       "      <th>M66</th>\n",
       "      <th>M67</th>\n",
       "      <th>M68</th>\n",
       "      <th>M69</th>\n",
       "      <th>M70</th>\n",
       "      <th>M71</th>\n",
       "      <th>M72</th>\n",
       "      <th>M73</th>\n",
       "      <th>M74</th>\n",
       "      <th>M75</th>\n",
       "      <th>M76</th>\n",
       "      <th>M77</th>\n",
       "      <th>M78</th>\n",
       "      <th>M79</th>\n",
       "      <th>M80</th>\n",
       "      <th>M81</th>\n",
       "      <th>M82</th>\n",
       "      <th>M83</th>\n",
       "      <th>M84</th>\n",
       "      <th>M85</th>\n",
       "      <th>M86</th>\n",
       "      <th>M87</th>\n",
       "      <th>M88</th>\n",
       "      <th>M89</th>\n",
       "      <th>M90</th>\n",
       "      <th>M91</th>\n",
       "      <th>M92</th>\n",
       "      <th>M93</th>\n",
       "      <th>M94</th>\n",
       "      <th>M95</th>\n",
       "      <th>M96</th>\n",
       "      <th>M97</th>\n",
       "      <th>M98</th>\n",
       "      <th>M99</th>\n",
       "      <th>M100</th>\n",
       "      <th>M101</th>\n",
       "      <th>M102</th>\n",
       "      <th>M103</th>\n",
       "      <th>M104</th>\n",
       "      <th>M105</th>\n",
       "      <th>M106</th>\n",
       "      <th>M107</th>\n",
       "      <th>M108</th>\n",
       "      <th>M109</th>\n",
       "      <th>M110</th>\n",
       "      <th>M111</th>\n",
       "      <th>M112</th>\n",
       "      <th>M113</th>\n",
       "      <th>M114</th>\n",
       "      <th>M115</th>\n",
       "      <th>M116</th>\n",
       "      <th>M117</th>\n",
       "      <th>M118</th>\n",
       "      <th>M119</th>\n",
       "      <th>M120</th>\n",
       "      <th>M121</th>\n",
       "      <th>M122</th>\n",
       "      <th>M123</th>\n",
       "      <th>M124</th>\n",
       "      <th>M125</th>\n",
       "      <th>M126</th>\n",
       "      <th>M127</th>\n",
       "      <th>M128</th>\n",
       "      <th>M129</th>\n",
       "      <th>M130</th>\n",
       "      <th>M131</th>\n",
       "      <th>M132</th>\n",
       "      <th>M133</th>\n",
       "      <th>M134</th>\n",
       "      <th>M135</th>\n",
       "      <th>M136</th>\n",
       "      <th>M137</th>\n",
       "      <th>M138</th>\n",
       "      <th>M139</th>\n",
       "      <th>M140</th>\n",
       "      <th>M141</th>\n",
       "      <th>M142</th>\n",
       "      <th>M143</th>\n",
       "      <th>M144</th>\n",
       "      <th>M145</th>\n",
       "      <th>M146</th>\n",
       "      <th>M147</th>\n",
       "      <th>M148</th>\n",
       "      <th>M149</th>\n",
       "      <th>M150</th>\n",
       "      <th>M151</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>190</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>171</td>\n",
       "      <td>89</td>\n",
       "      <td>20</td>\n",
       "      <td>239</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>178</td>\n",
       "      <td>186</td>\n",
       "      <td>72</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>229</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>135</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>62</td>\n",
       "      <td>206</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>255</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>49</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>74</td>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>92</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>106</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  M1  M2  M3   M4  M5   M6  M7   M8  M9  M10  M11  M12  M13  M14  M15  M16  M17  M18  M19  M20  M21  M22  M23  M24  M25  M26  M27  M28  M29  M30  M31  M32  M33  M34  M35  M36  M37  M38  M39  M40  M41  M42  M43  M44  M45  M46  M47  M48  M49  M50  M51  M52  M53  M54  M55  M56  M57  M58  M59  M60  M61  M62  \\\n",
       "0       0       0  12  127   0  242   0  173  20  12  19    0   45    0   17    0   12    2    0    0   12   12   12    0    0   171   0    0    0   12   190  13   30   171  89   20   239  12   12   178  186  72   27   12   12    0   206   0    4   229  18   12   135  47    0   19   11    0    0    0    0    0   29    \n",
       "\n",
       "   M63  M64  M65  M66  M67  M68  M69  M70  M71  M72  M73  M74  M75  M76  M77  M78  M79  M80  M81  M82  M83  M84  M85  M86  M87  M88  M89  M90  M91  M92  M93  M94  M95  M96  M97  M98  M99  M100  M101  M102  M103  M104  M105  M106  M107  M108  M109  M110  M111  M112  M113  M114  M115  M116  M117  M118  M119  M120  \\\n",
       "0  62   206   2    0   12    0    0    0   127  255  12   27    0    0    0   17   15   12   49   12   13   12    0   52   12    0    0   28   12   12    0   17   74   60   57    0    0    12    12    92    49     0    14    12    43    36    30     0    12    18    37     0     0    12    12     0     0     0    \n",
       "\n",
       "   M121  M122  M123  M124  M125  M126  M127  M128  M129  M130  M131  M132  M133  M134  M135  M136  M137  M138  M139  M140  M141  M142  M143  M144  M145  M146  M147  M148  M149  M150  M151  target  \n",
       "0    0     0     0    12    12    13     0     0    12    12     0    13    24    12    63     0    62     0     0     0     0    12    12     0     0    15    12     0    73    106   15      0    "
      ]
     },
     "execution_count": 2042,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transposing the dataframe for easy viewing\n",
    "null.T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2043,
   "id": "ee8df949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>M5</th>\n",
       "      <th>M6</th>\n",
       "      <th>M7</th>\n",
       "      <th>M8</th>\n",
       "      <th>M9</th>\n",
       "      <th>M10</th>\n",
       "      <th>M11</th>\n",
       "      <th>M12</th>\n",
       "      <th>M13</th>\n",
       "      <th>M14</th>\n",
       "      <th>M15</th>\n",
       "      <th>M16</th>\n",
       "      <th>M17</th>\n",
       "      <th>M18</th>\n",
       "      <th>M19</th>\n",
       "      <th>M20</th>\n",
       "      <th>M21</th>\n",
       "      <th>M22</th>\n",
       "      <th>M23</th>\n",
       "      <th>M24</th>\n",
       "      <th>M25</th>\n",
       "      <th>M26</th>\n",
       "      <th>M27</th>\n",
       "      <th>M28</th>\n",
       "      <th>M29</th>\n",
       "      <th>M30</th>\n",
       "      <th>M31</th>\n",
       "      <th>M32</th>\n",
       "      <th>M33</th>\n",
       "      <th>M34</th>\n",
       "      <th>M35</th>\n",
       "      <th>M36</th>\n",
       "      <th>M37</th>\n",
       "      <th>M38</th>\n",
       "      <th>M39</th>\n",
       "      <th>M40</th>\n",
       "      <th>M41</th>\n",
       "      <th>M42</th>\n",
       "      <th>M43</th>\n",
       "      <th>M44</th>\n",
       "      <th>M45</th>\n",
       "      <th>M46</th>\n",
       "      <th>M47</th>\n",
       "      <th>M48</th>\n",
       "      <th>M49</th>\n",
       "      <th>M50</th>\n",
       "      <th>M51</th>\n",
       "      <th>M52</th>\n",
       "      <th>M53</th>\n",
       "      <th>M54</th>\n",
       "      <th>M55</th>\n",
       "      <th>M56</th>\n",
       "      <th>M57</th>\n",
       "      <th>M58</th>\n",
       "      <th>M59</th>\n",
       "      <th>M60</th>\n",
       "      <th>M61</th>\n",
       "      <th>M62</th>\n",
       "      <th>M63</th>\n",
       "      <th>M64</th>\n",
       "      <th>M65</th>\n",
       "      <th>M66</th>\n",
       "      <th>M67</th>\n",
       "      <th>M68</th>\n",
       "      <th>M69</th>\n",
       "      <th>M70</th>\n",
       "      <th>M71</th>\n",
       "      <th>M72</th>\n",
       "      <th>M73</th>\n",
       "      <th>M74</th>\n",
       "      <th>M75</th>\n",
       "      <th>M76</th>\n",
       "      <th>M77</th>\n",
       "      <th>M78</th>\n",
       "      <th>M79</th>\n",
       "      <th>M80</th>\n",
       "      <th>M81</th>\n",
       "      <th>M82</th>\n",
       "      <th>M83</th>\n",
       "      <th>M84</th>\n",
       "      <th>M85</th>\n",
       "      <th>M86</th>\n",
       "      <th>M87</th>\n",
       "      <th>M88</th>\n",
       "      <th>M89</th>\n",
       "      <th>M90</th>\n",
       "      <th>M91</th>\n",
       "      <th>M92</th>\n",
       "      <th>M93</th>\n",
       "      <th>M94</th>\n",
       "      <th>M95</th>\n",
       "      <th>M96</th>\n",
       "      <th>M97</th>\n",
       "      <th>M98</th>\n",
       "      <th>M99</th>\n",
       "      <th>M100</th>\n",
       "      <th>M101</th>\n",
       "      <th>M102</th>\n",
       "      <th>M103</th>\n",
       "      <th>M104</th>\n",
       "      <th>M105</th>\n",
       "      <th>M106</th>\n",
       "      <th>M107</th>\n",
       "      <th>M108</th>\n",
       "      <th>M109</th>\n",
       "      <th>M110</th>\n",
       "      <th>M111</th>\n",
       "      <th>M112</th>\n",
       "      <th>M113</th>\n",
       "      <th>M114</th>\n",
       "      <th>M115</th>\n",
       "      <th>M116</th>\n",
       "      <th>M117</th>\n",
       "      <th>M118</th>\n",
       "      <th>M119</th>\n",
       "      <th>M120</th>\n",
       "      <th>M121</th>\n",
       "      <th>M122</th>\n",
       "      <th>M123</th>\n",
       "      <th>M124</th>\n",
       "      <th>M125</th>\n",
       "      <th>M126</th>\n",
       "      <th>M127</th>\n",
       "      <th>M128</th>\n",
       "      <th>M129</th>\n",
       "      <th>M130</th>\n",
       "      <th>M131</th>\n",
       "      <th>M132</th>\n",
       "      <th>M133</th>\n",
       "      <th>M134</th>\n",
       "      <th>M135</th>\n",
       "      <th>M136</th>\n",
       "      <th>M137</th>\n",
       "      <th>M138</th>\n",
       "      <th>M139</th>\n",
       "      <th>M140</th>\n",
       "      <th>M141</th>\n",
       "      <th>M142</th>\n",
       "      <th>M143</th>\n",
       "      <th>M144</th>\n",
       "      <th>M145</th>\n",
       "      <th>M146</th>\n",
       "      <th>M147</th>\n",
       "      <th>M148</th>\n",
       "      <th>M149</th>\n",
       "      <th>M150</th>\n",
       "      <th>M151</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>38.957055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.233129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.067485</td>\n",
       "      <td>6.134969</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>5.828221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.803681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.214724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>0.613497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.453988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>58.282209</td>\n",
       "      <td>3.98773</td>\n",
       "      <td>9.202454</td>\n",
       "      <td>52.453988</td>\n",
       "      <td>27.300613</td>\n",
       "      <td>6.134969</td>\n",
       "      <td>73.312883</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>54.601227</td>\n",
       "      <td>57.055215</td>\n",
       "      <td>22.08589</td>\n",
       "      <td>8.282209</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.190184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.226994</td>\n",
       "      <td>70.245399</td>\n",
       "      <td>5.521472</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>41.411043</td>\n",
       "      <td>14.417178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.828221</td>\n",
       "      <td>3.374233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.895706</td>\n",
       "      <td>19.018405</td>\n",
       "      <td>63.190184</td>\n",
       "      <td>0.613497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.957055</td>\n",
       "      <td>78.220859</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>8.282209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.214724</td>\n",
       "      <td>4.601227</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>15.030675</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>3.98773</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.95092</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.588957</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.214724</td>\n",
       "      <td>22.699387</td>\n",
       "      <td>18.404908</td>\n",
       "      <td>17.484663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>28.220859</td>\n",
       "      <td>15.030675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.294479</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>13.190184</td>\n",
       "      <td>11.042945</td>\n",
       "      <td>9.202454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>5.521472</td>\n",
       "      <td>11.349693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>3.98773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.98773</td>\n",
       "      <td>7.361963</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>19.325153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.018405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.601227</td>\n",
       "      <td>3.680982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.392638</td>\n",
       "      <td>32.515337</td>\n",
       "      <td>4.601227</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  M1      M2        M3      M4      M5      M6      M7         M8        M9        M10    M11     M12     M13     M14    M15     M16       M17    M18  M19     M20       M21       M22    M23  M24     M25     M26  M27  M28     M29       M30       M31       M32       M33        M34        M35       M36     \\\n",
       "0      0.0     0.0  3.680982  38.957055  0.0  74.233129  0.0  53.067485  6.134969  3.680982  5.828221  0.0  13.803681  0.0  5.214724  0.0  3.680982  0.613497  0.0  0.0  3.680982  3.680982  3.680982  0.0  0.0  52.453988  0.0  0.0  0.0  3.680982  58.282209  3.98773  9.202454  52.453988  27.300613  6.134969  73.312883   \n",
       "\n",
       "      M37       M38       M39        M40        M41       M42       M43       M44    M45     M46     M47     M48       M49        M50       M51       M52        M53     M54     M55       M56    M57  M58  M59  M60  M61     M62       M63        M64        M65    M66     M67    M68  M69  M70     M71        M72     \\\n",
       "0  3.680982  3.680982  54.601227  57.055215  22.08589  8.282209  3.680982  3.680982  0.0  63.190184  0.0  1.226994  70.245399  5.521472  3.680982  41.411043  14.417178  0.0  5.828221  3.374233  0.0  0.0  0.0  0.0  0.0  8.895706  19.018405  63.190184  0.613497  0.0  3.680982  0.0  0.0  0.0  38.957055  78.220859   \n",
       "\n",
       "      M73       M74    M75  M76  M77     M78       M79       M80       M81        M82      M83       M84    M85     M86       M87    M88  M89     M90       M91       M92    M93     M94       M95        M96        M97     M98  M99    M100      M101      M102       M103     M104    M105      M106      M107     \\\n",
       "0  3.680982  8.282209  0.0  0.0  0.0  5.214724  4.601227  3.680982  15.030675  3.680982  3.98773  3.680982  0.0  15.95092  3.680982  0.0  0.0  8.588957  3.680982  3.680982  0.0  5.214724  22.699387  18.404908  17.484663  0.0  0.0  3.680982  3.680982  28.220859  15.030675   0.0  4.294479  3.680982  13.190184   \n",
       "\n",
       "     M108       M109    M110    M111      M112      M113     M114  M115    M116      M117    M118  M119  M120  M121  M122  M123    M124      M125     M126    M127  M128    M129      M130    M131   M132      M133      M134      M135     M136    M137     M138  M139  M140  M141    M142      M143    M144  M145    M146    \\\n",
       "0  11.042945  9.202454   0.0  3.680982  5.521472  11.349693   0.0   0.0  3.680982  3.680982   0.0   0.0   0.0   0.0   0.0   0.0  3.680982  3.680982  3.98773   0.0   0.0  3.680982  3.680982   0.0  3.98773  7.361963  3.680982  19.325153   0.0  19.018405   0.0   0.0   0.0   0.0  3.680982  3.680982   0.0   0.0  4.601227   \n",
       "\n",
       "     M147    M148    M149       M150       M151    target  \n",
       "0  3.680982   0.0  22.392638  32.515337  4.601227    0.0   "
      ]
     },
     "execution_count": 2043,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data missing percentage for each columns\n",
    "null_perc = null.T/len(df1)*100\n",
    "null_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2044,
   "id": "42cfb13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the index column\n",
    "df1.drop(\"Unnamed: 0\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2045,
   "id": "841acefb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop variable whose missing values are >70%\n",
    "for i in df1.columns:\n",
    "     if df1[i].isna().sum()/len(df1)*100 > 70:\n",
    "            df1.drop(i,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2046,
   "id": "12fa06e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['M5', 'M36', 'M49', 'M72']"
      ]
     },
     "execution_count": 2046,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropped columns based on missing values\n",
    "dropped_columns = [i for i in raw_data.columns[1:] if i not in df1.columns]\n",
    "dropped_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b279da5",
   "metadata": {},
   "source": [
    "<b>Observations from the preliminary analysis:\n",
    "* Target classes are highly imbalanced    \n",
    "* The Target value doesnot contain any null values so we will not remove any rows completely\n",
    "* Majority of the columns has missing values and we will try imputing using KNN imputation method \n",
    "* We dropped columns with missing values >70 % since the information contained in the column is very less and even if we   impute the effect of it over the target variable might be misleading.However we can try without dropping these variables compare the results or use a different thershold for dropping.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95525d0",
   "metadata": {},
   "source": [
    "### 3. MISSING VALUE IMPUTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9469644a",
   "metadata": {},
   "source": [
    "* We will use <b>\"Minmax scaler\"</b> transformation which will ensures features are all in same scale and have equal influence in distance calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2047,
   "id": "f90f9476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the column names in a variable\n",
    "df1_col = df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2048,
   "id": "f98f7e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(326, 147)"
      ]
     },
     "execution_count": 2048,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of the dataframe after dropping 4variables and neglecting target\n",
    "df1.iloc[:,:-1].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2049,
   "id": "9dbab845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace inf with nan in the dataset\n",
    "df1.replace([np.inf, -np.inf], np.nan, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2050,
   "id": "ea92fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the independent variables\n",
    "\n",
    "# Initializing Minmax scaler object\n",
    "mm_scaler = MinMaxScaler()\n",
    "\n",
    "# fitting and transforming the independent variable\n",
    "df1_scaled = mm_scaler.fit_transform(df1.iloc[:,:-1])\n",
    "\n",
    "# converting to dataframe\n",
    "df1_iv_scaled = pd.DataFrame(df1_scaled)\n",
    "df1_target = pd.DataFrame(df1.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2051,
   "id": "57342d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(326, 147)"
      ]
     },
     "execution_count": 2051,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2052,
   "id": "388f3d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concating to dataframe\n",
    "df1_scaled = pd.concat([df1_iv_scaled,df1_target],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2053,
   "id": "928ff4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the columns of dataframe\n",
    "df1_scaled.set_axis(df1_col, axis=1,inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2054,
   "id": "780ba5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating X and Y for training the model\n",
    "y = df1_scaled[\"target\"]\n",
    "X = df1_scaled.drop([\"target\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2055,
   "id": "9e61ffa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>K neighbours</th>\n",
       "      <th>Val_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.764802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.780155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.775027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.770971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.778073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>0.780155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18</td>\n",
       "      <td>0.768889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21</td>\n",
       "      <td>0.788267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   K neighbours  Val_score\n",
       "0        1       0.764802 \n",
       "1        3       0.780155 \n",
       "2        5       0.775027 \n",
       "3        7       0.770971 \n",
       "4        9       0.778073 \n",
       "5       15       0.780155 \n",
       "6       18       0.768889 \n",
       "7       21       0.788267 "
      ]
     },
     "execution_count": 2055,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the best \"k\" neighbour for imputation\n",
    "\n",
    "results = list()\n",
    "neighbours = [1,3,5,7,9,15,18,21] \n",
    "\n",
    "for k in neighbours:\n",
    "    \n",
    "    #creating pipeline to assemble the model and kneighbours\n",
    "    pipeline = Pipeline(steps=[('i', KNNImputer(n_neighbors=int(k))), ('m', RandomForestClassifier())])\n",
    "    \n",
    "    #Kfold cross validation with different k values\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "    #scores of cross validation for different k's\n",
    "    scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    \n",
    "    #appending the results to a list\n",
    "    results.append(np.mean(scores))\n",
    "    \n",
    "# converting to dataframe    \n",
    "res = list(zip(neighbours, results))\n",
    "df = pd.DataFrame(res, columns=['K neighbours', 'Val_score'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7700c7",
   "metadata": {},
   "source": [
    "* We dont see much difference in val_score with different k neighbours.We will choose \"3\" as our Neighbour search for missing value impuatation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2056,
   "id": "9654bff1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lets impute the missing values using 3 neighbours\n",
    "\n",
    "# initializing the imputer object\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "# fit the imputer object on the dataset\n",
    "imputer.fit(X)\n",
    "\n",
    "# transform the dataset\n",
    "Xtrans = imputer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2057,
   "id": "209a4155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized values and knn imputed converted to dataframe\n",
    "df1_scaled_imputed = pd.DataFrame(Xtrans)  \n",
    "df1_target = pd.DataFrame(df1.iloc[:,-1])\n",
    "df1_imputed = pd.concat([df1_scaled_imputed,df1_target],axis=1)\n",
    "df1_imputed.set_axis(df1_col, axis=1,inplace=True)\n",
    "df1_imputed.to_csv(\"Null Variables dropped Normalized and Knn_imputed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2058,
   "id": "51871b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denormalizing the imputed values into original scale and converting to dataframe \n",
    "df1_train_descaled = pd.DataFrame(mm_scaler.inverse_transform(Xtrans))\n",
    "df1_train_descaled = pd.concat([df1_train_descaled,df1_target],axis=1)\n",
    "df1_train_descaled.set_axis(df1_col, axis=1,inplace=True)\n",
    "df1_train_descaled.to_csv(\"Null Variables dropped denormalized and Knn_imputed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2059,
   "id": "0df137ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>M6</th>\n",
       "      <th>M7</th>\n",
       "      <th>M8</th>\n",
       "      <th>M9</th>\n",
       "      <th>M10</th>\n",
       "      <th>M11</th>\n",
       "      <th>M12</th>\n",
       "      <th>M13</th>\n",
       "      <th>M14</th>\n",
       "      <th>M15</th>\n",
       "      <th>M16</th>\n",
       "      <th>M17</th>\n",
       "      <th>M18</th>\n",
       "      <th>M19</th>\n",
       "      <th>M20</th>\n",
       "      <th>M21</th>\n",
       "      <th>M22</th>\n",
       "      <th>M23</th>\n",
       "      <th>M24</th>\n",
       "      <th>M25</th>\n",
       "      <th>M26</th>\n",
       "      <th>M27</th>\n",
       "      <th>M28</th>\n",
       "      <th>M29</th>\n",
       "      <th>M30</th>\n",
       "      <th>M31</th>\n",
       "      <th>M32</th>\n",
       "      <th>M33</th>\n",
       "      <th>M34</th>\n",
       "      <th>M35</th>\n",
       "      <th>M37</th>\n",
       "      <th>M38</th>\n",
       "      <th>M39</th>\n",
       "      <th>M40</th>\n",
       "      <th>M41</th>\n",
       "      <th>M42</th>\n",
       "      <th>M43</th>\n",
       "      <th>M44</th>\n",
       "      <th>M45</th>\n",
       "      <th>M46</th>\n",
       "      <th>M47</th>\n",
       "      <th>M48</th>\n",
       "      <th>M50</th>\n",
       "      <th>M51</th>\n",
       "      <th>M52</th>\n",
       "      <th>M53</th>\n",
       "      <th>M54</th>\n",
       "      <th>M55</th>\n",
       "      <th>M56</th>\n",
       "      <th>M57</th>\n",
       "      <th>M58</th>\n",
       "      <th>M59</th>\n",
       "      <th>M60</th>\n",
       "      <th>M61</th>\n",
       "      <th>M62</th>\n",
       "      <th>M63</th>\n",
       "      <th>M64</th>\n",
       "      <th>M65</th>\n",
       "      <th>M66</th>\n",
       "      <th>M67</th>\n",
       "      <th>M68</th>\n",
       "      <th>M69</th>\n",
       "      <th>M70</th>\n",
       "      <th>M71</th>\n",
       "      <th>M73</th>\n",
       "      <th>M74</th>\n",
       "      <th>M75</th>\n",
       "      <th>M76</th>\n",
       "      <th>M77</th>\n",
       "      <th>M78</th>\n",
       "      <th>M79</th>\n",
       "      <th>M80</th>\n",
       "      <th>M81</th>\n",
       "      <th>M82</th>\n",
       "      <th>M83</th>\n",
       "      <th>M84</th>\n",
       "      <th>M85</th>\n",
       "      <th>M86</th>\n",
       "      <th>M87</th>\n",
       "      <th>M88</th>\n",
       "      <th>M89</th>\n",
       "      <th>M90</th>\n",
       "      <th>M91</th>\n",
       "      <th>M92</th>\n",
       "      <th>M93</th>\n",
       "      <th>M94</th>\n",
       "      <th>M95</th>\n",
       "      <th>M96</th>\n",
       "      <th>M97</th>\n",
       "      <th>M98</th>\n",
       "      <th>M99</th>\n",
       "      <th>M100</th>\n",
       "      <th>M101</th>\n",
       "      <th>M102</th>\n",
       "      <th>M103</th>\n",
       "      <th>M104</th>\n",
       "      <th>M105</th>\n",
       "      <th>M106</th>\n",
       "      <th>M107</th>\n",
       "      <th>M108</th>\n",
       "      <th>M109</th>\n",
       "      <th>M110</th>\n",
       "      <th>M111</th>\n",
       "      <th>M112</th>\n",
       "      <th>M113</th>\n",
       "      <th>M114</th>\n",
       "      <th>M115</th>\n",
       "      <th>M116</th>\n",
       "      <th>M117</th>\n",
       "      <th>M118</th>\n",
       "      <th>M119</th>\n",
       "      <th>M120</th>\n",
       "      <th>M121</th>\n",
       "      <th>M122</th>\n",
       "      <th>M123</th>\n",
       "      <th>M124</th>\n",
       "      <th>M125</th>\n",
       "      <th>M126</th>\n",
       "      <th>M127</th>\n",
       "      <th>M128</th>\n",
       "      <th>M129</th>\n",
       "      <th>M130</th>\n",
       "      <th>M131</th>\n",
       "      <th>M132</th>\n",
       "      <th>M133</th>\n",
       "      <th>M134</th>\n",
       "      <th>M135</th>\n",
       "      <th>M136</th>\n",
       "      <th>M137</th>\n",
       "      <th>M138</th>\n",
       "      <th>M139</th>\n",
       "      <th>M140</th>\n",
       "      <th>M141</th>\n",
       "      <th>M142</th>\n",
       "      <th>M143</th>\n",
       "      <th>M144</th>\n",
       "      <th>M145</th>\n",
       "      <th>M146</th>\n",
       "      <th>M147</th>\n",
       "      <th>M148</th>\n",
       "      <th>M149</th>\n",
       "      <th>M150</th>\n",
       "      <th>M151</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.240789e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.142857</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>2.387105</td>\n",
       "      <td>5.720456e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>651246451.0</td>\n",
       "      <td>65792507.0</td>\n",
       "      <td>1.430925e+09</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>6.285714</td>\n",
       "      <td>2.285474e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>2.910818e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.700000e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.358491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.278607e+08</td>\n",
       "      <td>1000979.0</td>\n",
       "      <td>2.773771e+17</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.040450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000e+06</td>\n",
       "      <td>4.709144e+08</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.594152e+07</td>\n",
       "      <td>1.934286e+08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119903530.0</td>\n",
       "      <td>1045041.0</td>\n",
       "      <td>1.646418e+08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1.002027e+09</td>\n",
       "      <td>63.619048</td>\n",
       "      <td>829863679.0</td>\n",
       "      <td>5.169929e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2561926.0</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>1.168908e+08</td>\n",
       "      <td>4.476974e+14</td>\n",
       "      <td>-7.800000e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-4.826130e+07</td>\n",
       "      <td>850824335.0</td>\n",
       "      <td>25859.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>22269145.0</td>\n",
       "      <td>1.203129e+09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.229919e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>250420668.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.049770e+07</td>\n",
       "      <td>1.931810e+16</td>\n",
       "      <td>596624.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>7.560272e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1000979.0</td>\n",
       "      <td>5.078871e-02</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>3.901621e+06</td>\n",
       "      <td>12333435.0</td>\n",
       "      <td>2.970188e+08</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>3.875934e+07</td>\n",
       "      <td>2.901706e+17</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.144689e+08</td>\n",
       "      <td>1.504233e+07</td>\n",
       "      <td>2.532710e+08</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>9.225540e+07</td>\n",
       "      <td>3.051623e+08</td>\n",
       "      <td>3.765203e+05</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>6.938591e+07</td>\n",
       "      <td>1.842534e+08</td>\n",
       "      <td>2.107143</td>\n",
       "      <td>1.249568e+08</td>\n",
       "      <td>7383944.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.824199e+08</td>\n",
       "      <td>2.767568</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>265529069.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.636035e+06</td>\n",
       "      <td>4299092.0</td>\n",
       "      <td>61656900.5</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>112896975.0</td>\n",
       "      <td>3.306454e+05</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>5.943793e+06</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.137554</td>\n",
       "      <td>0.673176</td>\n",
       "      <td>8.426000</td>\n",
       "      <td>0.914831</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.454261e+06</td>\n",
       "      <td>6138990.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.029878</td>\n",
       "      <td>1.694720e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>402015474.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.112340e+08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>8.080173e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.234333e+07</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.391304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.199603e+07</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>1.079069e+12</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.803985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.332033e+08</td>\n",
       "      <td>1.221445e+06</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.887793e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76967931.0</td>\n",
       "      <td>1509417.0</td>\n",
       "      <td>1.303709e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>3228097.0</td>\n",
       "      <td>1.482683e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1885318.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.906536e+06</td>\n",
       "      <td>1.536911e+15</td>\n",
       "      <td>-5.608099e+07</td>\n",
       "      <td>4.761905e+05</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.317400e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60744214.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.852903e+08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.611567e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>5303368.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>2.760024e+06</td>\n",
       "      <td>1.246726e+16</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>9.523538e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1240690.0</td>\n",
       "      <td>5.242413e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.950768e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.341153e+07</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>7.594195e+07</td>\n",
       "      <td>1.786641e+16</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.026874e+07</td>\n",
       "      <td>1.073313e+07</td>\n",
       "      <td>5.213575e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>5.129105e+06</td>\n",
       "      <td>1.682865e+07</td>\n",
       "      <td>2.557691e+07</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>2.879922e+06</td>\n",
       "      <td>1.023804e+07</td>\n",
       "      <td>1.783784</td>\n",
       "      <td>1.077655e+07</td>\n",
       "      <td>22135868.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2.322849e+07</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>58451772.0</td>\n",
       "      <td>1.462500</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>5.845177e+07</td>\n",
       "      <td>77572353.0</td>\n",
       "      <td>3115525.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.694206e+06</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>4.264630e+06</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.940661</td>\n",
       "      <td>2.000506</td>\n",
       "      <td>0.656152</td>\n",
       "      <td>1.016467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.359738e+07</td>\n",
       "      <td>1272552.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.103578</td>\n",
       "      <td>1.852271e+07</td>\n",
       "      <td>16.0</td>\n",
       "      <td>124910611.0</td>\n",
       "      <td>44371332.0</td>\n",
       "      <td>5.518678e+08</td>\n",
       "      <td>12.142857</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>1.918874e+07</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>3.017980e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.616667e+06</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.582734</td>\n",
       "      <td>1542674.0</td>\n",
       "      <td>4.246794e+06</td>\n",
       "      <td>83612.0</td>\n",
       "      <td>1.670457e+15</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.181445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-8.140667e+06</td>\n",
       "      <td>2.979856e+06</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.806219e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30856358.0</td>\n",
       "      <td>424182.0</td>\n",
       "      <td>4.291304e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.366557e+07</td>\n",
       "      <td>45.809524</td>\n",
       "      <td>166079328.0</td>\n",
       "      <td>3.245014e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1887248.0</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>8.836247e+05</td>\n",
       "      <td>3.481712e+12</td>\n",
       "      <td>-1.821839e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-1.120641e+07</td>\n",
       "      <td>39115783.0</td>\n",
       "      <td>1892955.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>21299777.0</td>\n",
       "      <td>9.205353e+07</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.160983e+07</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1204331.0</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>3.877527e+07</td>\n",
       "      <td>1.635350e+15</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>3.857127e+07</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>83612.0</td>\n",
       "      <td>9.469418e-01</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.522318e+06</td>\n",
       "      <td>1531113.0</td>\n",
       "      <td>1.643879e+07</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.753703e+07</td>\n",
       "      <td>1.903991e+14</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.044444</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.880631e+07</td>\n",
       "      <td>1.803011e+07</td>\n",
       "      <td>3.397465e+07</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>4.851505e+06</td>\n",
       "      <td>2.532838e+07</td>\n",
       "      <td>1.625583e+07</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>4.013703e+07</td>\n",
       "      <td>3.549669e+06</td>\n",
       "      <td>5.407407</td>\n",
       "      <td>1.415032e+07</td>\n",
       "      <td>48455690.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.142857</td>\n",
       "      <td>1.144816e+07</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>2601462.0</td>\n",
       "      <td>15.207977</td>\n",
       "      <td>6.142857</td>\n",
       "      <td>2.601462e+06</td>\n",
       "      <td>4373831.0</td>\n",
       "      <td>5132224.5</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1639704.0</td>\n",
       "      <td>4.640223e+06</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>9.142857</td>\n",
       "      <td>1.321201e+07</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.007713</td>\n",
       "      <td>0.502552</td>\n",
       "      <td>1.157555</td>\n",
       "      <td>0.988912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.243215e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>10.714286</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.050155e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1362655.0</td>\n",
       "      <td>231557103.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.428571</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.661335e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.824500e+08</td>\n",
       "      <td>52564750.0</td>\n",
       "      <td>7.540000e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.570909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.375040e+07</td>\n",
       "      <td>825784.0</td>\n",
       "      <td>3.538264e+16</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>1.015880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400000e+08</td>\n",
       "      <td>1.446328e+06</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.289131e+07</td>\n",
       "      <td>8.285714e+06</td>\n",
       "      <td>8.0</td>\n",
       "      <td>375228605.0</td>\n",
       "      <td>992655.0</td>\n",
       "      <td>3.364729e+05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.053503e+08</td>\n",
       "      <td>745.066667</td>\n",
       "      <td>961740449.0</td>\n",
       "      <td>8.779180e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.714286</td>\n",
       "      <td>-1.147068e+07</td>\n",
       "      <td>8.827755e+15</td>\n",
       "      <td>-7.543467e+07</td>\n",
       "      <td>3.428571e+07</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.509527e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>356689731.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>6.285714</td>\n",
       "      <td>402269314.0</td>\n",
       "      <td>1.720669e+08</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1.035969e+06</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>280752742.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.861510e+08</td>\n",
       "      <td>5.975882e+11</td>\n",
       "      <td>-3463893.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.142857</td>\n",
       "      <td>1.054106e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>825784.0</td>\n",
       "      <td>3.317987e-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.985428e+08</td>\n",
       "      <td>365870082.0</td>\n",
       "      <td>9.647028e+07</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.547249e+12</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.120377e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.635622e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.569189e+08</td>\n",
       "      <td>3.861157e+05</td>\n",
       "      <td>5.221550e+05</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.007674e+08</td>\n",
       "      <td>2.398642e+08</td>\n",
       "      <td>11.232558</td>\n",
       "      <td>2.332816e+08</td>\n",
       "      <td>702263143.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.180810e+08</td>\n",
       "      <td>0.634589</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>387362557.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>2.503747e+07</td>\n",
       "      <td>209680005.0</td>\n",
       "      <td>117190720.0</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.857143</td>\n",
       "      <td>342582008.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.029361e+08</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.504471</td>\n",
       "      <td>2.827495</td>\n",
       "      <td>0.670929</td>\n",
       "      <td>0.483688</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.892245e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.347021e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400018121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.800000e+06</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.871429e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.101114e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.912100e+04</td>\n",
       "      <td>54821.0</td>\n",
       "      <td>1.008468e+15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.559125</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.500000e+07</td>\n",
       "      <td>1.236488e+07</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.013714e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5787060.0</td>\n",
       "      <td>3936371.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>16254955.0</td>\n",
       "      <td>3.721497e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1786609.0</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1.504529e+07</td>\n",
       "      <td>1.423000e+13</td>\n",
       "      <td>-4.000000e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.818941e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>17618015.0</td>\n",
       "      <td>4.054821e+06</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1435898.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.137634e+06</td>\n",
       "      <td>3.002813e+14</td>\n",
       "      <td>14300.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>3.691210e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>54821.0</td>\n",
       "      <td>2.339467e+00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.180532e+06</td>\n",
       "      <td>1185898.0</td>\n",
       "      <td>2.821947e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.873712e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.020590e+07</td>\n",
       "      <td>7.881900e+06</td>\n",
       "      <td>7.633217e+07</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2.095534e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.480881e+06</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>2.139076e+06</td>\n",
       "      <td>2.545055e+06</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>8.719328e+06</td>\n",
       "      <td>1400447.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>2.051488e+06</td>\n",
       "      <td>4.843137</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>3435898.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.339770e+06</td>\n",
       "      <td>1042936.0</td>\n",
       "      <td>3049821.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.154725e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.230383e+06</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2815.070183</td>\n",
       "      <td>0.580685</td>\n",
       "      <td>1.313392</td>\n",
       "      <td>0.600029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        M1          M2      M3      M4        M6         M7          M8        M9       M10          M11           M12         M13      M14  M15     M16     M17     M18        M19          M20      M21     M22         M23          M24          M25      M26  M27     M28       M29          M30         M31     \\\n",
       "0  2.240789e+08        0.0  0.0  8.142857   2.857143  2.387105  5.720456e+07   0.0  651246451.0   65792507.0  1.430925e+09   5.000000  15.0  0.0  0.571429   6.0   5.285714   6.285714  2.285474e+07  0.0  1.142857  2.910818e+07         0.0  4.700000e+07  1.0  1.0  2.358491        0.0  1.278607e+08  1000979.0   \n",
       "1  5.454261e+06  6138990.0  0.0  5.142857   0.285714  1.029878  1.694720e+08   0.0  402015474.0          0.0  0.000000e+00   7.142857  22.0  4.0  0.714286   9.0   2.142857   3.000000  2.112340e+08  1.0  0.571429  8.080173e+06         0.0  1.234333e+07  4.0  0.0  3.391304        0.0  2.199603e+07  1000000.0   \n",
       "2  2.359738e+07  1272552.0  0.0  3.428571   4.000000  1.103578  1.852271e+07  16.0  124910611.0   44371332.0  5.518678e+08  12.142857  28.0  0.0  1.857143  28.0   1.571429   1.285714  1.918874e+07  3.0  1.142857  3.017980e+06         0.0  3.616667e+06  9.0  3.0  0.582734  1542674.0  4.246794e+06    83612.0   \n",
       "3  2.243215e+08        0.0  0.0  3.285714  10.714286  0.333333  1.050155e+06   0.0    1362655.0  231557103.0  0.000000e+00   8.428571   3.0  1.0  0.285714  24.0  13.000000  12.000000  4.661335e+06  0.0  0.285714  1.824500e+08  52564750.0  7.540000e+07  0.0  0.0  0.570909        0.0  6.375040e+07   825784.0   \n",
       "4  6.892245e+07        0.0  0.0  3.285714   1.857143  0.000000  3.347021e+07   0.0  400018121.0          0.0  1.800000e+06   0.428571   2.0  0.0  0.000000   4.0   5.857143   2.142857  2.871429e+05  0.0  0.000000  2.101114e+06         0.0  3.000000e+07  0.0  0.0  6.909091        0.0  6.912100e+04    54821.0   \n",
       "\n",
       "        M32         M33        M34       M35       M37    M38       M39           M40         M41        M42      M43   M44       M45           M46      M47      M48         M50          M51      M52     M53         M54          M55         M56           M57      M58     M59        M60          M61           M62      \\\n",
       "0  2.773771e+17   1.500000  0.040450  0.000000  0.142857  1.0  4.000000e+06  4.709144e+08   3.333333  18.000000  11.0   6.0  9.594152e+07  1.934286e+08  1.0  119903530.0  1045041.0  1.646418e+08  3.0  7.500000  1.002027e+09   63.619048  829863679.0  5.169929e+07  0.0  2561926.0   2.714286  1.168908e+08  4.476974e+14   \n",
       "1  1.079069e+12   0.833333  1.803985  0.000000  0.285714  0.0  2.332033e+08  1.221445e+06  24.000000  34.000000   9.0   8.0  4.887793e+06  0.000000e+00  0.0   76967931.0  1509417.0  1.303709e+08  0.0  1.666667  0.000000e+00   10.333333    3228097.0  1.482683e+07  1.0  1885318.0   0.285714  1.906536e+06  1.536911e+15   \n",
       "2  1.670457e+15   2.666667  1.181445  0.000000  4.285714  6.0 -8.140667e+06  2.979856e+06   5.000000  16.000000   9.0  10.0  6.806219e+07  0.000000e+00  0.0   30856358.0   424182.0  4.291304e+06  0.0  0.066667  1.366557e+07   45.809524  166079328.0  3.245014e+07  0.0  1887248.0   4.285714  8.836247e+05  3.481712e+12   \n",
       "3  3.538264e+16  12.500000  1.015880  0.000000  0.000000  0.0  2.400000e+08  1.446328e+06   2.333333   2.000000   7.0   5.0  4.289131e+07  8.285714e+06  8.0  375228605.0   992655.0  3.364729e+05  2.0  0.200000  1.053503e+08  745.066667  961740449.0  8.779180e+07  0.0        0.0  10.714286 -1.147068e+07  8.827755e+15   \n",
       "4  1.008468e+15   0.000000  5.559125  0.666667  0.000000  0.0 -2.500000e+07  1.236488e+07   2.666667   1.666667   3.0   2.0  4.013714e+06  0.000000e+00  0.0    5787060.0  3936371.0  0.000000e+00  0.0  1.000000  0.000000e+00    1.600000   16254955.0  3.721497e+06  0.0  1786609.0   1.714286  1.504529e+07  1.423000e+13   \n",
       "\n",
       "        M63           M64       M65       M66          M67          M68      M69   M70   M71  M73     M74       M75       M76        M77           M78       M79       M80         M81        M82        M83         M84         M85           M86         M87      M88     M89          M90       M91   M92     M93    \\\n",
       "0 -7.800000e+07  0.000000e+00  19.0 -4.826130e+07  850824335.0      25859.0  1.0   2.0  29.0  0.0  0.666667  1.142857  2.428571   22269145.0  1.203129e+09   3.0  2.229919e+08   1.000000  0.142857  250420668.0  0.000000  3.049770e+07  1.931810e+16   596624.0  34.0   2.857143  7.560272e+06   0.0   7.0  1.714286   \n",
       "1 -5.608099e+07  4.761905e+05  25.0  5.317400e+04          0.0   60744214.0  2.0   0.0   3.0  0.0  0.833333  1.428571  0.571429          0.0  1.852903e+08   3.0  4.611567e+05   3.000000  0.285714    5303368.0  0.285714  2.760024e+06  1.246726e+16    22000.0  80.0   1.428571  9.523538e+06   0.0  11.0  1.428571   \n",
       "2 -1.821839e+07  0.000000e+00  36.0 -1.120641e+07   39115783.0    1892955.0  1.0   6.0   1.0  3.0  7.400000  5.857143  5.857143   21299777.0  9.205353e+07   4.0  5.160983e+07  38.000000  3.000000    1204331.0  6.714286  3.877527e+07  1.635350e+15     3300.0  22.0   5.142857  3.857127e+07  10.0  10.0  3.714286   \n",
       "3 -7.543467e+07  3.428571e+07  50.0  2.509527e+07          0.0  356689731.0  1.0  10.0  10.0  1.0  0.666667  7.571429  6.285714  402269314.0  1.720669e+08  11.5  1.035969e+06   0.333333  0.000000  280752742.0  0.000000  4.861510e+08  5.975882e+11 -3463893.0  22.0  11.142857  1.054106e+06   0.0   1.0  9.000000   \n",
       "4 -4.000000e+06  0.000000e+00  10.0  6.818941e+07          0.0          0.0  2.0   0.0   7.0  0.0  0.388889  0.571429  0.285714   17618015.0  4.054821e+06   0.5  0.000000e+00   1.000000  0.285714    1435898.0  0.000000  1.137634e+06  3.002813e+14    14300.0  65.0   1.285714  3.691210e+05   0.0   2.0  0.285714   \n",
       "\n",
       "      M94          M95         M96         M97          M98           M99        M100        M101          M102        M103      M104      M105     M106    M107       M108      M109        M110          M111          M112        M113       M114        M115          M116          M117        M118        M119      \\\n",
       "0  1000979.0  5.078871e-02  0.788889  3.901621e+06   12333435.0  2.970188e+08  0.428571  3.875934e+07  2.901706e+17  0.500000  1.571429   2.000000   0.0   0.666667  0.500000  1.000000  1.144689e+08  1.504233e+07  2.532710e+08  13.000000  1.714286  9.225540e+07  3.051623e+08  3.765203e+05  2.142857  6.938591e+07   \n",
       "1  1240690.0  5.242413e-01  1.000000  5.950768e+06          0.0  1.341153e+07  0.285714  7.594195e+07  1.786641e+16  1.500000  1.000000   1.142857   0.0   0.566667  1.000000  0.000000  1.026874e+07  1.073313e+07  5.213575e+07  10.000000  0.857143  5.129105e+06  1.682865e+07  2.557691e+07  0.285714  2.879922e+06   \n",
       "2    83612.0  9.469418e-01  6.000000  1.522318e+06    1531113.0  1.643879e+07  5.000000  1.753703e+07  1.903991e+14  7.600000  3.857143  10.500000   3.0  26.044444  5.000000  6.000000  1.880631e+07  1.803011e+07  3.397465e+07  34.000000  7.571429  4.851505e+06  2.532838e+07  1.625583e+07  3.857143  4.013703e+07   \n",
       "3   825784.0  3.317987e-08  1.000000  1.985428e+08  365870082.0  9.647028e+07  0.142857  0.000000e+00  9.547249e+12  0.800000  3.142857   8.200000   1.0   0.333333  1.000000  0.833333  2.120377e+08  0.000000e+00  3.635622e+06   1.000000  8.000000  4.569189e+08  3.861157e+05  5.221550e+05  8.000000  4.007674e+08   \n",
       "4    54821.0  2.339467e+00  0.333333  1.180532e+06    1185898.0  2.821947e+06  0.000000  1.873712e+07  0.000000e+00  1.166667  0.428571   0.333333   0.0   0.388889  0.833333  0.500000  7.020590e+07  7.881900e+06  7.633217e+07   1.666667  0.428571  2.095534e+06  0.000000e+00  3.480881e+06  0.714286  2.139076e+06   \n",
       "\n",
       "       M120        M121         M122         M123      M124    M125        M126        M127    M128  M129  M130    M131       M132        M133       M134        M135         M136         M137        M138      M139      M140       M141          M142        M143      M144        M145        M146     M147     M148      \\\n",
       "0  1.842534e+08   2.107143  1.249568e+08    7383944.0   6.0  0.000000  2.824199e+08  2.767568   2.0   0.0   0.0  3.571429  265529069.0   0.571429  0.000000  1.636035e+06    4299092.0   61656900.5  2.285714  1.285714  2.000000  112896975.0  3.306454e+05  0.142857  1.428571  5.943793e+06   3.714286   8.0     1.137554   \n",
       "1  1.023804e+07   1.783784  1.077655e+07   22135868.0   1.0  0.428571  2.322849e+07  3.300000   0.0   1.0   0.0  0.428571   58451772.0   1.462500  1.428571  5.845177e+07   77572353.0    3115525.0  0.285714  0.000000  0.142857          0.0  2.694206e+06  0.285714  1.285714  4.264630e+06   2.600000  10.0     0.940661   \n",
       "2  3.549669e+06   5.407407  1.415032e+07   48455690.0   0.0  6.142857  1.144816e+07  0.432432   9.0   7.0   0.0  2.857143    2601462.0  15.207977  6.142857  2.601462e+06    4373831.0    5132224.5  4.142857  7.285714  6.000000    1639704.0  4.640223e+06  6.714286  9.142857  1.321201e+07   6.500000  13.0     1.007713   \n",
       "3  2.398642e+08  11.232558  2.332816e+08  702263143.0  12.0  0.000000  1.180810e+08  0.634589  12.0   0.0   0.0  7.714286  387362557.5   0.500000  0.142857  2.503747e+07  209680005.0  117190720.0  7.714286  7.000000  8.857143  342582008.0  0.000000e+00  0.000000  6.000000  7.029361e+08  11.500000   0.0     1.504471   \n",
       "4  2.545055e+06   0.640000  8.719328e+06    1400447.0  20.0  0.142857  2.051488e+06  4.843137   1.0   1.0   0.0  0.571429    3435898.0   0.250000  0.000000  4.339770e+06    1042936.0    3049821.0  0.714286  0.142857  0.285714          0.0  7.154725e+07  0.000000  0.142857  1.230383e+06   0.833333   2.0  2815.070183   \n",
       "\n",
       "     M149      M150      M151    target  \n",
       "0  0.673176  8.426000  0.914831     0    \n",
       "1  2.000506  0.656152  1.016467     1    \n",
       "2  0.502552  1.157555  0.988912     0    \n",
       "3  2.827495  0.670929  0.483688     0    \n",
       "4  0.580685  1.313392  0.600029     1    "
      ]
     },
     "execution_count": 2059,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the denormalized values to check if its matching with original values\n",
    "df1_train_descaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2060,
   "id": "c7a12a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the validation data file provided\n",
    "df1_valid = pd.read_csv(\"Test_data_Jenfi_assessment_070423.csv\")\n",
    "\n",
    "# dropping variables which we dropped on train data\n",
    "df1_valid.drop(['M5', 'M36', 'M49', 'M72',\"Unnamed: 0\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2061,
   "id": "6aaaf269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing target variable from validation data in a variable\n",
    "df1_valid_target = df1_valid.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2062,
   "id": "1b764f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace inf with nan to overcome errors\n",
    "df1_valid.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2063,
   "id": "aef7f217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the dataset, only transforming because we will use the same fit of train data\n",
    "df1_valid_norm = mm_scaler.transform(df1_valid.iloc[:,:-1])\n",
    "\n",
    "# imputing the validation dataset\n",
    "Xtrans_valid = imputer.transform(df1_valid_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2064,
   "id": "5b25aae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 147)"
      ]
     },
     "execution_count": 2064,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_valid.iloc[:,:-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2065,
   "id": "62bd3e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing column names of validation data in a variable\n",
    "df1_valid_col = df1_valid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2066,
   "id": "e7b2b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# denormalizing the validation data and saving it as dataframe\n",
    "df1_valid_descaled = pd.DataFrame(mm_scaler.inverse_transform(Xtrans_valid))\n",
    "df1_valid_descaled = pd.concat([df1_valid_descaled,df1_valid_target],axis=1)\n",
    "df1_valid_descaled.set_axis(df1_valid_col, axis=1,inplace=True)\n",
    "df1_valid_descaled.to_csv(\"validation Null Variables dropped denormalized and Knn_imputed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2067,
   "id": "66e725e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>M6</th>\n",
       "      <th>M7</th>\n",
       "      <th>M8</th>\n",
       "      <th>M9</th>\n",
       "      <th>M10</th>\n",
       "      <th>M11</th>\n",
       "      <th>M12</th>\n",
       "      <th>M13</th>\n",
       "      <th>M14</th>\n",
       "      <th>M15</th>\n",
       "      <th>M16</th>\n",
       "      <th>M17</th>\n",
       "      <th>M18</th>\n",
       "      <th>M19</th>\n",
       "      <th>M20</th>\n",
       "      <th>M21</th>\n",
       "      <th>M22</th>\n",
       "      <th>M23</th>\n",
       "      <th>M24</th>\n",
       "      <th>M25</th>\n",
       "      <th>M26</th>\n",
       "      <th>M27</th>\n",
       "      <th>M28</th>\n",
       "      <th>M29</th>\n",
       "      <th>M30</th>\n",
       "      <th>M31</th>\n",
       "      <th>M32</th>\n",
       "      <th>M33</th>\n",
       "      <th>M34</th>\n",
       "      <th>M35</th>\n",
       "      <th>M37</th>\n",
       "      <th>M38</th>\n",
       "      <th>M39</th>\n",
       "      <th>M40</th>\n",
       "      <th>M41</th>\n",
       "      <th>M42</th>\n",
       "      <th>M43</th>\n",
       "      <th>M44</th>\n",
       "      <th>M45</th>\n",
       "      <th>M46</th>\n",
       "      <th>M47</th>\n",
       "      <th>M48</th>\n",
       "      <th>M50</th>\n",
       "      <th>M51</th>\n",
       "      <th>M52</th>\n",
       "      <th>M53</th>\n",
       "      <th>M54</th>\n",
       "      <th>M55</th>\n",
       "      <th>M56</th>\n",
       "      <th>M57</th>\n",
       "      <th>M58</th>\n",
       "      <th>M59</th>\n",
       "      <th>M60</th>\n",
       "      <th>M61</th>\n",
       "      <th>M62</th>\n",
       "      <th>M63</th>\n",
       "      <th>M64</th>\n",
       "      <th>M65</th>\n",
       "      <th>M66</th>\n",
       "      <th>M67</th>\n",
       "      <th>M68</th>\n",
       "      <th>M69</th>\n",
       "      <th>M70</th>\n",
       "      <th>M71</th>\n",
       "      <th>M73</th>\n",
       "      <th>M74</th>\n",
       "      <th>M75</th>\n",
       "      <th>M76</th>\n",
       "      <th>M77</th>\n",
       "      <th>M78</th>\n",
       "      <th>M79</th>\n",
       "      <th>M80</th>\n",
       "      <th>M81</th>\n",
       "      <th>M82</th>\n",
       "      <th>M83</th>\n",
       "      <th>M84</th>\n",
       "      <th>M85</th>\n",
       "      <th>M86</th>\n",
       "      <th>M87</th>\n",
       "      <th>M88</th>\n",
       "      <th>M89</th>\n",
       "      <th>M90</th>\n",
       "      <th>M91</th>\n",
       "      <th>M92</th>\n",
       "      <th>M93</th>\n",
       "      <th>M94</th>\n",
       "      <th>M95</th>\n",
       "      <th>M96</th>\n",
       "      <th>M97</th>\n",
       "      <th>M98</th>\n",
       "      <th>M99</th>\n",
       "      <th>M100</th>\n",
       "      <th>M101</th>\n",
       "      <th>M102</th>\n",
       "      <th>M103</th>\n",
       "      <th>M104</th>\n",
       "      <th>M105</th>\n",
       "      <th>M106</th>\n",
       "      <th>M107</th>\n",
       "      <th>M108</th>\n",
       "      <th>M109</th>\n",
       "      <th>M110</th>\n",
       "      <th>M111</th>\n",
       "      <th>M112</th>\n",
       "      <th>M113</th>\n",
       "      <th>M114</th>\n",
       "      <th>M115</th>\n",
       "      <th>M116</th>\n",
       "      <th>M117</th>\n",
       "      <th>M118</th>\n",
       "      <th>M119</th>\n",
       "      <th>M120</th>\n",
       "      <th>M121</th>\n",
       "      <th>M122</th>\n",
       "      <th>M123</th>\n",
       "      <th>M124</th>\n",
       "      <th>M125</th>\n",
       "      <th>M126</th>\n",
       "      <th>M127</th>\n",
       "      <th>M128</th>\n",
       "      <th>M129</th>\n",
       "      <th>M130</th>\n",
       "      <th>M131</th>\n",
       "      <th>M132</th>\n",
       "      <th>M133</th>\n",
       "      <th>M134</th>\n",
       "      <th>M135</th>\n",
       "      <th>M136</th>\n",
       "      <th>M137</th>\n",
       "      <th>M138</th>\n",
       "      <th>M139</th>\n",
       "      <th>M140</th>\n",
       "      <th>M141</th>\n",
       "      <th>M142</th>\n",
       "      <th>M143</th>\n",
       "      <th>M144</th>\n",
       "      <th>M145</th>\n",
       "      <th>M146</th>\n",
       "      <th>M147</th>\n",
       "      <th>M148</th>\n",
       "      <th>M149</th>\n",
       "      <th>M150</th>\n",
       "      <th>M151</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.728364e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.399986e+06</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>6.571429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.774900e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.277520e+05</td>\n",
       "      <td>10853006.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.428571</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.378666e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.200000e+06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.159180e+05</td>\n",
       "      <td>42017.0</td>\n",
       "      <td>5.853168e+13</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.595393</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.953333e+08</td>\n",
       "      <td>1.516624e+06</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.018036e+07</td>\n",
       "      <td>4.714286e+06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.614815e+07</td>\n",
       "      <td>27746.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.571429</td>\n",
       "      <td>6086005.0</td>\n",
       "      <td>2.128075e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.206034e+07</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>-6.443362e+06</td>\n",
       "      <td>2.177592e+13</td>\n",
       "      <td>-2.632097e+05</td>\n",
       "      <td>1.671429e+07</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.567143e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59235606.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>788860.0</td>\n",
       "      <td>90840.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.707757e+07</td>\n",
       "      <td>1.697259e+15</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>28775.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>42017.0</td>\n",
       "      <td>0.662103</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.961312e+06</td>\n",
       "      <td>9033544.0</td>\n",
       "      <td>8.408577e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.430042e+14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.796102e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.877500e+04</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.626117e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>1.619399e+07</td>\n",
       "      <td>3.215477e+06</td>\n",
       "      <td>4.442623</td>\n",
       "      <td>1.495751e+07</td>\n",
       "      <td>4747051.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.856550e+06</td>\n",
       "      <td>1.665730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>4665875.0</td>\n",
       "      <td>116433433.0</td>\n",
       "      <td>1.996006e+06</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>5.551383e+06</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.032424</td>\n",
       "      <td>0.732185</td>\n",
       "      <td>0.985438</td>\n",
       "      <td>0.048041</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.338423e+06</td>\n",
       "      <td>1526173.0</td>\n",
       "      <td>3.899477e+07</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>1.526503</td>\n",
       "      <td>1.636418e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.368034e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.300000e+07</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.764371e+06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.803452e+06</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>5.628869e+07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.128205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.120148e+07</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>5.139768e+14</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.925216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.966667e+05</td>\n",
       "      <td>2.562371e+08</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.507640e+07</td>\n",
       "      <td>2.857143e+05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.749027e+06</td>\n",
       "      <td>1004341.0</td>\n",
       "      <td>5.966958e+06</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.066667</td>\n",
       "      <td>4601980.0</td>\n",
       "      <td>6.142857e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.284518e+06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-2.153286e+05</td>\n",
       "      <td>3.112605e+11</td>\n",
       "      <td>-1.393400e+06</td>\n",
       "      <td>1.429767e+07</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-4.652200e+04</td>\n",
       "      <td>2436229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77998964.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.618339e+06</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>2081829.0</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.435943e+06</td>\n",
       "      <td>4.479555e+13</td>\n",
       "      <td>-384.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>5195570.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.989342</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.262449e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.510695e+06</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>3.667040e+06</td>\n",
       "      <td>1.389384e+11</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.553571</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.750420e+06</td>\n",
       "      <td>1.599992e+06</td>\n",
       "      <td>1.024418e+07</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>2.819764e+06</td>\n",
       "      <td>5.955433e+06</td>\n",
       "      <td>6.962011e+06</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>2.471720e+06</td>\n",
       "      <td>1.039070e+06</td>\n",
       "      <td>1.727273</td>\n",
       "      <td>1.732082e+06</td>\n",
       "      <td>1528938.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.482270e+06</td>\n",
       "      <td>1.940000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>2476329.0</td>\n",
       "      <td>0.584980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2476329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.656758e+06</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.553804e+07</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>2.197055e+06</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.933704</td>\n",
       "      <td>0.996820</td>\n",
       "      <td>0.934458</td>\n",
       "      <td>1.034571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.778643e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.731965e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.180000e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>7.857143e+03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.296667e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.866667e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.634146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.483401e+06</td>\n",
       "      <td>1016224.0</td>\n",
       "      <td>5.155113e+15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.253068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.280000e+07</td>\n",
       "      <td>4.543338e+06</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.084429e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.674969e+09</td>\n",
       "      <td>299000.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>45029428.0</td>\n",
       "      <td>2.266667</td>\n",
       "      <td>178852812.0</td>\n",
       "      <td>8.644455e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.737371e+09</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>6.808786e+06</td>\n",
       "      <td>1.837372e+15</td>\n",
       "      <td>5.000000e+05</td>\n",
       "      <td>3.571429e+07</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-5.614219e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15755000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>81727523.0</td>\n",
       "      <td>1126224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.240086e+06</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>329428.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>6.942075e+07</td>\n",
       "      <td>2.247060e+13</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>67050631.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>1016224.0</td>\n",
       "      <td>1.353107</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6.193523e+05</td>\n",
       "      <td>30812829.0</td>\n",
       "      <td>8.002437e+07</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>4.904116e+07</td>\n",
       "      <td>2.430042e+14</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.740487e+07</td>\n",
       "      <td>4.271429e+04</td>\n",
       "      <td>3.555405e+07</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.546802e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.498000e+05</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>3.666282e+07</td>\n",
       "      <td>2.748350e+07</td>\n",
       "      <td>1.620690</td>\n",
       "      <td>1.566483e+07</td>\n",
       "      <td>6625759.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>1.126063e+06</td>\n",
       "      <td>3.616822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>20189428.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82483401.0</td>\n",
       "      <td>12136000.0</td>\n",
       "      <td>1.571156e+06</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>75512523.0</td>\n",
       "      <td>9.131163e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.070932e+07</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.685500</td>\n",
       "      <td>1.111475</td>\n",
       "      <td>0.910898</td>\n",
       "      <td>1.730498</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.036687e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>0.499681</td>\n",
       "      <td>9.079382e+07</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.140875e+08</td>\n",
       "      <td>31998505.0</td>\n",
       "      <td>5.007902e+08</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>4.640077e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.422081e+07</td>\n",
       "      <td>43854895.0</td>\n",
       "      <td>2.000000e+07</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.344681</td>\n",
       "      <td>134000132.0</td>\n",
       "      <td>8.623085e+07</td>\n",
       "      <td>2410701.0</td>\n",
       "      <td>3.171263e+15</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.379928</td>\n",
       "      <td>648.0</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.807872e+08</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.742447e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.837986e+08</td>\n",
       "      <td>1819952.0</td>\n",
       "      <td>1.593748e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>224474533.0</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>170943295.0</td>\n",
       "      <td>5.493165e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.045639e+06</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>1.043962e+06</td>\n",
       "      <td>3.894369e+15</td>\n",
       "      <td>-1.923710e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-3.126686e+07</td>\n",
       "      <td>220299381.0</td>\n",
       "      <td>174743035.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.444444</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>8.428571</td>\n",
       "      <td>216406421.0</td>\n",
       "      <td>268597320.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.432924e+07</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>5.571429</td>\n",
       "      <td>49861121.0</td>\n",
       "      <td>8.142857</td>\n",
       "      <td>1.094000e+08</td>\n",
       "      <td>6.889887e+15</td>\n",
       "      <td>-1204892.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.571429</td>\n",
       "      <td>402639612.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7753089.0</td>\n",
       "      <td>1.360041</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>6.783680e+07</td>\n",
       "      <td>183477771.0</td>\n",
       "      <td>1.418263e+08</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.517720e+08</td>\n",
       "      <td>5.484977e+15</td>\n",
       "      <td>8.166667</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>35.027778</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2.384840e+08</td>\n",
       "      <td>2.420915e+08</td>\n",
       "      <td>2.320682e+08</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.208207e+08</td>\n",
       "      <td>1.964553e+08</td>\n",
       "      <td>1.757749e+08</td>\n",
       "      <td>6.285714</td>\n",
       "      <td>1.104968e+08</td>\n",
       "      <td>1.571415e+08</td>\n",
       "      <td>8.403846</td>\n",
       "      <td>9.255668e+07</td>\n",
       "      <td>104001178.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.142857</td>\n",
       "      <td>9.670447e+07</td>\n",
       "      <td>0.414894</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>202626940.5</td>\n",
       "      <td>19.728836</td>\n",
       "      <td>6.571429</td>\n",
       "      <td>202626940.5</td>\n",
       "      <td>43366698.0</td>\n",
       "      <td>1.352885e+08</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.428571</td>\n",
       "      <td>365782641.0</td>\n",
       "      <td>1.606599e+08</td>\n",
       "      <td>8.285714</td>\n",
       "      <td>6.285714</td>\n",
       "      <td>1.237771e+08</td>\n",
       "      <td>8.166667</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.773008</td>\n",
       "      <td>2.326502</td>\n",
       "      <td>1.186048</td>\n",
       "      <td>0.923257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.713252e+07</td>\n",
       "      <td>1490847.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.386817</td>\n",
       "      <td>2.132774e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.086385e+09</td>\n",
       "      <td>8319737.0</td>\n",
       "      <td>7.630404e+09</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>43.0</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.609798e+08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>2.279258e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.010000e+08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.081633</td>\n",
       "      <td>2553609.0</td>\n",
       "      <td>1.226902e+08</td>\n",
       "      <td>870422.0</td>\n",
       "      <td>3.032327e+18</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.997680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.428859e+07</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.096504e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.042034e+08</td>\n",
       "      <td>231645.0</td>\n",
       "      <td>3.449121e+07</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1462991.0</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>16810432.0</td>\n",
       "      <td>2.542932e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.511726e+06</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>-1.285714e+05</td>\n",
       "      <td>1.353842e+14</td>\n",
       "      <td>-9.000000e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.297120e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200876544.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>439397.0</td>\n",
       "      <td>545454581.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.521633e+06</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>60058791.0</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.964446e+08</td>\n",
       "      <td>1.165138e+16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>6516087.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>1051991.0</td>\n",
       "      <td>0.984029</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.025313e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.163516e+08</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.826564e+06</td>\n",
       "      <td>1.507321e+17</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.410714</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.804674e+08</td>\n",
       "      <td>1.141999e+09</td>\n",
       "      <td>3.283688e+08</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>5.662246e+08</td>\n",
       "      <td>1.413068e+08</td>\n",
       "      <td>1.452059e+09</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.960297e+08</td>\n",
       "      <td>1.130638e+08</td>\n",
       "      <td>2.657895</td>\n",
       "      <td>1.011828e+06</td>\n",
       "      <td>5883461.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>5.026465e+07</td>\n",
       "      <td>3.123377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>82935353.0</td>\n",
       "      <td>2.183983</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>82935353.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.951991e+06</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>3782148.0</td>\n",
       "      <td>2.406444e+06</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.477728e+07</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.029067</td>\n",
       "      <td>2.423324</td>\n",
       "      <td>0.878093</td>\n",
       "      <td>1.044883</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        M1          M2           M3          M4        M6        M7          M8       M9        M10          M11          M12         M13     M14  M15     M16     M17     M18       M19         M20      M21     M22         M23          M24           M25      M26  M27     M28        M29           M30         M31     \\\n",
       "0  3.728364e+06        0.0  1.399986e+06  2.857143  6.571429  0.333333  2.774900e+04  0.0  1.277520e+05  10853006.0  0.000000e+00  2.857143   2.0  0.0  0.000000   8.0  7.428571  3.857143  0.000000e+00  0.0  0.000000  2.378666e+07          0.0  4.200000e+06  3.0  4.0  1.560000          0.0  1.159180e+05    42017.0   \n",
       "1  2.338423e+06  1526173.0  3.899477e+07  1.857143  3.428571  1.526503  1.636418e+06  0.0  2.368034e+07         0.0  6.300000e+07  0.428571   7.0  2.0  2.000000   3.0  1.285714  2.000000  8.764371e+06  2.0  2.000000  4.803452e+06  100000000.0  5.628869e+07  2.0  2.0  2.128205          0.0  8.120148e+07  1000000.0   \n",
       "2  5.778643e+07        0.0  0.000000e+00  2.000000  1.714286  0.000000  1.731965e+07  0.0  5.180000e+05         0.0  0.000000e+00  3.428571   1.0  0.0  0.000000   6.0  5.428571  2.285714  7.857143e+03  2.0  0.000000  2.296667e+08          0.0  5.866667e+07  0.0  1.0  3.634146          0.0  1.483401e+06  1016224.0   \n",
       "3  2.036687e+08        0.0  0.000000e+00  2.000000  2.714286  0.499681  9.079382e+07  9.0  5.140875e+08  31998505.0  5.007902e+08  1.428571  20.0  0.0  2.142857  21.0  3.571429  2.571429  4.640077e+07  0.0  1.000000  6.422081e+07   43854895.0  2.000000e+07  9.0  0.0  0.344681  134000132.0  8.623085e+07  2410701.0   \n",
       "4  6.713252e+07  1490847.0  0.000000e+00  2.000000  6.000000  1.386817  2.132774e+08  0.0  6.086385e+09   8319737.0  7.630404e+09  4.000000  39.0  2.0  2.428571  43.0  4.571429  6.000000  2.609798e+08  3.0  3.571429  2.279258e+07          0.0  2.010000e+08  4.0  1.0  3.081633    2553609.0  1.226902e+08   870422.0   \n",
       "\n",
       "        M32         M33       M34     M35      M37    M38       M39           M40         M41        M42      M43  M44       M45           M46      M47       M48         M50          M51         M52       M53        M54         M55         M56           M57      M58       M59         M60         M61      \\\n",
       "0  5.853168e+13  4.000000  0.595393    6.0  0.285714  0.0 -2.953333e+08  1.516624e+06   6.000000   1.666667   1.0  0.0  5.018036e+07  4.714286e+06  3.0  4.614815e+07    27746.0  0.000000e+00  1.000000  3.000000          0.0  20.571429    6086005.0  2.128075e+07  1.0  1.206034e+07  7.000000 -6.443362e+06   \n",
       "1  5.139768e+14  1.333333  0.925216    0.0  0.714286  0.0 -2.966667e+05  2.562371e+08   6.000000  32.000000   9.0  8.0  2.507640e+07  2.857143e+05  1.0  2.749027e+06  1004341.0  5.966958e+06  1.666667  2.000000          0.0  11.066667    4601980.0  6.142857e+06  0.0  1.284518e+06  4.000000 -2.153286e+05   \n",
       "2  5.155113e+15  1.000000  5.253068    0.0  0.000000  0.0 -2.280000e+07  4.543338e+06   2.666667   4.000000   0.0  4.0  7.084429e+06  0.000000e+00  1.0  1.674969e+09   299000.0  0.000000e+00  0.000000  1.666667   45029428.0   2.266667  178852812.0  8.644455e+06  1.0  1.737371e+09  1.714286  6.808786e+06   \n",
       "3  3.171263e+15  3.666667  0.379928  648.0  4.142857  7.0  0.000000e+00  1.807872e+08  15.000000  18.000000  10.0  9.0  6.742447e+07  0.000000e+00  7.0  1.837986e+08  1819952.0  1.593748e+08  1.000000  0.111111  224474533.0   7.100000  170943295.0  5.493165e+07  1.0  8.045639e+06  2.571429  1.043962e+06   \n",
       "4  3.032327e+18  1.333333  2.997680    0.0  1.571429  1.0  0.000000e+00  3.428859e+07  24.000000  69.000000  12.0  7.0  1.096504e+09  0.000000e+00  0.0  3.042034e+08   231645.0  3.449121e+07  2.000000  4.000000    1462991.0  13.600000   16810432.0  2.542932e+07  0.0  2.511726e+06  7.714286 -1.285714e+05   \n",
       "\n",
       "        M62           M63           M64       M65       M66          M67          M68      M69   M70     M71      M73     M74       M75       M76        M77          M78      M79       M80         M81        M82        M83        M84         M85           M86         M87      M88     M89        M90      M91   M92  \\\n",
       "0  2.177592e+13 -2.632097e+05  1.671429e+07   8.0 -9.567143e+04          0.0   59235606.0  0.0   0.0  40.000000   0.0  0.888889  4.857143  4.571429     788860.0      90840.0  2.0  0.000000e+00   1.333333  0.000000         0.0  0.000000  1.707757e+07  1.697259e+15    44000.0  32.0  4.571429      28775.0  0.0   1.0   \n",
       "1  3.112605e+11 -1.393400e+06  1.429767e+07   5.0 -4.652200e+04    2436229.0          0.0  0.0   0.0   9.666667   1.0  1.375000  1.285714  1.428571          0.0   77998964.0  1.5  1.618339e+06   7.000000  1.142857   2081829.0  1.428571  1.435943e+06  4.479555e+13     -384.0  65.0  0.714286    5195570.5  2.0   8.0   \n",
       "2  1.837372e+15  5.000000e+05  3.571429e+07  13.0 -5.614219e+07          0.0   15755000.0  1.0   0.0   2.000000   0.0  0.250000  3.428571  0.428571   81727523.0    1126224.0  0.0  1.240086e+06  13.000000  0.000000    329428.0  0.714286  6.942075e+07  2.247060e+13    55000.0  60.0  1.714286   67050631.0  1.0   1.0   \n",
       "3  3.894369e+15 -1.923710e+08  0.000000e+00  10.0 -3.126686e+07  220299381.0  174743035.0  0.0  10.0   9.000000  12.0  7.444444  5.714286  8.428571  216406421.0  268597320.0  9.0  8.432924e+07  52.000000  5.571429  49861121.0  8.142857  1.094000e+08  6.889887e+15 -1204892.0  18.0  6.571429  402639612.5  0.0  10.0   \n",
       "4  1.353842e+14 -9.000000e+05  0.000000e+00  19.0  2.297120e+06          0.0  200876544.0  1.0   6.0   9.000000   2.0  2.875000  1.285714  1.857143     439397.0  545454581.0  3.0  4.521633e+06  12.000000  3.571429  60058791.0  1.428571  1.964446e+08  1.165138e+16        0.0  55.0  1.285714    6516087.0  2.0  12.0   \n",
       "\n",
       "      M93       M94        M95       M96         M97          M98           M99        M100        M101          M102        M103      M104      M105    M106    M107     M108  M109      M110          M111          M112        M113       M114        M115          M116          M117        M118        M119      \\\n",
       "0  3.571429    42017.0  0.662103  0.500000  1.961312e+06    9033544.0  8.408577e+05  0.000000  0.000000e+00  2.430042e+14  1.000000  3.285714  1.833333   0.0   0.194444   0.5   1.0  2.796102e+06  0.000000e+00  2.877500e+04   1.666667  1.142857  1.626117e+07  0.000000e+00  0.000000e+00  2.142857  1.619399e+07   \n",
       "1  1.142857  1000000.0  0.989342  0.750000  1.262449e+06          0.0  1.510695e+06  0.571429  3.667040e+06  1.389384e+11  1.200000  1.714286  0.666667   2.0   2.553571   1.5   1.0  1.750420e+06  1.599992e+06  1.024418e+07  26.000000  0.571429  2.819764e+06  5.955433e+06  6.962011e+06  0.571429  2.471720e+06   \n",
       "2  2.142857  1016224.0  1.353107  0.666667  6.193523e+05   30812829.0  8.002437e+07  0.142857  4.904116e+07  2.430042e+14  1.166667  1.000000  1.500000   0.0   0.250000   0.5   0.5  5.740487e+07  4.271429e+04  3.555405e+07   1.666667  0.428571  1.546802e+07  0.000000e+00  4.498000e+05  0.285714  3.666282e+07   \n",
       "3  6.000000  7753089.0  1.360041  9.333333  6.783680e+07  183477771.0  1.418263e+08  8.000000  2.517720e+08  5.484977e+15  8.166667  7.285714  7.000000  19.0  35.027778   9.0  10.5  2.384840e+08  2.420915e+08  2.320682e+08  21.000000  8.000000  1.208207e+08  1.964553e+08  1.757749e+08  6.285714  1.104968e+08   \n",
       "4  2.714286  1051991.0  0.984029  1.666667  1.025313e+08          0.0  1.163516e+08  1.571429  2.826564e+06  1.507321e+17  2.833333  3.857143  1.600000   0.0   6.410714   2.0   1.0  8.804674e+08  1.141999e+09  3.283688e+08  42.000000  0.142857  5.662246e+08  1.413068e+08  1.452059e+09  2.000000  1.960297e+08   \n",
       "\n",
       "       M120        M121        M122         M123      M124    M125        M126        M127    M128  M129  M130    M131       M132        M133       M134       M135         M136          M137        M138      M139      M140       M141          M142        M143      M144        M145        M146    M147    M148    \\\n",
       "0  3.215477e+06  4.442623  1.495751e+07    4747051.0  21.0  0.000000  1.856550e+06  1.665730   1.0   0.0   0.0  2.428571     190000.0   0.500000  0.142857    4665875.0  116433433.0  1.996006e+06  2.142857  1.714286  5.714286          0.0  0.000000e+00  0.142857  1.714286  5.551383e+06  2.571429   1.0  1.032424   \n",
       "1  1.039070e+06  1.727273  1.732082e+06    1528938.0   0.0  1.000000  6.482270e+06  1.940000   0.0   1.0   2.0  1.428571    2476329.0   0.584980  1.000000    2476329.0          0.0  1.656758e+06  0.571429  1.285714  1.571429          0.0  1.553804e+07  0.714286  0.285714  2.197055e+06  1.500000  11.0  0.933704   \n",
       "2  2.748350e+07  1.620690  1.566483e+07    6625759.0  22.0  1.285714  1.126063e+06  3.616822   0.0   1.0   0.0  2.571429   20189428.0   0.500000  0.000000   82483401.0   12136000.0  1.571156e+06  1.285714  1.428571  0.714286   75512523.0  9.131163e+06  0.000000  1.000000  1.070932e+07  0.500000   1.0  3.685500   \n",
       "3  1.571415e+08  8.403846  9.255668e+07  104001178.0   1.0  8.142857  9.670447e+07  0.414894  11.0  13.0   7.0  8.000000  202626940.5  19.728836  6.571429  202626940.5   43366698.0  1.352885e+08  7.571429  7.000000  7.428571  365782641.0  1.606599e+08  8.285714  6.285714  1.237771e+08  8.166667  10.0  0.773008   \n",
       "4  1.130638e+08  2.657895  1.011828e+06    5883461.0   0.0  1.428571  5.026465e+07  3.123377   0.0   0.0   0.0  1.714286   82935353.0   2.183983  1.142857   82935353.0          0.0  1.951991e+06  1.428571  2.428571  1.714286    3782148.0  2.406444e+06  0.571429  1.000000  7.477728e+07  3.000000  10.0  1.029067   \n",
       "\n",
       "     M149      M150      M151    target  \n",
       "0  0.732185  0.985438  0.048041     1    \n",
       "1  0.996820  0.934458  1.034571     1    \n",
       "2  1.111475  0.910898  1.730498     1    \n",
       "3  2.326502  1.186048  0.923257     0    \n",
       "4  2.423324  0.878093  1.044883     1    "
      ]
     },
     "execution_count": 2067,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check denormalized validation data if it matches with original validation file\n",
    "df1_valid_descaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ac7470",
   "metadata": {},
   "source": [
    "### 4.CREATING USER-DEFINED FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765033ca",
   "metadata": {},
   "source": [
    "*  Creating useful functions for displaying results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2068,
   "id": "d982f2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function for classification report of different model\n",
    "\n",
    "def multiple_model(model,x_train,y_train,x_valid,y_valid):           \n",
    "\n",
    "    t_model = model.fit(x_train,y_train)\n",
    "    pred = t_model.predict(x_valid)\n",
    "\n",
    "    print(\"__\"*50)\n",
    "    print(model)\n",
    "    print(classification_report(y_valid,pred))\n",
    "    cm1= mat.confusion_matrix(y_valid,pred)\n",
    "    TN = cm1[0][0]\n",
    "    FN = cm1[1][0]\n",
    "    TP = cm1[1][1]\n",
    "    FP = cm1[0][1]\n",
    "    cm1_frame = pd.DataFrame({\"Predicted +ve [1]\":[TP,FP],\"Predicted -ve [0]\":[FN,TN]},index=[\"Actual +ve [1]\",\"Actual -ve [0]\"])\n",
    "    print(cm1_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2069,
   "id": "d3b612b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function for Voting classifier - report\n",
    "\n",
    "def voting_classifier(m1,m2,m3,x_train,y_train,x_valid,y_valid):\n",
    "\n",
    "    model1 = m1 \n",
    "    model2 = m2  \n",
    "    model3 = m3\n",
    "\n",
    "    # Define the voting classifier\n",
    "    voting_clf = VotingClassifier(estimators=[('m1', model1), ('m2', model2), ('m3', model3)], voting='soft')\n",
    "\n",
    "    # Train the voting classifier on the training data\n",
    "    voting_clf.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluate the performance of the voting classifier on the test data\n",
    "    pred = voting_clf.predict(x_valid)\n",
    "\n",
    "    print(\"Voting Classifier\")\n",
    "    print(classification_report(y_valid,pred))\n",
    "    cm2= mat.confusion_matrix(y_valid,pred)\n",
    "    TN = cm2[0][0]\n",
    "    FN = cm2[1][0]\n",
    "    TP = cm2[1][1]\n",
    "    FP = cm2[0][1]\n",
    "    cm2_frame = pd.DataFrame({\"Predicted +ve [1]\":[TP,FP],\"Predicted -ve [0]\":[FN,TN]},index=[\"Actual +ve [1]\",\"Actual -ve [0]\"] )\n",
    "    print(cm2_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2070,
   "id": "98a76fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating fuction for creating final results as dataframes\n",
    "\n",
    "# Display for multiple frame in a row\n",
    "from IPython.display import display_html\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "\n",
    "def result_frame(models,x_train,y_train,x_valid,y_valid,m1=False,m2=False,m3=False):\n",
    "    \n",
    "    # creating list to save the f1,auroc,recall,accuracy scores\n",
    "    acc_1,f_1,auroc_1,recall_1= [],[],[],[]\n",
    "    \n",
    "    acc_2,f_2,auroc_2,recall_2= [],[],[],[]\n",
    "    \n",
    "    # intializing count \n",
    "    count=0\n",
    "    \n",
    "    # iterate each model from the list\n",
    "    for model in models:\n",
    "        \n",
    "        # increasing count for each model\n",
    "        count+=1\n",
    "        \n",
    "        # setting condition to pass to else loop\n",
    "        if count<len(L2):\n",
    "\n",
    "            #training the models with train data and predicting the validation data and train data\n",
    "            t_model = model.fit(x_train,y_train)\n",
    "            \n",
    "            #predicting validation data\n",
    "            pred1 = t_model.predict(x_valid)\n",
    "            \n",
    "            #predicting train data\n",
    "            pred_t = t_model.predict(x_train) \n",
    "\n",
    "            #calculate accuracy score of the model in prediction class 1 - validation data and train data\n",
    "            acc = accuracy_score(y_valid,pred1)\n",
    "            acc_1.append(acc)\n",
    "            \n",
    "            acc_t = accuracy_score(y_train,pred_t)\n",
    "            acc_2.append(acc_t)\n",
    "                \n",
    "            #calculate f1 score of the model in predicting class 1 - validation data and train data\n",
    "            f1 = f1_score(y_valid,pred1)\n",
    "            f_1.append(f1)\n",
    "            \n",
    "            f1_t = f1_score(y_train,pred_t)\n",
    "            f_2.append(f1_t)\n",
    "                 \n",
    "            #calculate auroc score the model in predicting class 1 - validation data and train data\n",
    "            auroc = roc_auc_score(y_valid,pred1)\n",
    "            auroc_1.append(auroc)\n",
    "            \n",
    "            auroc_t = roc_auc_score(y_train,pred_t)\n",
    "            auroc_2.append(auroc_t)\n",
    "            \n",
    "            #calculate sensitivity score the model in predicting class 1 - validation data and train data\n",
    "            recall_score1 = mat.recall_score(y_valid,pred1)\n",
    "            recall_1.append(recall_score1)\n",
    "            \n",
    "            recall_score_t = mat.recall_score(y_train,pred_t)\n",
    "            recall_2.append(recall_score_t)\n",
    "             \n",
    "\n",
    "        else:\n",
    "            \n",
    "            # defining models for voting class_ we have defined 3 models\n",
    "            model1 = m1\n",
    "            model2 = m2\n",
    "            model3 = m3\n",
    "\n",
    "            # defining the estimators in voting classifier object\n",
    "            voting_clf = model(estimators=[('m1', model1), ('m2', model2), ('m3', model3)], voting='soft')\n",
    "            \n",
    "            # fitting the train data to the classifier object\n",
    "            voting_clf.fit(x_train, y_train)\n",
    "            \n",
    "            # predicting the validation data\n",
    "            pred2 = voting_clf.predict(x_valid)\n",
    "            \n",
    "            # predicting the train data\n",
    "            pred_t1 = voting_clf.predict(x_train)        \n",
    "             \n",
    "            #calculate accuracy score of the model in prediction class 1\n",
    "            acc = accuracy_score(y_valid,pred2)\n",
    "            acc_1.append(acc)\n",
    "            \n",
    "            acc_t = accuracy_score(y_train,pred_t)\n",
    "            acc_2.append(acc_t)\n",
    "            \n",
    "            #calculate f1 score of the model in predicting class 1\n",
    "            f1 = f1_score(y_valid,pred2)\n",
    "            f_1.append(f1)\n",
    "            \n",
    "            f1_t = f1_score(y_train,pred_t)\n",
    "            f_2.append(f1_t)\n",
    "\n",
    "            #calculate auroc score the model in predicting class 1\n",
    "            auroc = roc_auc_score(y_valid,pred2)\n",
    "            auroc_1.append(auroc)\n",
    "            \n",
    "            auroc_t = roc_auc_score(y_train,pred_t)\n",
    "            auroc_2.append(auroc_t)\n",
    "\n",
    "            #calculate sensitivity score the model in predicting class 1\n",
    "            recall_score1 = mat.recall_score(y_valid,pred2)\n",
    "            recall_1.append(recall_score1)\n",
    "\n",
    "            recall_score_t = mat.recall_score(y_train,pred_t)\n",
    "            recall_2.append(recall_score_t)\n",
    "            \n",
    "    \n",
    "    # Indexes for the dataframes\n",
    "    indexes=[\"LogisticRegression\",\"LinearDiscriminantClassifier\",\"AdaptiveBoosting\",\n",
    "            \"Gradient_Boosting\",\"RandomForest\",\"Bagging classifier\",\"Xg boost\",\"VotingClassifier\"]\n",
    "\n",
    "     \n",
    "    # creating dataframe with the results\n",
    "    df1 = pd.DataFrame({\"Accuracy\":acc_2,\"F1_score\":f_2,\"Auroc\":auroc_2,\"Recall\":recall_2},index=indexes)\n",
    "    df2 = pd.DataFrame({\"Accuracy\":acc_1,\"F1_score\":f_1,\"Auroc\":auroc_1,\"Recall\":recall_1},index=indexes)\n",
    "\n",
    "    # creating heading for dataframe\n",
    "    df1_style = df1.style.set_table_attributes(\"style='display:inline; margin-right:20px;'\").set_caption(\"Model's Performance on Train data\")\n",
    "    df2_style = df2.style.set_table_attributes(\"style='display:inline'\").set_caption(\"Model's Performance on Validation data \")\n",
    "\n",
    "    #returning the final dataframes\n",
    "    return(display_html(df1_style._repr_html_() + df2_style._repr_html_(), raw=True))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc038345",
   "metadata": {},
   "source": [
    "### 5.MODEL TRAINING AND VALIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdf4128",
   "metadata": {},
   "source": [
    "### <font color= BLUE> Experiment 1:\n",
    "\n",
    "* <b> Included all variables _ no feature reduction, no transformationS used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2071,
   "id": "d532d75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(326, 148)\n"
     ]
    }
   ],
   "source": [
    "# Import the file and Separarting X/Y -- train data\n",
    "\n",
    "df1_train_descaled = pd.read_csv(\"Null Variables dropped denormalized and Knn_imputed.csv\")\n",
    "print(df1_train_descaled.shape)  # check the size of train data\n",
    "\n",
    "y_train1 = df1_train_descaled[\"target\"]\n",
    "X_train1 = df1_train_descaled.drop([\"target\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2072,
   "id": "1a3b13dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88, 148)\n"
     ]
    }
   ],
   "source": [
    "# Importing the file and separating X/Y -- validation data\n",
    "\n",
    "df1_valid_descaled = pd.read_csv(\"validation Null Variables dropped denormalized and Knn_imputed.csv\")\n",
    "print(df1_valid_descaled.shape)  # check the size of validation data\n",
    "\n",
    "y_valid1 = df1_valid_descaled[\"target\"]\n",
    "X_valid1 = df1_valid_descaled.drop([\"target\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2073,
   "id": "860a811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing various Machine Learning models with its DEFAULT PARAMETERS to train  (random _state is fixed to make fair comparison between models over the same data)\n",
    "\n",
    "lr  = LogisticRegression(random_state=50)                   #logistic regression classifier\n",
    "ldm = LinearDiscriminantAnalysis()                           #Linear discriminant classifier\n",
    "ab  = AdaBoostClassifier(random_state=50)                   #support vector machines classifier\n",
    "gb  = GradientBoostingClassifier(random_state=50)           #gradientboost classifier\n",
    "rf  = RandomForestClassifier(random_state=50)               #random forest classifier\n",
    "bc  = BaggingClassifier(random_state=50)                    #Bagging classifier\n",
    "xgb = XGBClassifier(random_state=50)                        #bagging classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2074,
   "id": "0f651844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping all instances of the models in a list\n",
    "L1 = [lr,ldm,ab,gb,rf,bc,xgb] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2075,
   "id": "e5b6175a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "LogisticRegression(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      1.00      0.44        25\n",
      "           1       0.00      0.00      0.00        63\n",
      "\n",
      "    accuracy                           0.28        88\n",
      "   macro avg       0.14      0.50      0.22        88\n",
      "weighted avg       0.08      0.28      0.13        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]          0                 63        \n",
      "Actual -ve [0]          0                 25        \n",
      "____________________________________________________________________________________________________\n",
      "LinearDiscriminantAnalysis()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.28      0.32        25\n",
      "           1       0.74      0.81      0.77        63\n",
      "\n",
      "    accuracy                           0.66        88\n",
      "   macro avg       0.55      0.54      0.55        88\n",
      "weighted avg       0.63      0.66      0.64        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         51                 12        \n",
      "Actual -ve [0]         18                  7        \n",
      "____________________________________________________________________________________________________\n",
      "AdaBoostClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.52      0.57        25\n",
      "           1       0.82      0.87      0.85        63\n",
      "\n",
      "    accuracy                           0.77        88\n",
      "   macro avg       0.72      0.70      0.71        88\n",
      "weighted avg       0.76      0.77      0.77        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         55                  8        \n",
      "Actual -ve [0]         12                 13        \n",
      "____________________________________________________________________________________________________\n",
      "GradientBoostingClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.44      0.56        25\n",
      "           1       0.81      0.95      0.88        63\n",
      "\n",
      "    accuracy                           0.81        88\n",
      "   macro avg       0.80      0.70      0.72        88\n",
      "weighted avg       0.80      0.81      0.79        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         60                  3        \n",
      "Actual -ve [0]         14                 11        \n",
      "____________________________________________________________________________________________________\n",
      "RandomForestClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.36      0.46        25\n",
      "           1       0.78      0.92      0.85        63\n",
      "\n",
      "    accuracy                           0.76        88\n",
      "   macro avg       0.71      0.64      0.65        88\n",
      "weighted avg       0.74      0.76      0.74        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         58                  5        \n",
      "Actual -ve [0]         16                  9        \n",
      "____________________________________________________________________________________________________\n",
      "BaggingClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.56      0.64        25\n",
      "           1       0.84      0.92      0.88        63\n",
      "\n",
      "    accuracy                           0.82        88\n",
      "   macro avg       0.79      0.74      0.76        88\n",
      "weighted avg       0.81      0.82      0.81        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         58                  5        \n",
      "Actual -ve [0]         11                 14        \n",
      "____________________________________________________________________________________________________\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=50, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.40      0.53        25\n",
      "           1       0.80      0.95      0.87        63\n",
      "\n",
      "    accuracy                           0.80        88\n",
      "   macro avg       0.78      0.68      0.70        88\n",
      "weighted avg       0.79      0.80      0.77        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         60                  3        \n",
      "Actual -ve [0]         15                 10        \n"
     ]
    }
   ],
   "source": [
    "# Classification report of multiple models\n",
    "for i in L1:\n",
    "    multiple_model(i,X_train1,y_train1,X_valid1,y_valid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2076,
   "id": "ef929fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.40      0.53        25\n",
      "           1       0.80      0.95      0.87        63\n",
      "\n",
      "    accuracy                           0.80        88\n",
      "   macro avg       0.78      0.68      0.70        88\n",
      "weighted avg       0.79      0.80      0.77        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         60                  3        \n",
      "Actual -ve [0]         15                 10        \n"
     ]
    }
   ],
   "source": [
    "# Based on the individual performance we will choose the best classifiers as our voting classifiers\n",
    "\n",
    "m1,m2,m3 = xgb,gb,ab # xgboost,gradient,adaboost\n",
    "\n",
    "voting_classifier(m1,m2,m3,X_train1,y_train1,X_valid1,y_valid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2077,
   "id": "23c64ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_f714b\" style='display:inline; margin-right:20px;'>\n",
       "  <caption>Model's Performance on Train data</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f714b_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_f714b_level0_col1\" class=\"col_heading level0 col1\" >F1_score</th>\n",
       "      <th id=\"T_f714b_level0_col2\" class=\"col_heading level0 col2\" >Auroc</th>\n",
       "      <th id=\"T_f714b_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f714b_level0_row0\" class=\"row_heading level0 row0\" >LogisticRegression</th>\n",
       "      <td id=\"T_f714b_row0_col0\" class=\"data row0 col0\" >0.248466</td>\n",
       "      <td id=\"T_f714b_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "      <td id=\"T_f714b_row0_col2\" class=\"data row0 col2\" >0.500000</td>\n",
       "      <td id=\"T_f714b_row0_col3\" class=\"data row0 col3\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f714b_level0_row1\" class=\"row_heading level0 row1\" >LinearDiscriminantClassifier</th>\n",
       "      <td id=\"T_f714b_row1_col0\" class=\"data row1 col0\" >0.923313</td>\n",
       "      <td id=\"T_f714b_row1_col1\" class=\"data row1 col1\" >0.950690</td>\n",
       "      <td id=\"T_f714b_row1_col2\" class=\"data row1 col2\" >0.862207</td>\n",
       "      <td id=\"T_f714b_row1_col3\" class=\"data row1 col3\" >0.983673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f714b_level0_row2\" class=\"row_heading level0 row2\" >AdaptiveBoosting</th>\n",
       "      <td id=\"T_f714b_row2_col0\" class=\"data row2 col0\" >0.990798</td>\n",
       "      <td id=\"T_f714b_row2_col1\" class=\"data row2 col1\" >0.993890</td>\n",
       "      <td id=\"T_f714b_row2_col2\" class=\"data row2 col2\" >0.985614</td>\n",
       "      <td id=\"T_f714b_row2_col3\" class=\"data row2 col3\" >0.995918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f714b_level0_row3\" class=\"row_heading level0 row3\" >Gradient_Boosting</th>\n",
       "      <td id=\"T_f714b_row3_col0\" class=\"data row3 col0\" >1.000000</td>\n",
       "      <td id=\"T_f714b_row3_col1\" class=\"data row3 col1\" >1.000000</td>\n",
       "      <td id=\"T_f714b_row3_col2\" class=\"data row3 col2\" >1.000000</td>\n",
       "      <td id=\"T_f714b_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f714b_level0_row4\" class=\"row_heading level0 row4\" >RandomForest</th>\n",
       "      <td id=\"T_f714b_row4_col0\" class=\"data row4 col0\" >1.000000</td>\n",
       "      <td id=\"T_f714b_row4_col1\" class=\"data row4 col1\" >1.000000</td>\n",
       "      <td id=\"T_f714b_row4_col2\" class=\"data row4 col2\" >1.000000</td>\n",
       "      <td id=\"T_f714b_row4_col3\" class=\"data row4 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f714b_level0_row5\" class=\"row_heading level0 row5\" >Bagging classifier</th>\n",
       "      <td id=\"T_f714b_row5_col0\" class=\"data row5 col0\" >0.993865</td>\n",
       "      <td id=\"T_f714b_row5_col1\" class=\"data row5 col1\" >0.995918</td>\n",
       "      <td id=\"T_f714b_row5_col2\" class=\"data row5 col2\" >0.991786</td>\n",
       "      <td id=\"T_f714b_row5_col3\" class=\"data row5 col3\" >0.995918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f714b_level0_row6\" class=\"row_heading level0 row6\" >Xg boost</th>\n",
       "      <td id=\"T_f714b_row6_col0\" class=\"data row6 col0\" >1.000000</td>\n",
       "      <td id=\"T_f714b_row6_col1\" class=\"data row6 col1\" >1.000000</td>\n",
       "      <td id=\"T_f714b_row6_col2\" class=\"data row6 col2\" >1.000000</td>\n",
       "      <td id=\"T_f714b_row6_col3\" class=\"data row6 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f714b_level0_row7\" class=\"row_heading level0 row7\" >VotingClassifier</th>\n",
       "      <td id=\"T_f714b_row7_col0\" class=\"data row7 col0\" >1.000000</td>\n",
       "      <td id=\"T_f714b_row7_col1\" class=\"data row7 col1\" >1.000000</td>\n",
       "      <td id=\"T_f714b_row7_col2\" class=\"data row7 col2\" >1.000000</td>\n",
       "      <td id=\"T_f714b_row7_col3\" class=\"data row7 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_84fa9\" style='display:inline'>\n",
       "  <caption>Model's Performance on Validation data </caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_84fa9_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_84fa9_level0_col1\" class=\"col_heading level0 col1\" >F1_score</th>\n",
       "      <th id=\"T_84fa9_level0_col2\" class=\"col_heading level0 col2\" >Auroc</th>\n",
       "      <th id=\"T_84fa9_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_84fa9_level0_row0\" class=\"row_heading level0 row0\" >LogisticRegression</th>\n",
       "      <td id=\"T_84fa9_row0_col0\" class=\"data row0 col0\" >0.284091</td>\n",
       "      <td id=\"T_84fa9_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "      <td id=\"T_84fa9_row0_col2\" class=\"data row0 col2\" >0.500000</td>\n",
       "      <td id=\"T_84fa9_row0_col3\" class=\"data row0 col3\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84fa9_level0_row1\" class=\"row_heading level0 row1\" >LinearDiscriminantClassifier</th>\n",
       "      <td id=\"T_84fa9_row1_col0\" class=\"data row1 col0\" >0.659091</td>\n",
       "      <td id=\"T_84fa9_row1_col1\" class=\"data row1 col1\" >0.772727</td>\n",
       "      <td id=\"T_84fa9_row1_col2\" class=\"data row1 col2\" >0.544762</td>\n",
       "      <td id=\"T_84fa9_row1_col3\" class=\"data row1 col3\" >0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84fa9_level0_row2\" class=\"row_heading level0 row2\" >AdaptiveBoosting</th>\n",
       "      <td id=\"T_84fa9_row2_col0\" class=\"data row2 col0\" >0.772727</td>\n",
       "      <td id=\"T_84fa9_row2_col1\" class=\"data row2 col1\" >0.846154</td>\n",
       "      <td id=\"T_84fa9_row2_col2\" class=\"data row2 col2\" >0.696508</td>\n",
       "      <td id=\"T_84fa9_row2_col3\" class=\"data row2 col3\" >0.873016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84fa9_level0_row3\" class=\"row_heading level0 row3\" >Gradient_Boosting</th>\n",
       "      <td id=\"T_84fa9_row3_col0\" class=\"data row3 col0\" >0.806818</td>\n",
       "      <td id=\"T_84fa9_row3_col1\" class=\"data row3 col1\" >0.875912</td>\n",
       "      <td id=\"T_84fa9_row3_col2\" class=\"data row3 col2\" >0.696190</td>\n",
       "      <td id=\"T_84fa9_row3_col3\" class=\"data row3 col3\" >0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84fa9_level0_row4\" class=\"row_heading level0 row4\" >RandomForest</th>\n",
       "      <td id=\"T_84fa9_row4_col0\" class=\"data row4 col0\" >0.761364</td>\n",
       "      <td id=\"T_84fa9_row4_col1\" class=\"data row4 col1\" >0.846715</td>\n",
       "      <td id=\"T_84fa9_row4_col2\" class=\"data row4 col2\" >0.640317</td>\n",
       "      <td id=\"T_84fa9_row4_col3\" class=\"data row4 col3\" >0.920635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84fa9_level0_row5\" class=\"row_heading level0 row5\" >Bagging classifier</th>\n",
       "      <td id=\"T_84fa9_row5_col0\" class=\"data row5 col0\" >0.818182</td>\n",
       "      <td id=\"T_84fa9_row5_col1\" class=\"data row5 col1\" >0.878788</td>\n",
       "      <td id=\"T_84fa9_row5_col2\" class=\"data row5 col2\" >0.740317</td>\n",
       "      <td id=\"T_84fa9_row5_col3\" class=\"data row5 col3\" >0.920635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84fa9_level0_row6\" class=\"row_heading level0 row6\" >Xg boost</th>\n",
       "      <td id=\"T_84fa9_row6_col0\" class=\"data row6 col0\" >0.795455</td>\n",
       "      <td id=\"T_84fa9_row6_col1\" class=\"data row6 col1\" >0.869565</td>\n",
       "      <td id=\"T_84fa9_row6_col2\" class=\"data row6 col2\" >0.676190</td>\n",
       "      <td id=\"T_84fa9_row6_col3\" class=\"data row6 col3\" >0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84fa9_level0_row7\" class=\"row_heading level0 row7\" >VotingClassifier</th>\n",
       "      <td id=\"T_84fa9_row7_col0\" class=\"data row7 col0\" >0.795455</td>\n",
       "      <td id=\"T_84fa9_row7_col1\" class=\"data row7 col1\" >0.869565</td>\n",
       "      <td id=\"T_84fa9_row7_col2\" class=\"data row7 col2\" >0.676190</td>\n",
       "      <td id=\"T_84fa9_row7_col3\" class=\"data row7 col3\" >0.952381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating Dataframe of the results\n",
    "L2 = [lr,ldm,ab,gb,rf,bc,xgb,VotingClassifier]\n",
    "\n",
    "# Using the function to create dataframe\n",
    "result_frame(L2,X_train1,y_train1,X_valid1,y_valid1,m1,m2,m3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77b9e6e",
   "metadata": {},
   "source": [
    "<b> Remarks:\n",
    "\n",
    "* From the above trial with all the variables we can see the f1 score of Logistic model is zero because the \"true postive\" predicted by the model is Nil. This might be because the model couldnt establish linear relationship with (log(odds)) of outcome whereas rest of the models are performing on average.\n",
    "* Scaling the variable will help in the case of logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb70c11",
   "metadata": {},
   "source": [
    "* <b> <font color= Green> NOTE: In real case scenario, the percentage of events(class 1) is usually lower in proportion compared to non events(class 0).\n",
    "But in our case the events(class 1) is higher in train data. So lets concentrate to improve the auroc which is robust when class labels are interchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b3ed4d",
   "metadata": {},
   "source": [
    "### <font color= BLUE>Experiment 2:\n",
    "\n",
    "* <b> Standardizing the Independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2079,
   "id": "ea762035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(326, 148)\n"
     ]
    }
   ],
   "source": [
    "# Import the file and Separarting X/Y -- train data\n",
    "\n",
    "df1_train_descaled = pd.read_csv(\"Null Variables dropped denormalized and Knn_imputed.csv\")\n",
    "print(df1_train_descaled.shape)  # check the size of train data\n",
    "\n",
    "y_train2 = df1_train_descaled[\"target\"]\n",
    "X_train2 = df1_train_descaled.drop([\"target\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2080,
   "id": "7f8a7b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88, 148)\n"
     ]
    }
   ],
   "source": [
    "# Importing the file and separating X/Y -- validation data\n",
    "\n",
    "df1_valid_descaled = pd.read_csv(\"validation Null Variables dropped denormalized and Knn_imputed.csv\")\n",
    "print(df1_valid_descaled.shape)  # check the size of validation data\n",
    "\n",
    "y_valid2 = df1_valid_descaled[\"target\"]\n",
    "X_valid2 = df1_valid_descaled.drop([\"target\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2081,
   "id": "e13a4c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the train data\n",
    "\n",
    "# initializing the scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit and transform the train data\n",
    "X_train2_scaled = scaler.fit_transform(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2082,
   "id": "eae0aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the validation data using the fit of train data(mean and standard deviation)\n",
    "X_valid2_scaled = scaler.transform(X_valid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2083,
   "id": "abe39753",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "LogisticRegression(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.32      0.39        25\n",
      "           1       0.76      0.87      0.81        63\n",
      "\n",
      "    accuracy                           0.72        88\n",
      "   macro avg       0.63      0.60      0.60        88\n",
      "weighted avg       0.69      0.72      0.69        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         55                  8        \n",
      "Actual -ve [0]         17                  8        \n",
      "____________________________________________________________________________________________________\n",
      "LinearDiscriminantAnalysis()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.28      0.32        25\n",
      "           1       0.74      0.81      0.77        63\n",
      "\n",
      "    accuracy                           0.66        88\n",
      "   macro avg       0.55      0.54      0.55        88\n",
      "weighted avg       0.63      0.66      0.64        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         51                 12        \n",
      "Actual -ve [0]         18                  7        \n",
      "____________________________________________________________________________________________________\n",
      "AdaBoostClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.48      0.52        25\n",
      "           1       0.81      0.86      0.83        63\n",
      "\n",
      "    accuracy                           0.75        88\n",
      "   macro avg       0.69      0.67      0.68        88\n",
      "weighted avg       0.74      0.75      0.74        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         54                  9        \n",
      "Actual -ve [0]         13                 12        \n",
      "____________________________________________________________________________________________________\n",
      "GradientBoostingClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.44      0.55        25\n",
      "           1       0.81      0.94      0.87        63\n",
      "\n",
      "    accuracy                           0.80        88\n",
      "   macro avg       0.77      0.69      0.71        88\n",
      "weighted avg       0.79      0.80      0.78        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         59                  4        \n",
      "Actual -ve [0]         14                 11        \n",
      "____________________________________________________________________________________________________\n",
      "RandomForestClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.36      0.46        25\n",
      "           1       0.78      0.92      0.85        63\n",
      "\n",
      "    accuracy                           0.76        88\n",
      "   macro avg       0.71      0.64      0.65        88\n",
      "weighted avg       0.74      0.76      0.74        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         58                  5        \n",
      "Actual -ve [0]         16                  9        \n",
      "____________________________________________________________________________________________________\n",
      "BaggingClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.48      0.52        25\n",
      "           1       0.81      0.86      0.83        63\n",
      "\n",
      "    accuracy                           0.75        88\n",
      "   macro avg       0.69      0.67      0.68        88\n",
      "weighted avg       0.74      0.75      0.74        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         54                  9        \n",
      "Actual -ve [0]         13                 12        \n",
      "____________________________________________________________________________________________________\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=50, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.40      0.53        25\n",
      "           1       0.80      0.95      0.87        63\n",
      "\n",
      "    accuracy                           0.80        88\n",
      "   macro avg       0.78      0.68      0.70        88\n",
      "weighted avg       0.79      0.80      0.77        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         60                  3        \n",
      "Actual -ve [0]         15                 10        \n"
     ]
    }
   ],
   "source": [
    "# Classification report of multiple models over scaled data\n",
    "for i in L1:\n",
    "    multiple_model(i,X_train2_scaled,y_train2,X_valid2_scaled,y_valid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2084,
   "id": "a5444f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.44      0.56        25\n",
      "           1       0.81      0.95      0.88        63\n",
      "\n",
      "    accuracy                           0.81        88\n",
      "   macro avg       0.80      0.70      0.72        88\n",
      "weighted avg       0.80      0.81      0.79        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         60                  3        \n",
      "Actual -ve [0]         14                 11        \n"
     ]
    }
   ],
   "source": [
    "# Based on the individual performance we will choose the best classifiers as our voting classifiers\n",
    "\n",
    "m1,m2,m3 = xgb,gb,ab # xgboost,gradient,adaboost\n",
    "\n",
    "voting_classifier(m1,m2,m3,X_train2_scaled,y_train2,X_valid2_scaled,y_valid2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2085,
   "id": "96d06581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_42d49\" style='display:inline; margin-right:20px;'>\n",
       "  <caption>Model's Performance on Train data</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_42d49_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_42d49_level0_col1\" class=\"col_heading level0 col1\" >F1_score</th>\n",
       "      <th id=\"T_42d49_level0_col2\" class=\"col_heading level0 col2\" >Auroc</th>\n",
       "      <th id=\"T_42d49_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_42d49_level0_row0\" class=\"row_heading level0 row0\" >LogisticRegression</th>\n",
       "      <td id=\"T_42d49_row0_col0\" class=\"data row0 col0\" >0.880368</td>\n",
       "      <td id=\"T_42d49_row0_col1\" class=\"data row0 col1\" >0.925144</td>\n",
       "      <td id=\"T_42d49_row0_col2\" class=\"data row0 col2\" >0.775787</td>\n",
       "      <td id=\"T_42d49_row0_col3\" class=\"data row0 col3\" >0.983673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_42d49_level0_row1\" class=\"row_heading level0 row1\" >LinearDiscriminantClassifier</th>\n",
       "      <td id=\"T_42d49_row1_col0\" class=\"data row1 col0\" >0.923313</td>\n",
       "      <td id=\"T_42d49_row1_col1\" class=\"data row1 col1\" >0.950690</td>\n",
       "      <td id=\"T_42d49_row1_col2\" class=\"data row1 col2\" >0.862207</td>\n",
       "      <td id=\"T_42d49_row1_col3\" class=\"data row1 col3\" >0.983673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_42d49_level0_row2\" class=\"row_heading level0 row2\" >AdaptiveBoosting</th>\n",
       "      <td id=\"T_42d49_row2_col0\" class=\"data row2 col0\" >0.963190</td>\n",
       "      <td id=\"T_42d49_row2_col1\" class=\"data row2 col1\" >0.975806</td>\n",
       "      <td id=\"T_42d49_row2_col2\" class=\"data row2 col2\" >0.938322</td>\n",
       "      <td id=\"T_42d49_row2_col3\" class=\"data row2 col3\" >0.987755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_42d49_level0_row3\" class=\"row_heading level0 row3\" >Gradient_Boosting</th>\n",
       "      <td id=\"T_42d49_row3_col0\" class=\"data row3 col0\" >1.000000</td>\n",
       "      <td id=\"T_42d49_row3_col1\" class=\"data row3 col1\" >1.000000</td>\n",
       "      <td id=\"T_42d49_row3_col2\" class=\"data row3 col2\" >1.000000</td>\n",
       "      <td id=\"T_42d49_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_42d49_level0_row4\" class=\"row_heading level0 row4\" >RandomForest</th>\n",
       "      <td id=\"T_42d49_row4_col0\" class=\"data row4 col0\" >1.000000</td>\n",
       "      <td id=\"T_42d49_row4_col1\" class=\"data row4 col1\" >1.000000</td>\n",
       "      <td id=\"T_42d49_row4_col2\" class=\"data row4 col2\" >1.000000</td>\n",
       "      <td id=\"T_42d49_row4_col3\" class=\"data row4 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_42d49_level0_row5\" class=\"row_heading level0 row5\" >Bagging classifier</th>\n",
       "      <td id=\"T_42d49_row5_col0\" class=\"data row5 col0\" >0.990798</td>\n",
       "      <td id=\"T_42d49_row5_col1\" class=\"data row5 col1\" >0.993890</td>\n",
       "      <td id=\"T_42d49_row5_col2\" class=\"data row5 col2\" >0.985614</td>\n",
       "      <td id=\"T_42d49_row5_col3\" class=\"data row5 col3\" >0.995918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_42d49_level0_row6\" class=\"row_heading level0 row6\" >Xg boost</th>\n",
       "      <td id=\"T_42d49_row6_col0\" class=\"data row6 col0\" >1.000000</td>\n",
       "      <td id=\"T_42d49_row6_col1\" class=\"data row6 col1\" >1.000000</td>\n",
       "      <td id=\"T_42d49_row6_col2\" class=\"data row6 col2\" >1.000000</td>\n",
       "      <td id=\"T_42d49_row6_col3\" class=\"data row6 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_42d49_level0_row7\" class=\"row_heading level0 row7\" >VotingClassifier</th>\n",
       "      <td id=\"T_42d49_row7_col0\" class=\"data row7 col0\" >1.000000</td>\n",
       "      <td id=\"T_42d49_row7_col1\" class=\"data row7 col1\" >1.000000</td>\n",
       "      <td id=\"T_42d49_row7_col2\" class=\"data row7 col2\" >1.000000</td>\n",
       "      <td id=\"T_42d49_row7_col3\" class=\"data row7 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ee574\" style='display:inline'>\n",
       "  <caption>Model's Performance on Validation data </caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ee574_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_ee574_level0_col1\" class=\"col_heading level0 col1\" >F1_score</th>\n",
       "      <th id=\"T_ee574_level0_col2\" class=\"col_heading level0 col2\" >Auroc</th>\n",
       "      <th id=\"T_ee574_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ee574_level0_row0\" class=\"row_heading level0 row0\" >LogisticRegression</th>\n",
       "      <td id=\"T_ee574_row0_col0\" class=\"data row0 col0\" >0.715909</td>\n",
       "      <td id=\"T_ee574_row0_col1\" class=\"data row0 col1\" >0.814815</td>\n",
       "      <td id=\"T_ee574_row0_col2\" class=\"data row0 col2\" >0.596508</td>\n",
       "      <td id=\"T_ee574_row0_col3\" class=\"data row0 col3\" >0.873016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee574_level0_row1\" class=\"row_heading level0 row1\" >LinearDiscriminantClassifier</th>\n",
       "      <td id=\"T_ee574_row1_col0\" class=\"data row1 col0\" >0.659091</td>\n",
       "      <td id=\"T_ee574_row1_col1\" class=\"data row1 col1\" >0.772727</td>\n",
       "      <td id=\"T_ee574_row1_col2\" class=\"data row1 col2\" >0.544762</td>\n",
       "      <td id=\"T_ee574_row1_col3\" class=\"data row1 col3\" >0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee574_level0_row2\" class=\"row_heading level0 row2\" >AdaptiveBoosting</th>\n",
       "      <td id=\"T_ee574_row2_col0\" class=\"data row2 col0\" >0.750000</td>\n",
       "      <td id=\"T_ee574_row2_col1\" class=\"data row2 col1\" >0.830769</td>\n",
       "      <td id=\"T_ee574_row2_col2\" class=\"data row2 col2\" >0.668571</td>\n",
       "      <td id=\"T_ee574_row2_col3\" class=\"data row2 col3\" >0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee574_level0_row3\" class=\"row_heading level0 row3\" >Gradient_Boosting</th>\n",
       "      <td id=\"T_ee574_row3_col0\" class=\"data row3 col0\" >0.795455</td>\n",
       "      <td id=\"T_ee574_row3_col1\" class=\"data row3 col1\" >0.867647</td>\n",
       "      <td id=\"T_ee574_row3_col2\" class=\"data row3 col2\" >0.688254</td>\n",
       "      <td id=\"T_ee574_row3_col3\" class=\"data row3 col3\" >0.936508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee574_level0_row4\" class=\"row_heading level0 row4\" >RandomForest</th>\n",
       "      <td id=\"T_ee574_row4_col0\" class=\"data row4 col0\" >0.761364</td>\n",
       "      <td id=\"T_ee574_row4_col1\" class=\"data row4 col1\" >0.846715</td>\n",
       "      <td id=\"T_ee574_row4_col2\" class=\"data row4 col2\" >0.640317</td>\n",
       "      <td id=\"T_ee574_row4_col3\" class=\"data row4 col3\" >0.920635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee574_level0_row5\" class=\"row_heading level0 row5\" >Bagging classifier</th>\n",
       "      <td id=\"T_ee574_row5_col0\" class=\"data row5 col0\" >0.750000</td>\n",
       "      <td id=\"T_ee574_row5_col1\" class=\"data row5 col1\" >0.830769</td>\n",
       "      <td id=\"T_ee574_row5_col2\" class=\"data row5 col2\" >0.668571</td>\n",
       "      <td id=\"T_ee574_row5_col3\" class=\"data row5 col3\" >0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee574_level0_row6\" class=\"row_heading level0 row6\" >Xg boost</th>\n",
       "      <td id=\"T_ee574_row6_col0\" class=\"data row6 col0\" >0.795455</td>\n",
       "      <td id=\"T_ee574_row6_col1\" class=\"data row6 col1\" >0.869565</td>\n",
       "      <td id=\"T_ee574_row6_col2\" class=\"data row6 col2\" >0.676190</td>\n",
       "      <td id=\"T_ee574_row6_col3\" class=\"data row6 col3\" >0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee574_level0_row7\" class=\"row_heading level0 row7\" >VotingClassifier</th>\n",
       "      <td id=\"T_ee574_row7_col0\" class=\"data row7 col0\" >0.806818</td>\n",
       "      <td id=\"T_ee574_row7_col1\" class=\"data row7 col1\" >0.875912</td>\n",
       "      <td id=\"T_ee574_row7_col2\" class=\"data row7 col2\" >0.696190</td>\n",
       "      <td id=\"T_ee574_row7_col3\" class=\"data row7 col3\" >0.952381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the function to create dataframe\n",
    "result_frame(L2,X_train2_scaled,y_train2,X_valid2_scaled,y_valid2,m1,m2,m3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b779da8f",
   "metadata": {},
   "source": [
    "<b> Remarks:\n",
    "\n",
    "* From the above experiment as we expected the perfromance of the logistic regression improved drasitically with standardized variables.\n",
    "* Irrespective of the variable scaling the performance of the other models is closer to the previous case as most of these model are non parametric.\n",
    "* The auroc score is still very low we can try doing feature transformation to improve the score of auroc.\n",
    "* The training dataset is highly imbalanced so the model doesnot get to learn both the classes equally.\n",
    "* Applying oversampling technique like SMOTE can be helpful.\n",
    "* Lets try increasing the size of the minority class and see the performance in our next trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067e26a3",
   "metadata": {},
   "source": [
    "### <font color= BLUE> Experiment 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7ca238",
   "metadata": {},
   "source": [
    "* <b> Balancing the class imbalanceness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2086,
   "id": "c0c7f8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 Count: 245 Percentage: 50.0\n",
      "Class: 1 Count: 245 Percentage: 50.0\n"
     ]
    }
   ],
   "source": [
    "# Balancing the standardized data\n",
    "\n",
    "#Initialize smote object - Sythetic Minority Oversampling Technique\n",
    "oversample = SMOTE(random_state=50)\n",
    "\n",
    "#oversampling the classes (Note:using the same scaled data from previous trial)\n",
    "X_train_smt, y_train_smt = oversample.fit_resample(X_train2_scaled, y_train2)\n",
    "\n",
    "# Summarizing the distribution\n",
    "counter = Counter(y_train_smt)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_train_smt) * 100\n",
    "    print(\"Class:\",k,\"Count:\",v,\"Percentage:\", per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2087,
   "id": "e0bbac77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "LogisticRegression(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.64      0.59        25\n",
      "           1       0.85      0.79      0.82        63\n",
      "\n",
      "    accuracy                           0.75        88\n",
      "   macro avg       0.70      0.72      0.71        88\n",
      "weighted avg       0.76      0.75      0.76        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         50                 13        \n",
      "Actual -ve [0]          9                 16        \n",
      "____________________________________________________________________________________________________\n",
      "LinearDiscriminantAnalysis()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.44      0.42        25\n",
      "           1       0.77      0.73      0.75        63\n",
      "\n",
      "    accuracy                           0.65        88\n",
      "   macro avg       0.58      0.59      0.58        88\n",
      "weighted avg       0.66      0.65      0.65        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         46                 17        \n",
      "Actual -ve [0]         14                 11        \n",
      "____________________________________________________________________________________________________\n",
      "AdaBoostClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.56      0.56        25\n",
      "           1       0.83      0.83      0.83        63\n",
      "\n",
      "    accuracy                           0.75        88\n",
      "   macro avg       0.69      0.69      0.69        88\n",
      "weighted avg       0.75      0.75      0.75        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         52                 11        \n",
      "Actual -ve [0]         11                 14        \n",
      "____________________________________________________________________________________________________\n",
      "GradientBoostingClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.68      0.74        25\n",
      "           1       0.88      0.94      0.91        63\n",
      "\n",
      "    accuracy                           0.86        88\n",
      "   macro avg       0.85      0.81      0.82        88\n",
      "weighted avg       0.86      0.86      0.86        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         59                  4        \n",
      "Actual -ve [0]          8                 17        \n",
      "____________________________________________________________________________________________________\n",
      "RandomForestClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.56      0.62        25\n",
      "           1       0.84      0.90      0.87        63\n",
      "\n",
      "    accuracy                           0.81        88\n",
      "   macro avg       0.77      0.73      0.75        88\n",
      "weighted avg       0.80      0.81      0.80        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         57                  6        \n",
      "Actual -ve [0]         11                 14        \n",
      "____________________________________________________________________________________________________\n",
      "BaggingClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.64      0.68        25\n",
      "           1       0.86      0.90      0.88        63\n",
      "\n",
      "    accuracy                           0.83        88\n",
      "   macro avg       0.80      0.77      0.78        88\n",
      "weighted avg       0.82      0.83      0.83        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         57                  6        \n",
      "Actual -ve [0]          9                 16        \n",
      "____________________________________________________________________________________________________\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=50, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.56      0.65        25\n",
      "           1       0.84      0.94      0.89        63\n",
      "\n",
      "    accuracy                           0.83        88\n",
      "   macro avg       0.81      0.75      0.77        88\n",
      "weighted avg       0.82      0.83      0.82        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         59                  4        \n",
      "Actual -ve [0]         11                 14        \n"
     ]
    }
   ],
   "source": [
    "# Classification report of multiple models over scaled and oversampled data\n",
    "for i in L1:\n",
    "    multiple_model(i,X_train_smt,y_train_smt,X_valid2_scaled,y_valid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2088,
   "id": "c661d4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.56      0.65        25\n",
      "           1       0.84      0.94      0.89        63\n",
      "\n",
      "    accuracy                           0.83        88\n",
      "   macro avg       0.81      0.75      0.77        88\n",
      "weighted avg       0.82      0.83      0.82        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         59                  4        \n",
      "Actual -ve [0]         11                 14        \n"
     ]
    }
   ],
   "source": [
    "# Based on the individual performance we will choose the best classifiers as our voting classifiers\n",
    "\n",
    "m1,m2,m3 = xgb,ab,gb # xgboost,gradient,adaboost\n",
    "\n",
    "voting_classifier(m1,m2,m3,X_train_smt,y_train_smt,X_valid2_scaled,y_valid2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2089,
   "id": "920c0734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_27a8e\" style='display:inline; margin-right:20px;'>\n",
       "  <caption>Model's Performance on Train data</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_27a8e_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_27a8e_level0_col1\" class=\"col_heading level0 col1\" >F1_score</th>\n",
       "      <th id=\"T_27a8e_level0_col2\" class=\"col_heading level0 col2\" >Auroc</th>\n",
       "      <th id=\"T_27a8e_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_27a8e_level0_row0\" class=\"row_heading level0 row0\" >LogisticRegression</th>\n",
       "      <td id=\"T_27a8e_row0_col0\" class=\"data row0 col0\" >0.867347</td>\n",
       "      <td id=\"T_27a8e_row0_col1\" class=\"data row0 col1\" >0.864301</td>\n",
       "      <td id=\"T_27a8e_row0_col2\" class=\"data row0 col2\" >0.867347</td>\n",
       "      <td id=\"T_27a8e_row0_col3\" class=\"data row0 col3\" >0.844898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27a8e_level0_row1\" class=\"row_heading level0 row1\" >LinearDiscriminantClassifier</th>\n",
       "      <td id=\"T_27a8e_row1_col0\" class=\"data row1 col0\" >0.893878</td>\n",
       "      <td id=\"T_27a8e_row1_col1\" class=\"data row1 col1\" >0.893004</td>\n",
       "      <td id=\"T_27a8e_row1_col2\" class=\"data row1 col2\" >0.893878</td>\n",
       "      <td id=\"T_27a8e_row1_col3\" class=\"data row1 col3\" >0.885714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27a8e_level0_row2\" class=\"row_heading level0 row2\" >AdaptiveBoosting</th>\n",
       "      <td id=\"T_27a8e_row2_col0\" class=\"data row2 col0\" >0.973469</td>\n",
       "      <td id=\"T_27a8e_row2_col1\" class=\"data row2 col1\" >0.973523</td>\n",
       "      <td id=\"T_27a8e_row2_col2\" class=\"data row2 col2\" >0.973469</td>\n",
       "      <td id=\"T_27a8e_row2_col3\" class=\"data row2 col3\" >0.975510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27a8e_level0_row3\" class=\"row_heading level0 row3\" >Gradient_Boosting</th>\n",
       "      <td id=\"T_27a8e_row3_col0\" class=\"data row3 col0\" >1.000000</td>\n",
       "      <td id=\"T_27a8e_row3_col1\" class=\"data row3 col1\" >1.000000</td>\n",
       "      <td id=\"T_27a8e_row3_col2\" class=\"data row3 col2\" >1.000000</td>\n",
       "      <td id=\"T_27a8e_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27a8e_level0_row4\" class=\"row_heading level0 row4\" >RandomForest</th>\n",
       "      <td id=\"T_27a8e_row4_col0\" class=\"data row4 col0\" >1.000000</td>\n",
       "      <td id=\"T_27a8e_row4_col1\" class=\"data row4 col1\" >1.000000</td>\n",
       "      <td id=\"T_27a8e_row4_col2\" class=\"data row4 col2\" >1.000000</td>\n",
       "      <td id=\"T_27a8e_row4_col3\" class=\"data row4 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27a8e_level0_row5\" class=\"row_heading level0 row5\" >Bagging classifier</th>\n",
       "      <td id=\"T_27a8e_row5_col0\" class=\"data row5 col0\" >0.993878</td>\n",
       "      <td id=\"T_27a8e_row5_col1\" class=\"data row5 col1\" >0.993840</td>\n",
       "      <td id=\"T_27a8e_row5_col2\" class=\"data row5 col2\" >0.993878</td>\n",
       "      <td id=\"T_27a8e_row5_col3\" class=\"data row5 col3\" >0.987755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27a8e_level0_row6\" class=\"row_heading level0 row6\" >Xg boost</th>\n",
       "      <td id=\"T_27a8e_row6_col0\" class=\"data row6 col0\" >1.000000</td>\n",
       "      <td id=\"T_27a8e_row6_col1\" class=\"data row6 col1\" >1.000000</td>\n",
       "      <td id=\"T_27a8e_row6_col2\" class=\"data row6 col2\" >1.000000</td>\n",
       "      <td id=\"T_27a8e_row6_col3\" class=\"data row6 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27a8e_level0_row7\" class=\"row_heading level0 row7\" >VotingClassifier</th>\n",
       "      <td id=\"T_27a8e_row7_col0\" class=\"data row7 col0\" >1.000000</td>\n",
       "      <td id=\"T_27a8e_row7_col1\" class=\"data row7 col1\" >1.000000</td>\n",
       "      <td id=\"T_27a8e_row7_col2\" class=\"data row7 col2\" >1.000000</td>\n",
       "      <td id=\"T_27a8e_row7_col3\" class=\"data row7 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_452b1\" style='display:inline'>\n",
       "  <caption>Model's Performance on Validation data </caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_452b1_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_452b1_level0_col1\" class=\"col_heading level0 col1\" >F1_score</th>\n",
       "      <th id=\"T_452b1_level0_col2\" class=\"col_heading level0 col2\" >Auroc</th>\n",
       "      <th id=\"T_452b1_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_452b1_level0_row0\" class=\"row_heading level0 row0\" >LogisticRegression</th>\n",
       "      <td id=\"T_452b1_row0_col0\" class=\"data row0 col0\" >0.750000</td>\n",
       "      <td id=\"T_452b1_row0_col1\" class=\"data row0 col1\" >0.819672</td>\n",
       "      <td id=\"T_452b1_row0_col2\" class=\"data row0 col2\" >0.716825</td>\n",
       "      <td id=\"T_452b1_row0_col3\" class=\"data row0 col3\" >0.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_452b1_level0_row1\" class=\"row_heading level0 row1\" >LinearDiscriminantClassifier</th>\n",
       "      <td id=\"T_452b1_row1_col0\" class=\"data row1 col0\" >0.647727</td>\n",
       "      <td id=\"T_452b1_row1_col1\" class=\"data row1 col1\" >0.747967</td>\n",
       "      <td id=\"T_452b1_row1_col2\" class=\"data row1 col2\" >0.585079</td>\n",
       "      <td id=\"T_452b1_row1_col3\" class=\"data row1 col3\" >0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_452b1_level0_row2\" class=\"row_heading level0 row2\" >AdaptiveBoosting</th>\n",
       "      <td id=\"T_452b1_row2_col0\" class=\"data row2 col0\" >0.750000</td>\n",
       "      <td id=\"T_452b1_row2_col1\" class=\"data row2 col1\" >0.825397</td>\n",
       "      <td id=\"T_452b1_row2_col2\" class=\"data row2 col2\" >0.692698</td>\n",
       "      <td id=\"T_452b1_row2_col3\" class=\"data row2 col3\" >0.825397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_452b1_level0_row3\" class=\"row_heading level0 row3\" >Gradient_Boosting</th>\n",
       "      <td id=\"T_452b1_row3_col0\" class=\"data row3 col0\" >0.863636</td>\n",
       "      <td id=\"T_452b1_row3_col1\" class=\"data row3 col1\" >0.907692</td>\n",
       "      <td id=\"T_452b1_row3_col2\" class=\"data row3 col2\" >0.808254</td>\n",
       "      <td id=\"T_452b1_row3_col3\" class=\"data row3 col3\" >0.936508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_452b1_level0_row4\" class=\"row_heading level0 row4\" >RandomForest</th>\n",
       "      <td id=\"T_452b1_row4_col0\" class=\"data row4 col0\" >0.806818</td>\n",
       "      <td id=\"T_452b1_row4_col1\" class=\"data row4 col1\" >0.870229</td>\n",
       "      <td id=\"T_452b1_row4_col2\" class=\"data row4 col2\" >0.732381</td>\n",
       "      <td id=\"T_452b1_row4_col3\" class=\"data row4 col3\" >0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_452b1_level0_row5\" class=\"row_heading level0 row5\" >Bagging classifier</th>\n",
       "      <td id=\"T_452b1_row5_col0\" class=\"data row5 col0\" >0.829545</td>\n",
       "      <td id=\"T_452b1_row5_col1\" class=\"data row5 col1\" >0.883721</td>\n",
       "      <td id=\"T_452b1_row5_col2\" class=\"data row5 col2\" >0.772381</td>\n",
       "      <td id=\"T_452b1_row5_col3\" class=\"data row5 col3\" >0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_452b1_level0_row6\" class=\"row_heading level0 row6\" >Xg boost</th>\n",
       "      <td id=\"T_452b1_row6_col0\" class=\"data row6 col0\" >0.829545</td>\n",
       "      <td id=\"T_452b1_row6_col1\" class=\"data row6 col1\" >0.887218</td>\n",
       "      <td id=\"T_452b1_row6_col2\" class=\"data row6 col2\" >0.748254</td>\n",
       "      <td id=\"T_452b1_row6_col3\" class=\"data row6 col3\" >0.936508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_452b1_level0_row7\" class=\"row_heading level0 row7\" >VotingClassifier</th>\n",
       "      <td id=\"T_452b1_row7_col0\" class=\"data row7 col0\" >0.829545</td>\n",
       "      <td id=\"T_452b1_row7_col1\" class=\"data row7 col1\" >0.887218</td>\n",
       "      <td id=\"T_452b1_row7_col2\" class=\"data row7 col2\" >0.748254</td>\n",
       "      <td id=\"T_452b1_row7_col3\" class=\"data row7 col3\" >0.936508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the function to create dataframe\n",
    "result_frame(L2,X_train_smt,y_train_smt,X_valid2_scaled,y_valid2,m1,m2,m3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671ad96c",
   "metadata": {},
   "source": [
    "<b> Remarks:\n",
    "\n",
    "* The performance of the all the models in predicting both the classes has improved well after oversampling.So lets stick with oversampling for next trails.\n",
    "* The AUROC score has increased a lot compared to previous trial.\n",
    "* The complexity of the data is high as we can see the number of rows is very high in proportion to the columns\n",
    "* Features selection techniques such as Information Value, Feature importance using Random forest(Ensembling),.etc can be used to identify the important features.\n",
    "* Lets try selecting only the potential variables using WOE/IV in our next trial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6ab271",
   "metadata": {},
   "source": [
    "### <font color= BLUE> Experiment 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f43af1",
   "metadata": {},
   "source": [
    "* <b> Identifying high explanatory variables using \"Information value\" and using those as predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2090,
   "id": "ad16f1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing library for monotonic binning to identify potential variables\n",
    "from monotonic_binning.monotonic_woe_binning import Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2091,
   "id": "f005f6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of data is numerical(continuous or discrete) we will try WOE method to calculate the Info.Value\n",
    "data_woe = pd.read_csv(\"Null Variables dropped denormalized and Knn_imputed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2092,
   "id": "8bf83e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case we will use Original imputed data which is unscaled\n",
    "numeric = data_woe.drop([\"target\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2093,
   "id": "6fe9364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the WOE Summary and Information value in dict object\n",
    "woe={}\n",
    "iv={}     \n",
    "\n",
    "#iterating through each variable in the dataset\n",
    "for i in numeric:\n",
    "    \n",
    "    # variable to bin\n",
    "    var = i  \n",
    "    \n",
    "    # target variable\n",
    "    y_var = \"target\"\n",
    "    \n",
    "    # binning based on thershold \n",
    "    bin_object = Binning(y_var, n_threshold = 50, y_threshold = 10, p_threshold = 0.35, sign=False)\n",
    "    \n",
    "    # fitting the binning object with specifications on data \n",
    "    bin_object.fit(data_woe[[y_var, var]])\n",
    "    \n",
    "    # sum of iv's of all bins variable wise\n",
    "    iv[i]=(np.sum(bin_object.woe_summary['IV_components']))\n",
    "    \n",
    "    # storing summary of each variable\n",
    "    woe[i] = bin_object.woe_summary"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e891652a",
   "metadata": {},
   "source": [
    "Typical decision criteria for choosing the variable based on IV value:\n",
    "\n",
    " Information Value   Predictive power\n",
    " \n",
    " <0.02               Useless    \n",
    " 0.02 to 0.1         Weak predictors    \n",
    " 0.1 to 0.3          Medium Predictors    \n",
    " 0.3 to 0.5          Strong predictors    \n",
    " >0.5                Suspicious    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2094,
   "id": "760cdadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Varibles selected based on Chosen Thershold: 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Info.Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>M87</td>\n",
       "      <td>0.569835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M63</td>\n",
       "      <td>0.501447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>M88</td>\n",
       "      <td>0.430760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M124</td>\n",
       "      <td>0.377283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>M148</td>\n",
       "      <td>0.362911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M28</td>\n",
       "      <td>0.332620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M66</td>\n",
       "      <td>0.321658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>M127</td>\n",
       "      <td>0.218622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M15</td>\n",
       "      <td>0.198591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M39</td>\n",
       "      <td>0.192382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>M69</td>\n",
       "      <td>0.185466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M53</td>\n",
       "      <td>0.180133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M30</td>\n",
       "      <td>0.158189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>M151</td>\n",
       "      <td>0.074704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M58</td>\n",
       "      <td>0.056745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M34</td>\n",
       "      <td>0.053250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M25</td>\n",
       "      <td>0.032649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variable  Info.Value\n",
       "11    M87     0.569835 \n",
       "8     M63     0.501447 \n",
       "12    M88     0.430760 \n",
       "13   M124     0.377283 \n",
       "15   M148     0.362911 \n",
       "2     M28     0.332620 \n",
       "9     M66     0.321658 \n",
       "14   M127     0.218622 \n",
       "0     M15     0.198591 \n",
       "5     M39     0.192382 \n",
       "10    M69     0.185466 \n",
       "6     M53     0.180133 \n",
       "3     M30     0.158189 \n",
       "16   M151     0.074704 \n",
       "7     M58     0.056745 \n",
       "4     M34     0.053250 \n",
       "1     M25     0.032649 "
      ]
     },
     "execution_count": 2094,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list to store variable names for chosen IV's\n",
    "variables = []\n",
    "values_iv = []\n",
    "\n",
    "#To be on the safer side lets choose variables whose IV's greater than 0.03 irrespective of decision criteria specified\n",
    "for key,value in iv.items():\n",
    "    if value > 0.03: #and value < 0.5:\n",
    "        variables.append(key)\n",
    "        values_iv.append(value)\n",
    "        #print(key,value)\n",
    "print(\"No of Varibles selected based on Chosen Thershold:\",len(variables))\n",
    "\n",
    "df_iv = pd.DataFrame({\"Variable\":variables,\"Info.Value\":values_iv})\n",
    "df_iv.sort_values([\"Info.Value\"],ascending=False,inplace=True)\n",
    "df_iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2095,
   "id": "023689e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try using only the variables whose IV is above the thershold\n",
    "X_train3 = data_woe[variables]\n",
    "y_train3 = data_woe[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2096,
   "id": "f6ba00cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take validation data from our previous import and chose only the same 17 variables in validation set too\n",
    "y_valid3 = df1_valid_descaled[\"target\"]\n",
    "X_valid3 = df1_valid_descaled[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2097,
   "id": "32649464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the train data with only 17potential variables \n",
    "\n",
    "# initializing the scaler object\n",
    "scaler_new = StandardScaler()\n",
    "\n",
    "# fit and transform the train data\n",
    "data_woe_scaled = scaler_new.fit_transform(X_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2098,
   "id": "5ad8cd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the validation data using the fit of train data(mean and standard deviation)\n",
    "X_valid3_scaled = scaler_new.transform(X_valid3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2099,
   "id": "7d984be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 Count: 245 Percentage: 50.0\n",
      "Class: 1 Count: 245 Percentage: 50.0\n"
     ]
    }
   ],
   "source": [
    "# Lets increase the sample size of the minority class before training the model\n",
    "\n",
    "#Initialize smote object - Sythetic Minority Oversampling Technique\n",
    "oversample = SMOTE(random_state=50)\n",
    "\n",
    "#oversampling the classes (Note:using the same scaled data from previous trial)\n",
    "X_train_psmt, y_train_psmt = oversample.fit_resample(data_woe_scaled, y_train3)\n",
    "\n",
    "# Summarizing the distribution\n",
    "counter = Counter(y_train_psmt)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_train_psmt) * 100\n",
    "    print(\"Class:\",k,\"Count:\",v,\"Percentage:\", per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2100,
   "id": "0b1f9177",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "LogisticRegression(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.80      0.59        25\n",
      "           1       0.89      0.63      0.74        63\n",
      "\n",
      "    accuracy                           0.68        88\n",
      "   macro avg       0.68      0.72      0.66        88\n",
      "weighted avg       0.77      0.68      0.70        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         40                 23        \n",
      "Actual -ve [0]          5                 20        \n",
      "____________________________________________________________________________________________________\n",
      "LinearDiscriminantAnalysis()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.80      0.60        25\n",
      "           1       0.89      0.65      0.75        63\n",
      "\n",
      "    accuracy                           0.69        88\n",
      "   macro avg       0.68      0.73      0.67        88\n",
      "weighted avg       0.77      0.69      0.71        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         41                 22        \n",
      "Actual -ve [0]          5                 20        \n",
      "____________________________________________________________________________________________________\n",
      "AdaBoostClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.64      0.60        25\n",
      "           1       0.85      0.81      0.83        63\n",
      "\n",
      "    accuracy                           0.76        88\n",
      "   macro avg       0.71      0.72      0.72        88\n",
      "weighted avg       0.77      0.76      0.77        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         51                 12        \n",
      "Actual -ve [0]          9                 16        \n",
      "____________________________________________________________________________________________________\n",
      "GradientBoostingClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.60      0.63        25\n",
      "           1       0.85      0.87      0.86        63\n",
      "\n",
      "    accuracy                           0.80        88\n",
      "   macro avg       0.75      0.74      0.74        88\n",
      "weighted avg       0.79      0.80      0.79        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         55                  8        \n",
      "Actual -ve [0]         10                 15        \n",
      "____________________________________________________________________________________________________\n",
      "RandomForestClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.56      0.62        25\n",
      "           1       0.84      0.90      0.87        63\n",
      "\n",
      "    accuracy                           0.81        88\n",
      "   macro avg       0.77      0.73      0.75        88\n",
      "weighted avg       0.80      0.81      0.80        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         57                  6        \n",
      "Actual -ve [0]         11                 14        \n",
      "____________________________________________________________________________________________________\n",
      "BaggingClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.56      0.57        25\n",
      "           1       0.83      0.84      0.83        63\n",
      "\n",
      "    accuracy                           0.76        88\n",
      "   macro avg       0.71      0.70      0.70        88\n",
      "weighted avg       0.76      0.76      0.76        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         53                 10        \n",
      "Actual -ve [0]         11                 14        \n",
      "____________________________________________________________________________________________________\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=50, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.56      0.61        25\n",
      "           1       0.84      0.89      0.86        63\n",
      "\n",
      "    accuracy                           0.80        88\n",
      "   macro avg       0.75      0.72      0.74        88\n",
      "weighted avg       0.79      0.80      0.79        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         56                  7        \n",
      "Actual -ve [0]         11                 14        \n"
     ]
    }
   ],
   "source": [
    "# Classification report of multiple models over scaled - oversampled - chosen 17 potential variables from Info Value\n",
    "for i in L1:\n",
    "    multiple_model(i,X_train_psmt, y_train_psmt,X_valid3_scaled,y_valid3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2101,
   "id": "0694f3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64        25\n",
      "           1       0.86      0.86      0.86        63\n",
      "\n",
      "    accuracy                           0.80        88\n",
      "   macro avg       0.75      0.75      0.75        88\n",
      "weighted avg       0.80      0.80      0.80        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         54                  9        \n",
      "Actual -ve [0]          9                 16        \n"
     ]
    }
   ],
   "source": [
    "# Based on the individual performance we will choose the best classifiers as our voting classifiers\n",
    "\n",
    "m1,m2,m3 = xgb,ab,gb # xgboost,gradient,adaboost\n",
    "\n",
    "voting_classifier(m1,m2,m3,X_train_psmt, y_train_psmt,X_valid3_scaled,y_valid3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2102,
   "id": "a71d6802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_aee0a\" style='display:inline; margin-right:20px;'>\n",
       "  <caption>Model's Performance on Train data</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_aee0a_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_aee0a_level0_col1\" class=\"col_heading level0 col1\" >F1_score</th>\n",
       "      <th id=\"T_aee0a_level0_col2\" class=\"col_heading level0 col2\" >Auroc</th>\n",
       "      <th id=\"T_aee0a_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_aee0a_level0_row0\" class=\"row_heading level0 row0\" >LogisticRegression</th>\n",
       "      <td id=\"T_aee0a_row0_col0\" class=\"data row0 col0\" >0.669388</td>\n",
       "      <td id=\"T_aee0a_row0_col1\" class=\"data row0 col1\" >0.655319</td>\n",
       "      <td id=\"T_aee0a_row0_col2\" class=\"data row0 col2\" >0.669388</td>\n",
       "      <td id=\"T_aee0a_row0_col3\" class=\"data row0 col3\" >0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aee0a_level0_row1\" class=\"row_heading level0 row1\" >LinearDiscriminantClassifier</th>\n",
       "      <td id=\"T_aee0a_row1_col0\" class=\"data row1 col0\" >0.673469</td>\n",
       "      <td id=\"T_aee0a_row1_col1\" class=\"data row1 col1\" >0.656652</td>\n",
       "      <td id=\"T_aee0a_row1_col2\" class=\"data row1 col2\" >0.673469</td>\n",
       "      <td id=\"T_aee0a_row1_col3\" class=\"data row1 col3\" >0.624490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aee0a_level0_row2\" class=\"row_heading level0 row2\" >AdaptiveBoosting</th>\n",
       "      <td id=\"T_aee0a_row2_col0\" class=\"data row2 col0\" >0.906122</td>\n",
       "      <td id=\"T_aee0a_row2_col1\" class=\"data row2 col1\" >0.906504</td>\n",
       "      <td id=\"T_aee0a_row2_col2\" class=\"data row2 col2\" >0.906122</td>\n",
       "      <td id=\"T_aee0a_row2_col3\" class=\"data row2 col3\" >0.910204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aee0a_level0_row3\" class=\"row_heading level0 row3\" >Gradient_Boosting</th>\n",
       "      <td id=\"T_aee0a_row3_col0\" class=\"data row3 col0\" >0.983673</td>\n",
       "      <td id=\"T_aee0a_row3_col1\" class=\"data row3 col1\" >0.983673</td>\n",
       "      <td id=\"T_aee0a_row3_col2\" class=\"data row3 col2\" >0.983673</td>\n",
       "      <td id=\"T_aee0a_row3_col3\" class=\"data row3 col3\" >0.983673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aee0a_level0_row4\" class=\"row_heading level0 row4\" >RandomForest</th>\n",
       "      <td id=\"T_aee0a_row4_col0\" class=\"data row4 col0\" >1.000000</td>\n",
       "      <td id=\"T_aee0a_row4_col1\" class=\"data row4 col1\" >1.000000</td>\n",
       "      <td id=\"T_aee0a_row4_col2\" class=\"data row4 col2\" >1.000000</td>\n",
       "      <td id=\"T_aee0a_row4_col3\" class=\"data row4 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aee0a_level0_row5\" class=\"row_heading level0 row5\" >Bagging classifier</th>\n",
       "      <td id=\"T_aee0a_row5_col0\" class=\"data row5 col0\" >0.979592</td>\n",
       "      <td id=\"T_aee0a_row5_col1\" class=\"data row5 col1\" >0.979339</td>\n",
       "      <td id=\"T_aee0a_row5_col2\" class=\"data row5 col2\" >0.979592</td>\n",
       "      <td id=\"T_aee0a_row5_col3\" class=\"data row5 col3\" >0.967347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aee0a_level0_row6\" class=\"row_heading level0 row6\" >Xg boost</th>\n",
       "      <td id=\"T_aee0a_row6_col0\" class=\"data row6 col0\" >1.000000</td>\n",
       "      <td id=\"T_aee0a_row6_col1\" class=\"data row6 col1\" >1.000000</td>\n",
       "      <td id=\"T_aee0a_row6_col2\" class=\"data row6 col2\" >1.000000</td>\n",
       "      <td id=\"T_aee0a_row6_col3\" class=\"data row6 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aee0a_level0_row7\" class=\"row_heading level0 row7\" >VotingClassifier</th>\n",
       "      <td id=\"T_aee0a_row7_col0\" class=\"data row7 col0\" >1.000000</td>\n",
       "      <td id=\"T_aee0a_row7_col1\" class=\"data row7 col1\" >1.000000</td>\n",
       "      <td id=\"T_aee0a_row7_col2\" class=\"data row7 col2\" >1.000000</td>\n",
       "      <td id=\"T_aee0a_row7_col3\" class=\"data row7 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_cdf1d\" style='display:inline'>\n",
       "  <caption>Model's Performance on Validation data </caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_cdf1d_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_cdf1d_level0_col1\" class=\"col_heading level0 col1\" >F1_score</th>\n",
       "      <th id=\"T_cdf1d_level0_col2\" class=\"col_heading level0 col2\" >Auroc</th>\n",
       "      <th id=\"T_cdf1d_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_cdf1d_level0_row0\" class=\"row_heading level0 row0\" >LogisticRegression</th>\n",
       "      <td id=\"T_cdf1d_row0_col0\" class=\"data row0 col0\" >0.681818</td>\n",
       "      <td id=\"T_cdf1d_row0_col1\" class=\"data row0 col1\" >0.740741</td>\n",
       "      <td id=\"T_cdf1d_row0_col2\" class=\"data row0 col2\" >0.717460</td>\n",
       "      <td id=\"T_cdf1d_row0_col3\" class=\"data row0 col3\" >0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cdf1d_level0_row1\" class=\"row_heading level0 row1\" >LinearDiscriminantClassifier</th>\n",
       "      <td id=\"T_cdf1d_row1_col0\" class=\"data row1 col0\" >0.693182</td>\n",
       "      <td id=\"T_cdf1d_row1_col1\" class=\"data row1 col1\" >0.752294</td>\n",
       "      <td id=\"T_cdf1d_row1_col2\" class=\"data row1 col2\" >0.725397</td>\n",
       "      <td id=\"T_cdf1d_row1_col3\" class=\"data row1 col3\" >0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cdf1d_level0_row2\" class=\"row_heading level0 row2\" >AdaptiveBoosting</th>\n",
       "      <td id=\"T_cdf1d_row2_col0\" class=\"data row2 col0\" >0.761364</td>\n",
       "      <td id=\"T_cdf1d_row2_col1\" class=\"data row2 col1\" >0.829268</td>\n",
       "      <td id=\"T_cdf1d_row2_col2\" class=\"data row2 col2\" >0.724762</td>\n",
       "      <td id=\"T_cdf1d_row2_col3\" class=\"data row2 col3\" >0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cdf1d_level0_row3\" class=\"row_heading level0 row3\" >Gradient_Boosting</th>\n",
       "      <td id=\"T_cdf1d_row3_col0\" class=\"data row3 col0\" >0.795455</td>\n",
       "      <td id=\"T_cdf1d_row3_col1\" class=\"data row3 col1\" >0.859375</td>\n",
       "      <td id=\"T_cdf1d_row3_col2\" class=\"data row3 col2\" >0.736508</td>\n",
       "      <td id=\"T_cdf1d_row3_col3\" class=\"data row3 col3\" >0.873016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cdf1d_level0_row4\" class=\"row_heading level0 row4\" >RandomForest</th>\n",
       "      <td id=\"T_cdf1d_row4_col0\" class=\"data row4 col0\" >0.806818</td>\n",
       "      <td id=\"T_cdf1d_row4_col1\" class=\"data row4 col1\" >0.870229</td>\n",
       "      <td id=\"T_cdf1d_row4_col2\" class=\"data row4 col2\" >0.732381</td>\n",
       "      <td id=\"T_cdf1d_row4_col3\" class=\"data row4 col3\" >0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cdf1d_level0_row5\" class=\"row_heading level0 row5\" >Bagging classifier</th>\n",
       "      <td id=\"T_cdf1d_row5_col0\" class=\"data row5 col0\" >0.761364</td>\n",
       "      <td id=\"T_cdf1d_row5_col1\" class=\"data row5 col1\" >0.834646</td>\n",
       "      <td id=\"T_cdf1d_row5_col2\" class=\"data row5 col2\" >0.700635</td>\n",
       "      <td id=\"T_cdf1d_row5_col3\" class=\"data row5 col3\" >0.841270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cdf1d_level0_row6\" class=\"row_heading level0 row6\" >Xg boost</th>\n",
       "      <td id=\"T_cdf1d_row6_col0\" class=\"data row6 col0\" >0.795455</td>\n",
       "      <td id=\"T_cdf1d_row6_col1\" class=\"data row6 col1\" >0.861538</td>\n",
       "      <td id=\"T_cdf1d_row6_col2\" class=\"data row6 col2\" >0.724444</td>\n",
       "      <td id=\"T_cdf1d_row6_col3\" class=\"data row6 col3\" >0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cdf1d_level0_row7\" class=\"row_heading level0 row7\" >VotingClassifier</th>\n",
       "      <td id=\"T_cdf1d_row7_col0\" class=\"data row7 col0\" >0.795455</td>\n",
       "      <td id=\"T_cdf1d_row7_col1\" class=\"data row7 col1\" >0.857143</td>\n",
       "      <td id=\"T_cdf1d_row7_col2\" class=\"data row7 col2\" >0.748571</td>\n",
       "      <td id=\"T_cdf1d_row7_col3\" class=\"data row7 col3\" >0.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the function to create dataframe\n",
    "result_frame(L2,X_train_psmt, y_train_psmt,X_valid3_scaled,y_valid3,m1,m2,m3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be3cf0a",
   "metadata": {},
   "source": [
    "<b>Remarks:\n",
    "\n",
    "* After a huge dimensionality reduction (from 147 to 17) the models still sustained to perform better in predicting the target classes which shows these are variable which could explain almost all the variance in the data.\n",
    "* Eventhough the performance of the is better compared to previous trials it could still be improved.\n",
    "* With the help of Variation inflation factor the multicollinearity between Independent variables can be identified.\n",
    "* Let us try reducing high Multicollinearity variables which where chosen using Info.Value in our next trial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53073681",
   "metadata": {},
   "source": [
    "### <font color= BLUE> Experiment 5:\n",
    "\n",
    "* <b> Identifying Multicollinear variables using Variation Inflation Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2103,
   "id": "15496195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure multiple correlation between independent variables using Rsquare\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Using Vif module calculate VIF of all variables \n",
    "vif = [variance_inflation_factor(X_train3.values, ix) for ix in range (X_train3.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2104,
   "id": "e44ca48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M15 : 8.439426150380218\n",
      "M25 : 1.74276489681869\n",
      "M28 : 13.7256891236099\n",
      "M30 : 1.4596144718897144\n",
      "M34 : 1.187990629776585\n",
      "M39 : 1.0805523664904637\n",
      "M53 : 1.6346784587629002\n",
      "M58 : 9.081514291547421\n",
      "M63 : 1.397542748516178\n",
      "M66 : 1.5663893467505094\n",
      "M69 : 11.800402146035616\n",
      "M87 : 1.3105367534723786\n",
      "M88 : 7.340626659893049\n",
      "M124 : 2.005164152506195\n",
      "M127 : 13.420617860060643\n",
      "M148 : 1.0306605705848666\n",
      "M151 : 1.1663502691697598\n"
     ]
    }
   ],
   "source": [
    "# lets have a thershold of vif as \"3\" and drop variables which ever is > that , which means that the Rsquare is < 70%. VIF=(1/1-Rsquare)\n",
    "\n",
    "i = 0\n",
    "for column in X_train3.columns:\n",
    "    # just to iterate the loop assigning counter\n",
    "    if i < 30: \n",
    "        print(column, \":\", vif[i])\n",
    "        i=i+1       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2105,
   "id": "aa1a5040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take only the above variables with less VIF for training the model\n",
    "\n",
    "X_train4 = X_train3.drop([\"M127\",\"M69\",\"M15\"],axis=1)\n",
    "y_train4 = data_woe[\"target\"]\n",
    "\n",
    "# Tried dropping variables one by one and checked the performance of the model.The results are shown after the final resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2106,
   "id": "7008428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing retained variable names\n",
    "X_train4_col = X_train4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2107,
   "id": "d55275be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 2107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of variables retained after reduction by checking Multicollinearity\n",
    "len(X_train4.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2108,
   "id": "54404258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Vif of the retained variable\n",
    "vif = [variance_inflation_factor(X_train4.values, ix) for ix in range (X_train4.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2109,
   "id": "9e0a473c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.7090926151329406,\n",
       " 3.1015564065258823,\n",
       " 1.4164022332669626,\n",
       " 1.0989523040625544,\n",
       " 1.0583734228011392,\n",
       " 1.604430799170513,\n",
       " 2.8804560328715296,\n",
       " 1.3855576607672175,\n",
       " 1.5261810524970267,\n",
       " 1.3023221742008528,\n",
       " 4.85687511037015,\n",
       " 1.9253012429331227,\n",
       " 1.0252440017996463,\n",
       " 1.1600794360203428]"
      ]
     },
     "execution_count": 2109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vif of retained varibles\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2110,
   "id": "8755be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take validation data from our previous import and chose only retained variables\n",
    "y_valid4 = df1_valid_descaled[\"target\"]\n",
    "X_valid4 = df1_valid_descaled[X_train4_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2111,
   "id": "cee888f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the train data with only 14potential variables \n",
    "\n",
    "# initializing the scaler object\n",
    "scaler_new1 = StandardScaler()\n",
    "\n",
    "# fit and transform the train data\n",
    "data_woe_scaled_vif = scaler_new1.fit_transform(X_train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2112,
   "id": "35c37118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the validation data using the fit of train data(mean and standard deviation)\n",
    "X_valid4_scaled = scaler_new1.transform(X_valid4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2113,
   "id": "9515a57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 Count: 245 Percentage: 50.0\n",
      "Class: 1 Count: 245 Percentage: 50.0\n"
     ]
    }
   ],
   "source": [
    "# Lets increase the sample size of the minority class before training the model\n",
    "\n",
    "#Initialize smote object - Sythetic Minority Oversampling Technique\n",
    "oversample = SMOTE(random_state=50)\n",
    "\n",
    "#oversampling the classes (Note:using the same scaled data from previous trial)\n",
    "X_train_vif, y_train_vif = oversample.fit_resample(data_woe_scaled_vif, y_train4)\n",
    "\n",
    "# Summarizing the distribution\n",
    "counter = Counter(y_train_vif)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_train_vif) * 100\n",
    "    print(\"Class:\",k,\"Count:\",v,\"Percentage:\", per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2114,
   "id": "e20e7794",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "LogisticRegression(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.76      0.60        25\n",
      "           1       0.88      0.70      0.78        63\n",
      "\n",
      "    accuracy                           0.72        88\n",
      "   macro avg       0.69      0.73      0.69        88\n",
      "weighted avg       0.77      0.72      0.73        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         44                 19        \n",
      "Actual -ve [0]          6                 19        \n",
      "____________________________________________________________________________________________________\n",
      "LinearDiscriminantAnalysis()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.76      0.61        25\n",
      "           1       0.88      0.71      0.79        63\n",
      "\n",
      "    accuracy                           0.73        88\n",
      "   macro avg       0.70      0.74      0.70        88\n",
      "weighted avg       0.78      0.73      0.74        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         45                 18        \n",
      "Actual -ve [0]          6                 19        \n",
      "____________________________________________________________________________________________________\n",
      "AdaBoostClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.68      0.62        25\n",
      "           1       0.86      0.79      0.83        63\n",
      "\n",
      "    accuracy                           0.76        88\n",
      "   macro avg       0.71      0.74      0.72        88\n",
      "weighted avg       0.78      0.76      0.77        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         50                 13        \n",
      "Actual -ve [0]          8                 17        \n",
      "____________________________________________________________________________________________________\n",
      "GradientBoostingClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.60      0.61        25\n",
      "           1       0.84      0.86      0.85        63\n",
      "\n",
      "    accuracy                           0.78        88\n",
      "   macro avg       0.73      0.73      0.73        88\n",
      "weighted avg       0.78      0.78      0.78        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         54                  9        \n",
      "Actual -ve [0]         10                 15        \n",
      "____________________________________________________________________________________________________\n",
      "RandomForestClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.56      0.61        25\n",
      "           1       0.84      0.89      0.86        63\n",
      "\n",
      "    accuracy                           0.80        88\n",
      "   macro avg       0.75      0.72      0.74        88\n",
      "weighted avg       0.79      0.80      0.79        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         56                  7        \n",
      "Actual -ve [0]         11                 14        \n",
      "____________________________________________________________________________________________________\n",
      "BaggingClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60        25\n",
      "           1       0.84      0.84      0.84        63\n",
      "\n",
      "    accuracy                           0.77        88\n",
      "   macro avg       0.72      0.72      0.72        88\n",
      "weighted avg       0.77      0.77      0.77        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         53                 10        \n",
      "Actual -ve [0]         10                 15        \n",
      "____________________________________________________________________________________________________\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=50, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.60      0.63        25\n",
      "           1       0.85      0.87      0.86        63\n",
      "\n",
      "    accuracy                           0.80        88\n",
      "   macro avg       0.75      0.74      0.74        88\n",
      "weighted avg       0.79      0.80      0.79        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         55                  8        \n",
      "Actual -ve [0]         10                 15        \n"
     ]
    }
   ],
   "source": [
    "# Classification report of multiple models over scaled - oversampled \n",
    "for i in L1:\n",
    "    multiple_model(i,X_train_vif, y_train_vif,X_valid4_scaled,y_valid4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2115,
   "id": "ed3531ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64        25\n",
      "           1       0.86      0.86      0.86        63\n",
      "\n",
      "    accuracy                           0.80        88\n",
      "   macro avg       0.75      0.75      0.75        88\n",
      "weighted avg       0.80      0.80      0.80        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         54                  9        \n",
      "Actual -ve [0]          9                 16        \n"
     ]
    }
   ],
   "source": [
    "# Based on the individual performance we will choose the best classifiers as our voting classifiers\n",
    "\n",
    "m1,m2,m3 = xgb,ab,gb # xgboost,gradient,adaboost\n",
    "\n",
    "voting_classifier(m1,m2,m3,X_train_vif, y_train_vif,X_valid4_scaled,y_valid4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2116,
   "id": "94c18464",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_dfd5b\" style='display:inline; margin-right:20px;'>\n",
       "  <caption>Model's Performance on Train data</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_dfd5b_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_dfd5b_level0_col1\" class=\"col_heading level0 col1\" >F1_score</th>\n",
       "      <th id=\"T_dfd5b_level0_col2\" class=\"col_heading level0 col2\" >Auroc</th>\n",
       "      <th id=\"T_dfd5b_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_dfd5b_level0_row0\" class=\"row_heading level0 row0\" >LogisticRegression</th>\n",
       "      <td id=\"T_dfd5b_row0_col0\" class=\"data row0 col0\" >0.663265</td>\n",
       "      <td id=\"T_dfd5b_row0_col1\" class=\"data row0 col1\" >0.652632</td>\n",
       "      <td id=\"T_dfd5b_row0_col2\" class=\"data row0 col2\" >0.663265</td>\n",
       "      <td id=\"T_dfd5b_row0_col3\" class=\"data row0 col3\" >0.632653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfd5b_level0_row1\" class=\"row_heading level0 row1\" >LinearDiscriminantClassifier</th>\n",
       "      <td id=\"T_dfd5b_row1_col0\" class=\"data row1 col0\" >0.667347</td>\n",
       "      <td id=\"T_dfd5b_row1_col1\" class=\"data row1 col1\" >0.655391</td>\n",
       "      <td id=\"T_dfd5b_row1_col2\" class=\"data row1 col2\" >0.667347</td>\n",
       "      <td id=\"T_dfd5b_row1_col3\" class=\"data row1 col3\" >0.632653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfd5b_level0_row2\" class=\"row_heading level0 row2\" >AdaptiveBoosting</th>\n",
       "      <td id=\"T_dfd5b_row2_col0\" class=\"data row2 col0\" >0.900000</td>\n",
       "      <td id=\"T_dfd5b_row2_col1\" class=\"data row2 col1\" >0.899384</td>\n",
       "      <td id=\"T_dfd5b_row2_col2\" class=\"data row2 col2\" >0.900000</td>\n",
       "      <td id=\"T_dfd5b_row2_col3\" class=\"data row2 col3\" >0.893878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfd5b_level0_row3\" class=\"row_heading level0 row3\" >Gradient_Boosting</th>\n",
       "      <td id=\"T_dfd5b_row3_col0\" class=\"data row3 col0\" >0.975510</td>\n",
       "      <td id=\"T_dfd5b_row3_col1\" class=\"data row3 col1\" >0.975610</td>\n",
       "      <td id=\"T_dfd5b_row3_col2\" class=\"data row3 col2\" >0.975510</td>\n",
       "      <td id=\"T_dfd5b_row3_col3\" class=\"data row3 col3\" >0.979592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfd5b_level0_row4\" class=\"row_heading level0 row4\" >RandomForest</th>\n",
       "      <td id=\"T_dfd5b_row4_col0\" class=\"data row4 col0\" >1.000000</td>\n",
       "      <td id=\"T_dfd5b_row4_col1\" class=\"data row4 col1\" >1.000000</td>\n",
       "      <td id=\"T_dfd5b_row4_col2\" class=\"data row4 col2\" >1.000000</td>\n",
       "      <td id=\"T_dfd5b_row4_col3\" class=\"data row4 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfd5b_level0_row5\" class=\"row_heading level0 row5\" >Bagging classifier</th>\n",
       "      <td id=\"T_dfd5b_row5_col0\" class=\"data row5 col0\" >0.983673</td>\n",
       "      <td id=\"T_dfd5b_row5_col1\" class=\"data row5 col1\" >0.983471</td>\n",
       "      <td id=\"T_dfd5b_row5_col2\" class=\"data row5 col2\" >0.983673</td>\n",
       "      <td id=\"T_dfd5b_row5_col3\" class=\"data row5 col3\" >0.971429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfd5b_level0_row6\" class=\"row_heading level0 row6\" >Xg boost</th>\n",
       "      <td id=\"T_dfd5b_row6_col0\" class=\"data row6 col0\" >1.000000</td>\n",
       "      <td id=\"T_dfd5b_row6_col1\" class=\"data row6 col1\" >1.000000</td>\n",
       "      <td id=\"T_dfd5b_row6_col2\" class=\"data row6 col2\" >1.000000</td>\n",
       "      <td id=\"T_dfd5b_row6_col3\" class=\"data row6 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfd5b_level0_row7\" class=\"row_heading level0 row7\" >VotingClassifier</th>\n",
       "      <td id=\"T_dfd5b_row7_col0\" class=\"data row7 col0\" >1.000000</td>\n",
       "      <td id=\"T_dfd5b_row7_col1\" class=\"data row7 col1\" >1.000000</td>\n",
       "      <td id=\"T_dfd5b_row7_col2\" class=\"data row7 col2\" >1.000000</td>\n",
       "      <td id=\"T_dfd5b_row7_col3\" class=\"data row7 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_8450e\" style='display:inline'>\n",
       "  <caption>Model's Performance on Validation data </caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8450e_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_8450e_level0_col1\" class=\"col_heading level0 col1\" >F1_score</th>\n",
       "      <th id=\"T_8450e_level0_col2\" class=\"col_heading level0 col2\" >Auroc</th>\n",
       "      <th id=\"T_8450e_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8450e_level0_row0\" class=\"row_heading level0 row0\" >LogisticRegression</th>\n",
       "      <td id=\"T_8450e_row0_col0\" class=\"data row0 col0\" >0.715909</td>\n",
       "      <td id=\"T_8450e_row0_col1\" class=\"data row0 col1\" >0.778761</td>\n",
       "      <td id=\"T_8450e_row0_col2\" class=\"data row0 col2\" >0.729206</td>\n",
       "      <td id=\"T_8450e_row0_col3\" class=\"data row0 col3\" >0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8450e_level0_row1\" class=\"row_heading level0 row1\" >LinearDiscriminantClassifier</th>\n",
       "      <td id=\"T_8450e_row1_col0\" class=\"data row1 col0\" >0.727273</td>\n",
       "      <td id=\"T_8450e_row1_col1\" class=\"data row1 col1\" >0.789474</td>\n",
       "      <td id=\"T_8450e_row1_col2\" class=\"data row1 col2\" >0.737143</td>\n",
       "      <td id=\"T_8450e_row1_col3\" class=\"data row1 col3\" >0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8450e_level0_row2\" class=\"row_heading level0 row2\" >AdaptiveBoosting</th>\n",
       "      <td id=\"T_8450e_row2_col0\" class=\"data row2 col0\" >0.761364</td>\n",
       "      <td id=\"T_8450e_row2_col1\" class=\"data row2 col1\" >0.826446</td>\n",
       "      <td id=\"T_8450e_row2_col2\" class=\"data row2 col2\" >0.736825</td>\n",
       "      <td id=\"T_8450e_row2_col3\" class=\"data row2 col3\" >0.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8450e_level0_row3\" class=\"row_heading level0 row3\" >Gradient_Boosting</th>\n",
       "      <td id=\"T_8450e_row3_col0\" class=\"data row3 col0\" >0.784091</td>\n",
       "      <td id=\"T_8450e_row3_col1\" class=\"data row3 col1\" >0.850394</td>\n",
       "      <td id=\"T_8450e_row3_col2\" class=\"data row3 col2\" >0.728571</td>\n",
       "      <td id=\"T_8450e_row3_col3\" class=\"data row3 col3\" >0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8450e_level0_row4\" class=\"row_heading level0 row4\" >RandomForest</th>\n",
       "      <td id=\"T_8450e_row4_col0\" class=\"data row4 col0\" >0.795455</td>\n",
       "      <td id=\"T_8450e_row4_col1\" class=\"data row4 col1\" >0.861538</td>\n",
       "      <td id=\"T_8450e_row4_col2\" class=\"data row4 col2\" >0.724444</td>\n",
       "      <td id=\"T_8450e_row4_col3\" class=\"data row4 col3\" >0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8450e_level0_row5\" class=\"row_heading level0 row5\" >Bagging classifier</th>\n",
       "      <td id=\"T_8450e_row5_col0\" class=\"data row5 col0\" >0.772727</td>\n",
       "      <td id=\"T_8450e_row5_col1\" class=\"data row5 col1\" >0.841270</td>\n",
       "      <td id=\"T_8450e_row5_col2\" class=\"data row5 col2\" >0.720635</td>\n",
       "      <td id=\"T_8450e_row5_col3\" class=\"data row5 col3\" >0.841270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8450e_level0_row6\" class=\"row_heading level0 row6\" >Xg boost</th>\n",
       "      <td id=\"T_8450e_row6_col0\" class=\"data row6 col0\" >0.795455</td>\n",
       "      <td id=\"T_8450e_row6_col1\" class=\"data row6 col1\" >0.859375</td>\n",
       "      <td id=\"T_8450e_row6_col2\" class=\"data row6 col2\" >0.736508</td>\n",
       "      <td id=\"T_8450e_row6_col3\" class=\"data row6 col3\" >0.873016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8450e_level0_row7\" class=\"row_heading level0 row7\" >VotingClassifier</th>\n",
       "      <td id=\"T_8450e_row7_col0\" class=\"data row7 col0\" >0.795455</td>\n",
       "      <td id=\"T_8450e_row7_col1\" class=\"data row7 col1\" >0.857143</td>\n",
       "      <td id=\"T_8450e_row7_col2\" class=\"data row7 col2\" >0.748571</td>\n",
       "      <td id=\"T_8450e_row7_col3\" class=\"data row7 col3\" >0.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the function to create dataframe\n",
    "result_frame(L2,X_train_vif, y_train_vif,X_valid4_scaled,y_valid4,m1,m2,m3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "81d036c0",
   "metadata": {},
   "source": [
    "# Result observations by dropping the high multicollinear variables one after the other.\n",
    "\n",
    "\n",
    "-->dropping M127\n",
    "\n",
    "Model's Performance on Validation data\n",
    "\n",
    "                                 Accuracy\tF1_score\tAuroc\tRecall\n",
    "            LogisticRegression  0.693182\t0.752294\t0.725397\t0.650794\n",
    "  LinearDiscriminantClassifier\t0.693182\t0.752294\t0.725397\t0.650794\n",
    "            AdaptiveBoosting\t0.784091\t0.845528\t0.752698\t0.825397\n",
    "            Gradient_Boosting\t0.818182\t0.876923\t0.752381\t0.904762\n",
    "                RandomForest\t0.784091\t0.850394\t0.728571\t0.857143\n",
    "            Bagging classifier\t0.727273\t0.806452\t0.676825\t0.793651\n",
    "                    Xg boost\t0.806818\t0.868217\t0.744444\t0.888889\n",
    "            VotingClassifier\t0.818182\t0.875000\t0.764444\t0.888889\n",
    "-------------------------------------------------------------------------------------------------------------------------------            \n",
    "-->dropping M127 and M69            \n",
    "\n",
    "Model's Performance on Validation data\n",
    "\n",
    "                                Accuracy\tF1_score\tAuroc\tRecall\n",
    "            LogisticRegression\t0.715909\t0.778761\t0.729206\t0.698413\n",
    "LinearDiscriminantClassifier\t0.704545\t0.767857\t0.721270\t0.682540\n",
    "            AdaptiveBoosting\t0.784091\t0.850394\t0.728571\t0.857143\n",
    "            Gradient_Boosting\t0.806818\t0.868217\t0.744444\t0.888889\n",
    "                RandomForest\t0.795455\t0.857143\t0.748571\t0.857143\n",
    "            Bagging classifier\t0.806818\t0.866142\t0.756508\t0.873016\n",
    "                    Xg boost\t0.795455\t0.859375\t0.736508\t0.873016\n",
    "            VotingClassifier\t0.784091\t0.852713\t0.716508\t0.873016            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef9a04b",
   "metadata": {},
   "source": [
    "<b> Remark:\n",
    "\n",
    "* The performance of the model after dropping high VIF value variables doesnt seem to improve more significantly but the dimension complexity has still fallen down compared to the trial where we didnt drop multicollinear varibles.\n",
    "* We can see the performance of Linear discriminant model has improved very well which was affected by multicollinearity in previous case.    \n",
    "* Lets try using WOE values to transform the variables based on bin range and see the performance of the model in our next trial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a75aa5",
   "metadata": {},
   "source": [
    "### <font color= BLUE> Experiment 6:\n",
    "\n",
    "* <b> Feature transformation using WOE values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2117,
   "id": "b108636a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>M25</th>\n",
       "      <th>M28</th>\n",
       "      <th>M30</th>\n",
       "      <th>M34</th>\n",
       "      <th>M39</th>\n",
       "      <th>M53</th>\n",
       "      <th>M58</th>\n",
       "      <th>M63</th>\n",
       "      <th>M66</th>\n",
       "      <th>M87</th>\n",
       "      <th>M88</th>\n",
       "      <th>M124</th>\n",
       "      <th>M148</th>\n",
       "      <th>M151</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.700000e+07</td>\n",
       "      <td>2.358491</td>\n",
       "      <td>1.278607e+08</td>\n",
       "      <td>0.040450</td>\n",
       "      <td>4.000000e+06</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.800000e+07</td>\n",
       "      <td>-4.826130e+07</td>\n",
       "      <td>596624.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.137554</td>\n",
       "      <td>0.914831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.234333e+07</td>\n",
       "      <td>3.391304</td>\n",
       "      <td>2.199603e+07</td>\n",
       "      <td>1.803985</td>\n",
       "      <td>2.332033e+08</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.608099e+07</td>\n",
       "      <td>5.317400e+04</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.940661</td>\n",
       "      <td>1.016467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.616667e+06</td>\n",
       "      <td>0.582734</td>\n",
       "      <td>4.246794e+06</td>\n",
       "      <td>1.181445</td>\n",
       "      <td>-8.140667e+06</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.821839e+07</td>\n",
       "      <td>-1.120641e+07</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.007713</td>\n",
       "      <td>0.988912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.540000e+07</td>\n",
       "      <td>0.570909</td>\n",
       "      <td>6.375040e+07</td>\n",
       "      <td>1.015880</td>\n",
       "      <td>2.400000e+08</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.543467e+07</td>\n",
       "      <td>2.509527e+07</td>\n",
       "      <td>-3463893.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.504471</td>\n",
       "      <td>0.483688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.000000e+07</td>\n",
       "      <td>6.909091</td>\n",
       "      <td>6.912100e+04</td>\n",
       "      <td>5.559125</td>\n",
       "      <td>-2.500000e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.000000e+06</td>\n",
       "      <td>6.818941e+07</td>\n",
       "      <td>14300.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2815.070183</td>\n",
       "      <td>0.600029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        M25         M28         M30         M34         M39         M53    M58       M63           M66         M87      M88  M124     M148        M151  \n",
       "0  4.700000e+07  2.358491  1.278607e+08  0.040450  4.000000e+06  7.500000  0.0 -7.800000e+07 -4.826130e+07   596624.0  34.0   6.0     1.137554  0.914831\n",
       "1  1.234333e+07  3.391304  2.199603e+07  1.803985  2.332033e+08  1.666667  1.0 -5.608099e+07  5.317400e+04    22000.0  80.0   1.0     0.940661  1.016467\n",
       "2  3.616667e+06  0.582734  4.246794e+06  1.181445 -8.140667e+06  0.066667  0.0 -1.821839e+07 -1.120641e+07     3300.0  22.0   0.0     1.007713  0.988912\n",
       "3  7.540000e+07  0.570909  6.375040e+07  1.015880  2.400000e+08  0.200000  0.0 -7.543467e+07  2.509527e+07 -3463893.0  22.0  12.0     1.504471  0.483688\n",
       "4  3.000000e+07  6.909091  6.912100e+04  5.559125 -2.500000e+07  1.000000  0.0 -4.000000e+06  6.818941e+07    14300.0  65.0  20.0  2815.070183  0.600029"
      ]
     },
     "execution_count": 2117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variables chosen using Info.Value and Multicollinearity check\n",
    "new_data_train = data_woe[X_train4_col]\n",
    "new_data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2118,
   "id": "52c01110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Index(['M25', 'M28', 'M30', 'M34', 'M39', 'M53', 'M58', 'M63', 'M66', 'M87', 'M88', 'M124', 'M148', 'M151'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(len(new_data_train.columns))\n",
    "print(new_data_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2119,
   "id": "967872cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the train data in new variable\n",
    "woe_transformed_train_data = new_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2120,
   "id": "35207366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>M25</th>\n",
       "      <th>M28</th>\n",
       "      <th>M30</th>\n",
       "      <th>M34</th>\n",
       "      <th>M39</th>\n",
       "      <th>M53</th>\n",
       "      <th>M58</th>\n",
       "      <th>M63</th>\n",
       "      <th>M66</th>\n",
       "      <th>M87</th>\n",
       "      <th>M88</th>\n",
       "      <th>M124</th>\n",
       "      <th>M148</th>\n",
       "      <th>M151</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        M25       M28       M30       M34       M39       M53       M58       M63       M66       M87       M88      M124      M148      M151  \n",
       "0   -0.126151 -0.254167  0.038050  0.464955 -0.419247 -0.891287  0.240643  0.695302  0.800079 -0.577978 -0.040593 -0.815004  0.035225  0.413662\n",
       "1   -0.126151 -0.623581  0.038050 -0.115036 -0.419247  0.016565 -0.236926  0.695302 -0.413017 -0.577978 -0.741646  0.259511  0.035225 -0.181721\n",
       "2    0.259511  0.825907  0.335700 -0.115036 -0.186395  0.398624  0.240643 -0.577530  0.800079 -0.421660  0.813048  0.652073  0.035225 -0.181721\n",
       "3   -0.126151  0.825907  0.038050 -0.115036 -0.419247  0.398624  0.240643  0.695302 -0.413017  1.158102  0.813048 -0.815004 -0.727875  0.413662\n",
       "4   -0.126151 -0.623581  0.335700 -0.115036 -0.186395  0.016565  0.240643 -0.577530 -0.413017 -0.421660 -0.741646 -0.815004 -0.727875  0.413662\n",
       "5   -0.126151 -0.254167 -0.780261 -0.115036 -0.419247  0.398624 -0.236926  0.695302 -0.413017 -0.421660 -0.741646  0.259511 -0.727875 -0.181721\n",
       "6   -0.126151 -0.623581  0.038050 -0.115036 -0.419247 -0.891287 -0.236926 -0.577530 -0.413017 -0.577978 -0.741646  0.259511 -0.727875  0.413662\n",
       "7    0.259511  0.825907  0.038050 -0.115036 -0.186395  0.398624  0.240643  0.695302  0.800079  1.158102  0.813048  0.259511  0.747435 -0.181721\n",
       "8   -0.126151  0.825907  0.038050 -0.115036 -0.186395  0.016565 -0.236926 -0.988137 -0.413017 -0.421660 -0.741646 -0.815004  0.035225 -0.181721\n",
       "9   -0.126151 -0.254167  0.038050 -0.115036 -0.419247  0.016565  0.240643  0.695302 -0.413017  1.158102 -0.741646  0.652073  0.747435 -0.181721\n",
       "10  -0.126151 -0.623581 -0.780261 -0.115036 -0.419247  0.398624 -0.236926  0.695302 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875  0.413662\n",
       "11   0.259511 -0.623581  0.335700 -0.115036 -0.186395 -0.891287  0.240643  0.695302 -0.413017 -0.421660  0.813048  0.259511 -0.727875 -0.181721\n",
       "12  -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.398624  0.240643  0.695302  0.800079 -0.421660  0.813048  0.652073  0.035225 -0.181721\n",
       "13   0.259511  0.825907  0.335700 -0.115036 -0.419247  0.398624  0.240643  0.695302 -0.413017  1.158102  0.813048 -0.815004  0.035225  0.413662\n",
       "14  -0.126151 -0.254167  0.335700 -0.115036 -0.186395  0.016565 -0.236926 -0.577530 -0.413017 -0.421660 -0.040593 -0.815004  0.747435 -0.181721\n",
       "15  -0.126151  0.825907  0.335700  0.464955  0.809558  0.016565  0.240643  0.695302 -0.413017  1.158102 -0.040593  0.259511  0.035225  0.413662\n",
       "16  -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.016565 -0.236926 -0.577530 -0.413017 -0.577978 -0.741646  0.259511  0.035225 -0.181721\n",
       "17   0.259511 -0.623581  0.038050  0.464955 -0.186395  0.016565 -0.236926 -0.988137 -0.413017 -0.421660  0.813048 -0.815004  0.035225 -0.181721\n",
       "18  -0.126151 -0.623581  0.038050  0.464955 -0.186395  0.398624  0.240643 -0.577530 -0.413017 -0.577978 -0.741646  0.652073 -0.727875 -0.181721\n",
       "19  -0.126151 -0.254167 -0.780261 -0.115036 -0.186395  0.398624 -0.236926 -0.577530 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "20  -0.126151  0.825907  0.335700  0.464955  0.809558  0.398624 -0.236926  0.695302  0.800079 -0.577978  0.813048  0.259511  0.035225 -0.181721\n",
       "21  -0.126151 -0.254167  0.335700  0.464955 -0.186395  0.398624 -0.236926  0.695302 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "22  -0.126151 -0.254167  0.335700 -0.115036  0.809558  0.016565  0.240643  0.695302 -0.413017 -0.421660  0.813048  0.652073  0.035225  0.413662\n",
       "23  -0.126151  0.825907  0.038050  0.464955  0.809558  0.398624 -0.236926 -0.988137 -0.413017 -0.421660 -0.040593 -0.815004  0.747435 -0.181721\n",
       "24  -0.126151 -0.623581 -0.780261 -0.115036 -0.186395 -0.891287  0.240643 -0.577530 -0.413017 -0.577978 -0.040593 -0.815004 -0.727875  0.413662\n",
       "25  -0.126151 -0.254167 -0.780261 -0.115036 -0.419247  0.016565 -0.236926 -0.988137 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "26  -0.126151 -0.623581  0.038050 -0.115036 -0.186395 -0.891287  0.240643 -0.988137 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875  0.413662\n",
       "27  -0.126151 -0.623581  0.038050 -0.115036 -0.186395  0.016565 -0.236926  0.695302 -0.413017 -0.421660 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "28  -0.126151 -0.623581  0.038050 -0.115036 -0.186395  0.016565 -0.236926  0.695302  0.800079 -0.421660 -0.741646  0.259511 -0.727875 -0.181721\n",
       "29  -0.126151 -0.623581  0.335700  0.464955 -0.186395  0.398624  0.240643 -0.577530 -0.413017 -0.421660 -0.741646  0.652073 -0.727875 -0.181721\n",
       "30  -0.126151 -0.623581 -0.780261 -0.115036 -0.186395  0.398624  0.240643 -0.988137 -0.413017 -0.421660 -0.040593 -0.815004 -0.727875 -0.181721\n",
       "31  -0.126151  0.825907 -0.780261 -0.115036 -0.186395  0.398624 -0.236926  0.695302 -0.413017  1.158102  0.813048  0.259511  0.747435 -0.181721\n",
       "32  -0.126151  0.825907 -0.780261  0.464955 -0.419247  0.016565 -0.236926 -0.577530 -0.413017 -0.577978 -0.040593  0.259511  0.035225 -0.181721\n",
       "33  -0.126151  0.825907 -0.780261 -0.115036 -0.419247  0.016565 -0.236926  0.695302 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "34  -0.126151  0.825907  0.038050 -0.115036 -0.186395  0.016565  0.240643  0.695302 -0.413017  1.158102  0.813048  0.652073  0.747435 -0.181721\n",
       "35  -0.126151 -0.254167  0.038050 -0.115036 -0.186395 -0.891287  0.240643 -0.988137  0.800079 -0.577978  0.813048 -0.815004  0.035225 -0.181721\n",
       "36  -0.126151  0.825907  0.038050 -0.115036 -0.419247  0.398624 -0.236926  0.695302  0.800079  1.158102  0.813048 -0.815004  0.035225 -0.181721\n",
       "37   0.259511 -0.254167  0.335700  0.464955 -0.186395  0.398624  0.240643 -0.577530 -0.413017 -0.421660 -0.040593  0.652073  0.747435 -0.181721\n",
       "38  -0.126151 -0.623581 -0.780261  0.464955 -0.186395 -0.891287  0.240643 -0.577530 -0.413017 -0.577978 -0.741646 -0.815004  0.035225 -0.181721\n",
       "39  -0.126151 -0.254167 -0.780261 -0.115036  0.809558  0.016565 -0.236926  0.695302 -0.413017  1.158102 -0.741646  0.259511  0.035225  0.413662\n",
       "40   0.259511 -0.254167  0.335700 -0.115036 -0.186395  0.016565  0.240643 -0.577530 -0.413017 -0.577978  0.813048  0.259511  0.035225 -0.181721\n",
       "41   0.259511 -0.623581  0.038050 -0.115036 -0.186395  0.016565 -0.236926 -0.577530 -0.413017 -0.577978 -0.741646  0.259511 -0.727875  0.413662\n",
       "42   0.259511  0.825907  0.335700 -0.115036 -0.419247  0.398624  0.240643 -0.577530 -0.413017 -0.421660  0.813048 -0.815004  0.035225 -0.181721\n",
       "43   0.259511 -0.254167  0.038050 -0.115036 -0.186395 -0.891287  0.240643  0.695302  0.800079 -0.577978  0.813048  0.652073 -0.727875 -0.181721\n",
       "44   0.259511  0.825907  0.335700 -0.115036 -0.186395  0.398624  0.240643  0.695302  0.800079 -0.577978 -0.040593  0.652073  0.035225 -0.181721\n",
       "45  -0.126151  0.825907  0.038050 -0.115036 -0.186395 -0.891287  0.240643  0.695302 -0.413017 -0.577978  0.813048  0.652073 -0.727875 -0.181721\n",
       "46  -0.126151 -0.254167  0.038050 -0.115036  0.809558  0.398624 -0.236926  0.695302  0.800079  1.158102  0.813048  0.652073  0.747435 -0.181721\n",
       "47   0.259511 -0.254167  0.335700 -0.115036 -0.186395  0.016565  0.240643 -0.577530 -0.413017 -0.577978 -0.741646  0.652073 -0.727875  0.413662\n",
       "48  -0.126151 -0.623581  0.038050 -0.115036 -0.186395 -0.891287  0.240643  0.695302  0.800079  1.158102 -0.040593  0.652073  0.747435 -0.181721\n",
       "49  -0.126151 -0.254167 -0.780261 -0.115036 -0.186395  0.016565 -0.236926 -0.577530  0.800079 -0.421660 -0.040593  0.259511  0.747435 -0.181721\n",
       "50   0.259511  0.825907 -0.780261 -0.115036  0.809558  0.398624  0.240643  0.695302  0.800079  1.158102  0.813048  0.652073  0.747435 -0.181721\n",
       "51  -0.126151  0.825907  0.038050 -0.115036 -0.186395  0.016565  0.240643 -0.577530 -0.413017  1.158102 -0.040593  0.652073  0.747435 -0.181721\n",
       "52   0.259511 -0.623581 -0.780261 -0.115036 -0.186395 -0.891287  0.240643 -0.577530  0.800079 -0.577978 -0.040593 -0.815004 -0.727875 -0.181721\n",
       "53  -0.126151 -0.254167 -0.780261 -0.115036 -0.186395  0.016565 -0.236926 -0.988137 -0.413017 -0.577978 -0.741646 -0.815004  0.035225 -0.181721\n",
       "54   0.259511 -0.623581  0.038050 -0.115036 -0.186395 -0.891287 -0.236926  0.695302 -0.413017 -0.577978  0.813048  0.259511 -0.727875  0.413662\n",
       "55  -0.126151 -0.254167  0.335700 -0.115036  0.809558 -0.891287  0.240643 -0.988137 -0.413017 -0.421660  0.813048  0.259511 -0.727875 -0.181721\n",
       "56   0.259511 -0.254167  0.335700 -0.115036  0.809558  0.016565  0.240643 -0.577530 -0.413017 -0.421660 -0.040593 -0.815004  0.747435 -0.181721\n",
       "57  -0.126151 -0.623581 -0.780261 -0.115036 -0.186395  0.016565 -0.236926 -0.988137 -0.413017 -0.577978 -0.741646  0.259511 -0.727875  0.413662\n",
       "58  -0.126151 -0.623581 -0.780261 -0.115036 -0.186395  0.016565 -0.236926 -0.577530 -0.413017 -0.421660 -0.741646  0.259511 -0.727875  0.413662\n",
       "59   0.259511 -0.623581  0.335700 -0.115036 -0.186395 -0.891287  0.240643 -0.988137  0.800079 -0.577978 -0.040593 -0.815004 -0.727875  0.413662\n",
       "60   0.259511 -0.623581  0.038050 -0.115036 -0.186395  0.016565 -0.236926 -0.988137  0.800079 -0.577978 -0.040593 -0.815004 -0.727875  0.413662\n",
       "61   0.259511 -0.623581  0.335700 -0.115036 -0.186395 -0.891287 -0.236926 -0.577530 -0.413017 -0.577978 -0.040593  0.259511 -0.727875 -0.181721\n",
       "62  -0.126151  0.825907  0.038050 -0.115036 -0.186395  0.398624 -0.236926 -0.577530 -0.413017 -0.421660 -0.741646  0.259511  0.035225 -0.181721\n",
       "63  -0.126151  0.825907  0.038050 -0.115036 -0.186395  0.398624  0.240643  0.695302  0.800079  1.158102 -0.741646  0.652073  0.747435  0.413662\n",
       "64  -0.126151 -0.254167  0.335700 -0.115036  0.809558  0.016565  0.240643  0.695302  0.800079 -0.421660 -0.040593  0.652073  0.035225  0.413662\n",
       "65  -0.126151  0.825907 -0.780261 -0.115036 -0.419247  0.016565 -0.236926 -0.988137 -0.413017 -0.421660 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "66  -0.126151 -0.254167  0.038050 -0.115036 -0.419247  0.016565 -0.236926 -0.577530 -0.413017 -0.577978 -0.741646  0.259511  0.747435  0.413662\n",
       "67   0.259511 -0.623581  0.335700 -0.115036 -0.186395 -0.891287  0.240643 -0.577530  0.800079 -0.577978 -0.040593  0.652073 -0.727875 -0.181721\n",
       "68  -0.126151 -0.623581 -0.780261 -0.115036 -0.186395 -0.891287  0.240643 -0.988137 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875  0.413662\n",
       "69  -0.126151 -0.254167  0.335700  0.464955  0.809558  0.016565  0.240643 -0.577530  0.800079 -0.577978 -0.040593  0.652073  0.035225  0.413662\n",
       "70  -0.126151 -0.254167 -0.780261 -0.115036 -0.419247  0.398624 -0.236926  0.695302 -0.413017 -0.421660 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "71  -0.126151 -0.254167  0.335700  0.464955  0.809558  0.016565 -0.236926 -0.577530  0.800079 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "72  -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.016565  0.240643 -0.577530 -0.413017 -0.421660  0.813048 -0.815004 -0.727875 -0.181721\n",
       "73  -0.126151  0.825907 -0.780261 -0.115036  0.809558  0.398624 -0.236926  0.695302 -0.413017  1.158102 -0.741646 -0.815004  0.035225 -0.181721\n",
       "74  -0.126151 -0.623581 -0.780261 -0.115036 -0.419247  0.016565  0.240643 -0.577530 -0.413017 -0.421660 -0.741646  0.652073 -0.727875 -0.181721\n",
       "75   0.259511 -0.254167  0.335700 -0.115036  0.809558 -0.891287 -0.236926 -0.988137 -0.413017 -0.421660 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "76  -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.016565 -0.236926 -0.577530 -0.413017 -0.421660 -0.040593 -0.815004  0.035225 -0.181721\n",
       "77  -0.126151  0.825907  0.038050  0.464955 -0.186395  0.398624 -0.236926  0.695302  0.800079 -0.577978 -0.741646  0.259511 -0.727875  0.413662\n",
       "78  -0.126151 -0.254167  0.335700 -0.115036 -0.186395  0.016565  0.240643  0.695302  0.800079 -0.577978 -0.040593  0.652073  0.035225 -0.181721\n",
       "79  -0.126151 -0.254167 -0.780261 -0.115036 -0.419247 -0.891287 -0.236926  0.695302  0.800079 -0.577978 -0.741646 -0.815004  0.747435 -0.181721\n",
       "80  -0.126151 -0.254167  0.038050 -0.115036 -0.186395 -0.891287 -0.236926  0.695302 -0.413017 -0.577978 -0.040593  0.259511  0.747435 -0.181721\n",
       "81  -0.126151  0.825907  0.038050 -0.115036 -0.186395  0.398624 -0.236926  0.695302 -0.413017  1.158102 -0.040593 -0.815004 -0.727875 -0.181721\n",
       "82  -0.126151 -0.623581  0.038050 -0.115036 -0.186395 -0.891287  0.240643  0.695302 -0.413017 -0.577978 -0.741646  0.652073 -0.727875 -0.181721\n",
       "83  -0.126151 -0.623581 -0.780261 -0.115036 -0.186395 -0.891287  0.240643 -0.577530  0.800079 -0.577978 -0.741646 -0.815004 -0.727875  0.413662\n",
       "84  -0.126151 -0.254167 -0.780261 -0.115036  0.809558 -0.891287 -0.236926  0.695302 -0.413017 -0.577978  0.813048  0.259511  0.747435 -0.181721\n",
       "85  -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.016565  0.240643 -0.988137  0.800079 -0.577978 -0.040593 -0.815004 -0.727875 -0.181721\n",
       "86   0.259511  0.825907  0.038050  0.464955 -0.186395  0.016565 -0.236926  0.695302 -0.413017 -0.421660 -0.741646  0.259511  0.747435  0.413662\n",
       "87  -0.126151 -0.254167 -0.780261 -0.115036 -0.186395  0.398624 -0.236926 -0.577530 -0.413017 -0.577978 -0.741646  0.259511 -0.727875 -0.181721\n",
       "88  -0.126151 -0.254167  0.038050 -0.115036 -0.186395 -0.891287  0.240643 -0.988137  0.800079 -0.421660 -0.040593 -0.815004 -0.727875 -0.181721\n",
       "89  -0.126151 -0.254167  0.335700 -0.115036 -0.186395  0.016565 -0.236926  0.695302  0.800079 -0.421660 -0.040593  0.259511  0.747435 -0.181721\n",
       "90  -0.126151 -0.254167  0.335700 -0.115036 -0.186395  0.398624 -0.236926 -0.988137 -0.413017 -0.577978 -0.741646 -0.815004  0.747435  0.413662\n",
       "91  -0.126151  0.825907  0.335700 -0.115036  0.809558  0.016565  0.240643 -0.988137 -0.413017 -0.421660  0.813048 -0.815004  0.035225 -0.181721\n",
       "92  -0.126151  0.825907  0.335700 -0.115036 -0.186395  0.398624  0.240643  0.695302  0.800079  1.158102  0.813048  0.652073  0.747435  0.413662\n",
       "93  -0.126151 -0.623581 -0.780261 -0.115036 -0.186395 -0.891287 -0.236926  0.695302 -0.413017 -0.577978 -0.741646  0.259511  0.035225 -0.181721\n",
       "94  -0.126151 -0.254167 -0.780261  0.464955 -0.186395  0.016565 -0.236926 -0.577530 -0.413017  1.158102 -0.040593  0.259511 -0.727875 -0.181721\n",
       "95   0.259511 -0.623581  0.335700 -0.115036 -0.186395  0.016565 -0.236926 -0.577530 -0.413017 -0.421660 -0.040593 -0.815004 -0.727875 -0.181721\n",
       "96  -0.126151 -0.254167  0.335700 -0.115036  0.809558  0.016565 -0.236926  0.695302 -0.413017 -0.577978 -0.040593  0.259511  0.035225 -0.181721\n",
       "97  -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.016565 -0.236926 -0.988137 -0.413017 -0.421660 -0.741646 -0.815004  0.747435 -0.181721\n",
       "98   0.259511 -0.254167  0.335700 -0.115036 -0.186395  0.016565 -0.236926 -0.577530 -0.413017 -0.421660  0.813048  0.259511  0.035225 -0.181721\n",
       "99  -0.126151 -0.254167  0.038050  0.464955 -0.419247  0.398624 -0.236926  0.695302  0.800079 -0.577978 -0.741646  0.259511  0.747435 -0.181721\n",
       "100 -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.016565  0.240643 -0.988137 -0.413017 -0.421660 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "101  0.259511  0.825907 -0.780261  0.464955 -0.186395  0.398624  0.240643  0.695302 -0.413017  1.158102  0.813048  0.652073  0.747435  0.413662\n",
       "102 -0.126151 -0.623581 -0.780261  0.464955 -0.419247  0.016565 -0.236926 -0.577530 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "103 -0.126151 -0.623581  0.038050 -0.115036 -0.186395  0.016565 -0.236926  0.695302 -0.413017 -0.577978 -0.741646  0.259511 -0.727875  0.413662\n",
       "104 -0.126151  0.825907  0.038050 -0.115036 -0.186395  0.398624 -0.236926 -0.577530 -0.413017  1.158102 -0.040593  0.259511  0.747435  0.413662\n",
       "105  0.259511 -0.254167  0.335700 -0.115036 -0.186395  0.016565  0.240643 -0.988137 -0.413017 -0.577978  0.813048 -0.815004  0.035225 -0.181721\n",
       "106 -0.126151 -0.623581  0.335700 -0.115036  0.809558  0.016565  0.240643  0.695302 -0.413017 -0.577978 -0.040593 -0.815004  0.747435 -0.181721\n",
       "107  0.259511  0.825907  0.038050  0.464955 -0.186395  0.398624 -0.236926  0.695302  0.800079  1.158102  0.813048  0.259511  0.747435 -0.181721\n",
       "108  0.259511 -0.623581  0.038050 -0.115036  0.809558 -0.891287  0.240643  0.695302 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875  0.413662\n",
       "109  0.259511  0.825907  0.038050 -0.115036 -0.186395  0.398624 -0.236926 -0.577530 -0.413017  1.158102  0.813048 -0.815004  0.747435  0.413662\n",
       "110 -0.126151 -0.254167 -0.780261 -0.115036 -0.186395  0.398624 -0.236926  0.695302 -0.413017 -0.421660 -0.741646 -0.815004 -0.727875  0.413662\n",
       "111  0.259511 -0.623581 -0.780261 -0.115036 -0.186395 -0.891287 -0.236926 -0.988137  0.800079 -0.577978 -0.741646  0.259511 -0.727875  0.413662\n",
       "112 -0.126151  0.825907  0.335700 -0.115036 -0.186395  0.398624 -0.236926 -0.577530 -0.413017 -0.421660 -0.741646 -0.815004  0.747435 -0.181721\n",
       "113 -0.126151 -0.254167 -0.780261 -0.115036 -0.419247  0.398624 -0.236926 -0.577530 -0.413017 -0.421660 -0.741646 -0.815004  0.035225  0.413662\n",
       "114 -0.126151 -0.254167 -0.780261 -0.115036 -0.419247  0.016565 -0.236926  0.695302 -0.413017 -0.421660 -0.741646  0.259511  0.747435 -0.181721\n",
       "115 -0.126151 -0.254167  0.335700 -0.115036 -0.186395  0.398624  0.240643 -0.577530 -0.413017 -0.577978 -0.741646  0.652073  0.035225  0.413662\n",
       "116 -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.398624 -0.236926  0.695302 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "117  0.259511 -0.623581  0.335700 -0.115036 -0.186395 -0.891287  0.240643 -0.988137 -0.413017 -0.577978 -0.040593 -0.815004 -0.727875 -0.181721\n",
       "118  0.259511 -0.254167  0.335700  0.464955 -0.186395  0.016565 -0.236926  0.695302  0.800079 -0.577978  0.813048  0.259511  0.747435 -0.181721\n",
       "119 -0.126151 -0.623581  0.335700 -0.115036 -0.186395 -0.891287  0.240643 -0.577530 -0.413017 -0.421660 -0.040593 -0.815004 -0.727875 -0.181721\n",
       "120  0.259511 -0.254167  0.335700 -0.115036 -0.186395 -0.891287 -0.236926 -0.988137 -0.413017 -0.421660  0.813048 -0.815004  0.035225 -0.181721\n",
       "121 -0.126151 -0.623581  0.335700 -0.115036 -0.186395  0.016565 -0.236926  0.695302  0.800079 -0.421660 -0.741646  0.259511  0.035225 -0.181721\n",
       "122 -0.126151 -0.623581  0.335700 -0.115036  0.809558  0.398624 -0.236926 -0.988137  0.800079 -0.577978 -0.741646 -0.815004  0.747435 -0.181721\n",
       "123 -0.126151 -0.254167 -0.780261 -0.115036 -0.186395  0.016565  0.240643  0.695302 -0.413017 -0.577978 -0.741646  0.652073  0.747435 -0.181721\n",
       "124  0.259511  0.825907  0.335700 -0.115036  0.809558  0.398624  0.240643  0.695302 -0.413017 -0.577978  0.813048  0.259511  0.747435 -0.181721\n",
       "125 -0.126151 -0.623581  0.038050 -0.115036 -0.186395  0.016565  0.240643  0.695302 -0.413017 -0.577978 -0.741646  0.652073  0.035225 -0.181721\n",
       "126  0.259511 -0.623581  0.335700 -0.115036 -0.186395 -0.891287 -0.236926  0.695302 -0.413017 -0.421660 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "127 -0.126151 -0.254167  0.038050 -0.115036  0.809558  0.016565  0.240643 -0.577530 -0.413017 -0.421660 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "128  0.259511  0.825907  0.038050 -0.115036 -0.186395  0.016565 -0.236926 -0.577530  0.800079  1.158102  0.813048  0.652073  0.035225  0.413662\n",
       "129 -0.126151 -0.623581  0.038050 -0.115036  0.809558 -0.891287  0.240643  0.695302 -0.413017 -0.577978 -0.741646  0.259511 -0.727875 -0.181721\n",
       "130 -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.398624 -0.236926 -0.988137 -0.413017 -0.577978 -0.741646  0.259511  0.035225 -0.181721\n",
       "131 -0.126151 -0.623581  0.038050  0.464955 -0.186395 -0.891287 -0.236926 -0.577530 -0.413017 -0.421660 -0.040593  0.259511 -0.727875 -0.181721\n",
       "132 -0.126151 -0.623581 -0.780261 -0.115036 -0.419247  0.016565 -0.236926  0.695302 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875  0.413662\n",
       "133  0.259511 -0.623581  0.335700 -0.115036 -0.419247  0.016565  0.240643 -0.577530 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "134 -0.126151 -0.254167  0.335700 -0.115036 -0.186395  0.016565 -0.236926 -0.577530  0.800079 -0.577978  0.813048 -0.815004  0.035225 -0.181721\n",
       "135 -0.126151 -0.623581  0.335700 -0.115036 -0.419247 -0.891287  0.240643  0.695302 -0.413017 -0.577978 -0.741646  0.652073  0.747435 -0.181721\n",
       "136 -0.126151 -0.623581 -0.780261 -0.115036 -0.186395  0.398624 -0.236926 -0.577530  0.800079 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "137  0.259511 -0.254167  0.038050 -0.115036 -0.186395  0.016565  0.240643 -0.988137 -0.413017  1.158102 -0.040593 -0.815004  0.035225 -0.181721\n",
       "138  0.259511  0.825907  0.335700 -0.115036 -0.186395  0.016565 -0.236926  0.695302  0.800079  1.158102  0.813048  0.652073  0.035225 -0.181721\n",
       "139 -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.016565 -0.236926 -0.577530 -0.413017 -0.421660 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "140 -0.126151 -0.254167  0.038050 -0.115036 -0.419247  0.016565 -0.236926 -0.988137 -0.413017 -0.421660 -0.741646  0.259511 -0.727875  0.413662\n",
       "141 -0.126151 -0.254167  0.335700 -0.115036 -0.419247  0.016565 -0.236926  0.695302 -0.413017 -0.577978  0.813048  0.259511  0.035225 -0.181721\n",
       "142  0.259511  0.825907  0.038050  0.464955 -0.186395  0.016565  0.240643 -0.577530 -0.413017  1.158102  0.813048  0.652073  0.035225  0.413662\n",
       "143 -0.126151  0.825907  0.335700 -0.115036  0.809558  0.398624  0.240643 -0.577530 -0.413017  1.158102  0.813048  0.652073  0.747435 -0.181721\n",
       "144 -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.016565  0.240643  0.695302  0.800079 -0.577978 -0.040593  0.652073 -0.727875  0.413662\n",
       "145  0.259511  0.825907  0.038050  0.464955 -0.186395  0.016565  0.240643 -0.577530  0.800079  1.158102  0.813048  0.652073  0.747435 -0.181721\n",
       "146  0.259511  0.825907  0.038050 -0.115036 -0.186395  0.016565  0.240643 -0.577530 -0.413017  1.158102  0.813048 -0.815004 -0.727875 -0.181721\n",
       "147 -0.126151 -0.623581  0.038050 -0.115036 -0.419247 -0.891287  0.240643 -0.988137  0.800079 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "148 -0.126151  0.825907  0.335700 -0.115036 -0.419247  0.398624 -0.236926 -0.577530 -0.413017 -0.421660 -0.741646  0.259511  0.747435 -0.181721\n",
       "149  0.259511 -0.254167  0.335700 -0.115036 -0.186395  0.016565 -0.236926 -0.577530 -0.413017 -0.577978 -0.040593 -0.815004  0.747435 -0.181721\n",
       "150 -0.126151 -0.623581  0.335700 -0.115036 -0.186395  0.016565  0.240643 -0.988137 -0.413017 -0.421660  0.813048 -0.815004 -0.727875 -0.181721\n",
       "151 -0.126151  0.825907  0.335700 -0.115036 -0.186395  0.398624  0.240643  0.695302  0.800079  1.158102  0.813048  0.652073  0.747435 -0.181721\n",
       "152  0.259511 -0.254167  0.038050 -0.115036 -0.186395 -0.891287  0.240643 -0.577530  0.800079 -0.577978 -0.741646  0.652073 -0.727875 -0.181721\n",
       "153  0.259511 -0.623581  0.335700 -0.115036  0.809558  0.016565 -0.236926 -0.577530 -0.413017 -0.421660 -0.040593 -0.815004 -0.727875 -0.181721\n",
       "154 -0.126151  0.825907 -0.780261 -0.115036 -0.419247  0.016565 -0.236926  0.695302 -0.413017 -0.421660 -0.741646 -0.815004 -0.727875  0.413662\n",
       "155 -0.126151 -0.254167  0.335700 -0.115036 -0.186395  0.398624 -0.236926 -0.988137  0.800079 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "156  0.259511  0.825907  0.038050  0.464955 -0.186395  0.398624 -0.236926  0.695302  0.800079 -0.577978  0.813048  0.259511 -0.727875  0.413662\n",
       "157 -0.126151 -0.623581  0.335700 -0.115036 -0.419247 -0.891287 -0.236926 -0.577530 -0.413017 -0.577978 -0.741646 -0.815004  0.747435 -0.181721\n",
       "158 -0.126151  0.825907  0.335700 -0.115036 -0.186395  0.398624  0.240643  0.695302  0.800079  1.158102  0.813048  0.652073  0.035225 -0.181721\n",
       "159  0.259511  0.825907  0.038050 -0.115036  0.809558  0.016565  0.240643 -0.577530  0.800079 -0.421660  0.813048 -0.815004  0.035225  0.413662\n",
       "160 -0.126151 -0.254167 -0.780261 -0.115036 -0.186395  0.398624 -0.236926 -0.577530 -0.413017 -0.421660 -0.741646 -0.815004  0.035225 -0.181721\n",
       "161 -0.126151 -0.623581 -0.780261 -0.115036 -0.186395  0.016565  0.240643 -0.577530  0.800079 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "162 -0.126151  0.825907  0.038050 -0.115036 -0.186395  0.398624 -0.236926 -0.577530 -0.413017 -0.421660 -0.741646  0.259511  0.035225 -0.181721\n",
       "163  0.259511  0.825907  0.038050 -0.115036  0.809558  0.398624 -0.236926 -0.988137 -0.413017 -0.421660  0.813048 -0.815004 -0.727875 -0.181721\n",
       "164 -0.126151 -0.254167  0.335700  0.464955 -0.186395  0.016565 -0.236926 -0.988137  0.800079 -0.577978 -0.741646  0.259511 -0.727875  0.413662\n",
       "165 -0.126151 -0.254167  0.335700 -0.115036 -0.186395  0.016565  0.240643 -0.577530  0.800079  1.158102  0.813048  0.652073  0.747435 -0.181721\n",
       "166 -0.126151 -0.254167 -0.780261 -0.115036 -0.186395  0.398624 -0.236926 -0.988137 -0.413017  1.158102 -0.741646 -0.815004  0.747435 -0.181721\n",
       "167 -0.126151  0.825907 -0.780261 -0.115036 -0.186395  0.398624 -0.236926  0.695302 -0.413017  1.158102 -0.040593  0.259511 -0.727875 -0.181721\n",
       "168 -0.126151 -0.254167 -0.780261  0.464955 -0.419247  0.016565 -0.236926 -0.988137 -0.413017 -0.577978 -0.741646 -0.815004  0.747435  0.413662\n",
       "169 -0.126151 -0.623581  0.038050 -0.115036 -0.186395 -0.891287  0.240643 -0.988137 -0.413017  1.158102 -0.040593 -0.815004  0.035225 -0.181721\n",
       "170 -0.126151  0.825907  0.038050 -0.115036 -0.186395  0.016565  0.240643 -0.988137 -0.413017 -0.421660 -0.040593 -0.815004  0.747435 -0.181721\n",
       "171 -0.126151  0.825907  0.038050  0.464955 -0.186395  0.016565  0.240643  0.695302 -0.413017  1.158102  0.813048  0.652073  0.747435 -0.181721\n",
       "172 -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.016565  0.240643 -0.577530 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "173 -0.126151  0.825907  0.038050 -0.115036 -0.186395  0.016565  0.240643  0.695302 -0.413017  1.158102  0.813048  0.652073  0.747435 -0.181721\n",
       "174 -0.126151  0.825907  0.335700 -0.115036 -0.186395  0.016565 -0.236926 -0.577530 -0.413017  1.158102 -0.040593 -0.815004  0.747435 -0.181721\n",
       "175 -0.126151 -0.254167  0.038050  0.464955 -0.186395  0.016565  0.240643  0.695302  0.800079 -0.577978 -0.741646  0.652073 -0.727875  0.413662\n",
       "176  0.259511  0.825907  0.335700 -0.115036 -0.186395  0.016565  0.240643 -0.577530 -0.413017 -0.421660  0.813048 -0.815004  0.035225 -0.181721\n",
       "177 -0.126151 -0.254167  0.335700 -0.115036 -0.186395  0.398624 -0.236926 -0.988137 -0.413017 -0.577978 -0.741646 -0.815004  0.747435 -0.181721\n",
       "178  0.259511 -0.623581  0.038050 -0.115036 -0.186395  0.016565 -0.236926 -0.988137 -0.413017 -0.577978 -0.741646  0.259511 -0.727875 -0.181721\n",
       "179 -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.398624 -0.236926  0.695302 -0.413017 -0.421660 -0.040593  0.259511 -0.727875 -0.181721\n",
       "180 -0.126151 -0.254167  0.335700 -0.115036 -0.186395  0.398624  0.240643 -0.988137 -0.413017 -0.421660  0.813048 -0.815004  0.035225 -0.181721\n",
       "181 -0.126151 -0.254167 -0.780261 -0.115036 -0.186395  0.398624 -0.236926  0.695302 -0.413017 -0.421660 -0.040593 -0.815004 -0.727875  0.413662\n",
       "182  0.259511 -0.254167  0.038050 -0.115036 -0.419247  0.016565 -0.236926  0.695302 -0.413017 -0.421660 -0.741646  0.259511  0.035225 -0.181721\n",
       "183  0.259511  0.825907  0.335700 -0.115036  0.809558  0.398624  0.240643 -0.988137 -0.413017 -0.577978  0.813048 -0.815004  0.035225 -0.181721\n",
       "184 -0.126151 -0.254167 -0.780261 -0.115036 -0.186395  0.016565 -0.236926 -0.988137 -0.413017 -0.421660 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "185  0.259511 -0.623581 -0.780261 -0.115036 -0.186395 -0.891287  0.240643  0.695302  0.800079  1.158102  0.813048  0.652073  0.035225 -0.181721\n",
       "186 -0.126151 -0.623581 -0.780261 -0.115036 -0.186395  0.398624 -0.236926  0.695302 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "187 -0.126151 -0.254167  0.038050 -0.115036  0.809558  0.016565 -0.236926  0.695302 -0.413017 -0.577978 -0.040593  0.652073  0.747435  0.413662\n",
       "188 -0.126151  0.825907  0.335700 -0.115036 -0.186395  0.398624 -0.236926 -0.988137 -0.413017 -0.421660 -0.741646 -0.815004  0.035225 -0.181721\n",
       "189 -0.126151 -0.623581  0.038050 -0.115036 -0.186395  0.016565 -0.236926 -0.988137 -0.413017 -0.577978 -0.741646  0.259511 -0.727875 -0.181721\n",
       "190 -0.126151 -0.254167  0.335700  0.464955 -0.419247  0.016565  0.240643 -0.577530 -0.413017 -0.577978 -0.040593  0.652073  0.035225 -0.181721\n",
       "191  0.259511 -0.254167  0.038050 -0.115036  0.809558  0.398624  0.240643  0.695302  0.800079 -0.421660  0.813048  0.652073  0.747435  0.413662\n",
       "192 -0.126151 -0.254167 -0.780261  0.464955 -0.186395  0.398624 -0.236926  0.695302 -0.413017  1.158102 -0.741646 -0.815004  0.035225 -0.181721\n",
       "193 -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.016565  0.240643 -0.577530 -0.413017 -0.577978 -0.040593 -0.815004 -0.727875 -0.181721\n",
       "194 -0.126151 -0.623581  0.038050 -0.115036 -0.186395 -0.891287  0.240643 -0.577530 -0.413017 -0.421660 -0.040593 -0.815004 -0.727875 -0.181721\n",
       "195  0.259511  0.825907  0.335700 -0.115036  0.809558  0.398624 -0.236926 -0.577530 -0.413017  1.158102  0.813048 -0.815004  0.035225 -0.181721\n",
       "196 -0.126151 -0.254167 -0.780261 -0.115036 -0.419247  0.016565 -0.236926  0.695302 -0.413017  1.158102 -0.741646 -0.815004  0.035225 -0.181721\n",
       "197 -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.016565  0.240643 -0.577530 -0.413017 -0.577978 -0.040593  0.652073  0.035225  0.413662\n",
       "198 -0.126151 -0.254167  0.335700 -0.115036 -0.186395  0.016565 -0.236926 -0.577530 -0.413017 -0.421660  0.813048  0.259511  0.035225  0.413662\n",
       "199 -0.126151  0.825907  0.038050 -0.115036 -0.186395  0.016565 -0.236926  0.695302 -0.413017 -0.421660 -0.741646  0.259511  0.747435 -0.181721\n",
       "200  0.259511 -0.254167  0.038050 -0.115036 -0.419247  0.016565 -0.236926 -0.988137 -0.413017 -0.577978 -0.040593 -0.815004 -0.727875 -0.181721\n",
       "201 -0.126151 -0.623581 -0.780261 -0.115036 -0.419247  0.016565 -0.236926 -0.577530 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "202 -0.126151  0.825907 -0.780261 -0.115036 -0.186395  0.398624 -0.236926 -0.577530 -0.413017 -0.421660 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "203 -0.126151  0.825907  0.038050  0.464955 -0.186395  0.398624 -0.236926 -0.577530  0.800079  1.158102 -0.741646  0.259511  0.747435 -0.181721\n",
       "204  0.259511 -0.254167  0.038050 -0.115036 -0.186395  0.016565 -0.236926 -0.988137 -0.413017 -0.421660 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "205 -0.126151 -0.254167  0.335700 -0.115036  0.809558  0.398624  0.240643 -0.577530 -0.413017 -0.421660  0.813048 -0.815004 -0.727875 -0.181721\n",
       "206 -0.126151 -0.623581  0.038050 -0.115036 -0.186395 -0.891287 -0.236926 -0.577530 -0.413017  1.158102 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "207 -0.126151 -0.254167  0.335700  0.464955 -0.186395  0.398624  0.240643  0.695302  0.800079 -0.577978 -0.040593  0.652073  0.035225 -0.181721\n",
       "208 -0.126151 -0.254167  0.335700 -0.115036 -0.419247  0.016565 -0.236926  0.695302 -0.413017  1.158102 -0.741646  0.259511  0.747435 -0.181721\n",
       "209 -0.126151 -0.254167  0.038050  0.464955 -0.186395 -0.891287  0.240643 -0.577530  0.800079  1.158102 -0.741646  0.652073  0.747435 -0.181721\n",
       "210 -0.126151 -0.623581  0.038050 -0.115036 -0.186395 -0.891287  0.240643 -0.577530 -0.413017 -0.421660 -0.040593 -0.815004  0.035225  0.413662\n",
       "211  0.259511  0.825907  0.335700 -0.115036  0.809558  0.016565  0.240643  0.695302  0.800079  1.158102  0.813048  0.652073  0.035225 -0.181721\n",
       "212  0.259511 -0.254167  0.038050 -0.115036 -0.186395  0.016565  0.240643  0.695302 -0.413017 -0.421660 -0.741646  0.652073  0.747435 -0.181721\n",
       "213  0.259511  0.825907  0.038050 -0.115036  0.809558  0.398624  0.240643  0.695302 -0.413017  1.158102  0.813048  0.652073  0.747435 -0.181721\n",
       "214  0.259511 -0.254167  0.335700 -0.115036 -0.186395  0.398624 -0.236926 -0.577530 -0.413017 -0.421660 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "215 -0.126151 -0.623581  0.335700 -0.115036 -0.186395  0.398624 -0.236926  0.695302 -0.413017 -0.577978 -0.741646  0.259511 -0.727875 -0.181721\n",
       "216  0.259511 -0.254167  0.335700 -0.115036 -0.186395  0.016565  0.240643 -0.577530 -0.413017 -0.421660 -0.040593  0.652073  0.747435 -0.181721\n",
       "217 -0.126151 -0.623581 -0.780261  0.464955 -0.419247  0.398624 -0.236926  0.695302  0.800079 -0.577978 -0.741646  0.259511 -0.727875  0.413662\n",
       "218 -0.126151 -0.623581  0.335700  0.464955 -0.186395  0.016565  0.240643 -0.577530 -0.413017 -0.577978 -0.741646  0.652073  0.747435 -0.181721\n",
       "219  0.259511 -0.254167  0.335700 -0.115036  0.809558  0.016565 -0.236926  0.695302  0.800079  1.158102 -0.040593 -0.815004  0.747435 -0.181721\n",
       "220 -0.126151 -0.254167  0.038050 -0.115036 -0.419247  0.016565  0.240643 -0.577530 -0.413017  1.158102 -0.040593  0.259511  0.747435  0.413662\n",
       "221  0.259511  0.825907  0.335700 -0.115036  0.809558 -0.891287 -0.236926 -0.577530 -0.413017  1.158102  0.813048  0.259511  0.035225 -0.181721\n",
       "222  0.259511 -0.254167  0.038050 -0.115036  0.809558  0.016565  0.240643  0.695302 -0.413017 -0.577978 -0.040593  0.259511 -0.727875 -0.181721\n",
       "223  0.259511 -0.254167  0.038050 -0.115036 -0.186395  0.016565 -0.236926 -0.988137 -0.413017 -0.421660 -0.741646  0.259511 -0.727875 -0.181721\n",
       "224  0.259511 -0.254167  0.335700 -0.115036 -0.186395 -0.891287  0.240643 -0.577530 -0.413017 -0.421660 -0.741646  0.652073  0.035225  0.413662\n",
       "225  0.259511 -0.254167  0.038050  0.464955 -0.186395  0.398624  0.240643  0.695302  0.800079 -0.421660 -0.040593  0.652073  0.747435 -0.181721\n",
       "226  0.259511 -0.623581  0.038050 -0.115036 -0.186395 -0.891287  0.240643  0.695302 -0.413017 -0.577978 -0.741646  0.652073 -0.727875  0.413662\n",
       "227  0.259511 -0.623581 -0.780261 -0.115036 -0.186395  0.016565  0.240643 -0.988137 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "228 -0.126151 -0.623581 -0.780261 -0.115036  0.809558  0.398624  0.240643  0.695302  0.800079  1.158102  0.813048  0.652073  0.035225  0.413662\n",
       "229 -0.126151 -0.623581  0.335700 -0.115036 -0.186395 -0.891287 -0.236926  0.695302  0.800079 -0.577978 -0.040593  0.259511 -0.727875  0.413662\n",
       "230 -0.126151  0.825907  0.335700 -0.115036 -0.186395  0.016565 -0.236926 -0.988137 -0.413017 -0.577978 -0.741646 -0.815004  0.747435 -0.181721\n",
       "231 -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.016565  0.240643 -0.577530 -0.413017 -0.577978 -0.741646  0.652073 -0.727875 -0.181721\n",
       "232 -0.126151  0.825907  0.038050 -0.115036 -0.186395  0.398624 -0.236926  0.695302 -0.413017 -0.577978 -0.741646 -0.815004  0.747435 -0.181721\n",
       "233 -0.126151 -0.254167  0.335700 -0.115036 -0.419247  0.398624 -0.236926 -0.577530 -0.413017 -0.577978 -0.741646  0.259511  0.747435 -0.181721\n",
       "234 -0.126151 -0.623581  0.038050 -0.115036 -0.186395  0.016565  0.240643 -0.988137 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "235 -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.016565 -0.236926  0.695302 -0.413017 -0.421660 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "236 -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.398624  0.240643 -0.988137 -0.413017 -0.421660 -0.040593 -0.815004  0.747435 -0.181721\n",
       "237 -0.126151 -0.623581 -0.780261 -0.115036 -0.419247  0.016565 -0.236926  0.695302 -0.413017 -0.577978 -0.741646  0.259511 -0.727875 -0.181721\n",
       "238 -0.126151 -0.254167  0.335700  0.464955 -0.186395  0.398624  0.240643  0.695302  0.800079 -0.421660 -0.741646  0.652073 -0.727875 -0.181721\n",
       "239 -0.126151  0.825907  0.335700 -0.115036 -0.186395  0.016565 -0.236926 -0.988137  0.800079 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "240 -0.126151 -0.623581  0.335700  0.464955 -0.186395 -0.891287 -0.236926  0.695302 -0.413017  1.158102 -0.040593  0.259511  0.747435 -0.181721\n",
       "241 -0.126151  0.825907  0.038050 -0.115036 -0.186395  0.016565 -0.236926 -0.988137 -0.413017 -0.421660 -0.040593 -0.815004 -0.727875 -0.181721\n",
       "242 -0.126151 -0.254167 -0.780261 -0.115036 -0.186395  0.398624 -0.236926 -0.577530 -0.413017 -0.421660 -0.741646 -0.815004  0.035225 -0.181721\n",
       "243 -0.126151  0.825907 -0.780261 -0.115036 -0.419247  0.016565 -0.236926  0.695302 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "244 -0.126151 -0.254167 -0.780261  0.464955 -0.186395  0.016565 -0.236926  0.695302 -0.413017 -0.577978  0.813048  0.652073  0.035225 -0.181721\n",
       "245  0.259511 -0.254167  0.335700 -0.115036 -0.186395 -0.891287  0.240643 -0.577530 -0.413017 -0.577978  0.813048 -0.815004 -0.727875 -0.181721\n",
       "246  0.259511 -0.254167  0.038050 -0.115036  0.809558 -0.891287  0.240643 -0.577530  0.800079 -0.421660  0.813048  0.652073  0.035225  0.413662\n",
       "247  0.259511 -0.254167  0.335700 -0.115036 -0.186395  0.016565  0.240643  0.695302 -0.413017  1.158102  0.813048 -0.815004  0.035225 -0.181721\n",
       "248 -0.126151 -0.254167  0.335700 -0.115036 -0.186395  0.398624 -0.236926 -0.988137 -0.413017 -0.577978 -0.741646  0.259511 -0.727875 -0.181721\n",
       "249 -0.126151 -0.623581  0.038050 -0.115036  0.809558 -0.891287  0.240643 -0.988137  0.800079 -0.421660  0.813048  0.652073  0.035225 -0.181721\n",
       "250  0.259511 -0.254167  0.335700 -0.115036 -0.186395  0.016565  0.240643  0.695302 -0.413017  1.158102  0.813048  0.652073  0.747435 -0.181721\n",
       "251 -0.126151 -0.623581  0.038050 -0.115036  0.809558 -0.891287  0.240643 -0.988137 -0.413017 -0.577978 -0.040593 -0.815004 -0.727875  0.413662\n",
       "252 -0.126151 -0.254167 -0.780261 -0.115036 -0.419247 -0.891287 -0.236926 -0.988137  0.800079 -0.577978 -0.741646 -0.815004  0.035225 -0.181721\n",
       "253  0.259511  0.825907  0.335700 -0.115036 -0.419247  0.398624  0.240643 -0.577530  0.800079 -0.577978  0.813048 -0.815004  0.035225 -0.181721\n",
       "254 -0.126151 -0.623581  0.335700 -0.115036 -0.186395  0.016565 -0.236926  0.695302 -0.413017 -0.577978 -0.741646  0.259511  0.747435 -0.181721\n",
       "255  0.259511 -0.623581  0.335700 -0.115036 -0.186395  0.016565 -0.236926 -0.988137 -0.413017 -0.577978 -0.040593 -0.815004 -0.727875 -0.181721\n",
       "256  0.259511 -0.254167  0.038050 -0.115036 -0.186395  0.016565 -0.236926 -0.577530  0.800079 -0.577978 -0.741646  0.259511 -0.727875 -0.181721\n",
       "257  0.259511  0.825907  0.038050 -0.115036 -0.186395  0.398624  0.240643  0.695302 -0.413017  1.158102 -0.741646  0.652073  0.747435 -0.181721\n",
       "258  0.259511 -0.254167  0.038050  0.464955 -0.186395  0.398624 -0.236926 -0.577530 -0.413017 -0.577978 -0.741646  0.259511 -0.727875  0.413662\n",
       "259 -0.126151 -0.254167  0.038050 -0.115036  0.809558 -0.891287  0.240643 -0.988137 -0.413017 -0.421660 -0.040593  0.259511 -0.727875 -0.181721\n",
       "260  0.259511  0.825907  0.335700  0.464955  0.809558  0.016565  0.240643 -0.577530 -0.413017 -0.577978  0.813048  0.259511  0.035225 -0.181721\n",
       "261 -0.126151 -0.254167  0.038050 -0.115036 -0.186395 -0.891287  0.240643  0.695302  0.800079 -0.577978 -0.741646  0.652073  0.747435 -0.181721\n",
       "262 -0.126151  0.825907  0.038050 -0.115036 -0.186395  0.398624 -0.236926 -0.577530  0.800079  1.158102  0.813048  0.259511  0.035225  0.413662\n",
       "263 -0.126151 -0.623581  0.335700 -0.115036 -0.186395  0.016565 -0.236926 -0.988137 -0.413017 -0.577978 -0.741646  0.259511 -0.727875  0.413662\n",
       "264 -0.126151 -0.623581  0.038050 -0.115036 -0.186395  0.016565  0.240643  0.695302 -0.413017 -0.577978 -0.040593  0.652073  0.747435  0.413662\n",
       "265  0.259511 -0.254167  0.335700 -0.115036 -0.186395  0.016565  0.240643 -0.577530 -0.413017 -0.421660  0.813048  0.652073  0.035225 -0.181721\n",
       "266  0.259511 -0.254167  0.038050 -0.115036  0.809558 -0.891287  0.240643 -0.988137  0.800079 -0.577978 -0.040593 -0.815004 -0.727875  0.413662\n",
       "267  0.259511  0.825907  0.038050 -0.115036  0.809558  0.398624 -0.236926  0.695302 -0.413017 -0.421660 -0.040593 -0.815004  0.747435 -0.181721\n",
       "268  0.259511 -0.254167  0.038050 -0.115036  0.809558 -0.891287 -0.236926  0.695302 -0.413017 -0.577978 -0.040593 -0.815004  0.035225  0.413662\n",
       "269 -0.126151 -0.623581  0.038050 -0.115036 -0.186395  0.016565 -0.236926 -0.577530 -0.413017 -0.577978 -0.741646  0.259511 -0.727875  0.413662\n",
       "270 -0.126151 -0.623581  0.335700  0.464955 -0.186395  0.016565 -0.236926  0.695302 -0.413017 -0.577978 -0.040593  0.259511 -0.727875  0.413662\n",
       "271  0.259511 -0.623581  0.335700 -0.115036 -0.186395 -0.891287 -0.236926 -0.577530 -0.413017 -0.577978  0.813048 -0.815004 -0.727875  0.413662\n",
       "272  0.259511 -0.623581  0.335700  0.464955 -0.186395  0.016565  0.240643  0.695302 -0.413017 -0.421660  0.813048  0.259511  0.035225  0.413662\n",
       "273 -0.126151 -0.254167  0.038050  0.464955 -0.186395  0.398624  0.240643  0.695302 -0.413017  1.158102 -0.741646  0.652073  0.747435  0.413662\n",
       "274 -0.126151 -0.623581  0.038050  0.464955 -0.419247  0.398624 -0.236926  0.695302  0.800079 -0.577978 -0.741646  0.259511 -0.727875 -0.181721\n",
       "275 -0.126151 -0.623581 -0.780261  0.464955 -0.419247 -0.891287 -0.236926 -0.988137 -0.413017 -0.577978 -0.741646  0.259511 -0.727875 -0.181721\n",
       "276  0.259511 -0.254167 -0.780261 -0.115036 -0.186395  0.016565 -0.236926  0.695302 -0.413017  1.158102 -0.040593  0.259511  0.747435 -0.181721\n",
       "277 -0.126151 -0.254167  0.335700 -0.115036 -0.186395  0.398624  0.240643  0.695302  0.800079  1.158102  0.813048  0.652073  0.747435 -0.181721\n",
       "278 -0.126151 -0.623581 -0.780261 -0.115036 -0.419247  0.398624 -0.236926 -0.577530 -0.413017 -0.421660 -0.741646 -0.815004  0.747435 -0.181721\n",
       "279 -0.126151  0.825907  0.038050  0.464955  0.809558  0.398624 -0.236926  0.695302  0.800079  1.158102  0.813048  0.259511  0.747435  0.413662\n",
       "280  0.259511  0.825907  0.038050 -0.115036  0.809558  0.398624  0.240643 -0.577530  0.800079  1.158102  0.813048  0.652073  0.747435 -0.181721\n",
       "281 -0.126151  0.825907 -0.780261 -0.115036  0.809558  0.016565  0.240643  0.695302 -0.413017  1.158102  0.813048  0.652073  0.035225  0.413662\n",
       "282 -0.126151 -0.254167 -0.780261 -0.115036 -0.419247  0.398624 -0.236926 -0.988137 -0.413017 -0.421660 -0.741646  0.259511  0.035225 -0.181721\n",
       "283 -0.126151 -0.623581 -0.780261 -0.115036 -0.186395 -0.891287 -0.236926 -0.988137 -0.413017 -0.577978 -0.741646  0.259511 -0.727875 -0.181721\n",
       "284 -0.126151  0.825907  0.335700 -0.115036 -0.186395  0.016565 -0.236926 -0.577530  0.800079  1.158102  0.813048  0.259511  0.035225 -0.181721\n",
       "285 -0.126151 -0.254167  0.335700 -0.115036  0.809558  0.016565  0.240643  0.695302  0.800079 -0.577978  0.813048  0.259511  0.035225  0.413662\n",
       "286 -0.126151 -0.254167  0.038050 -0.115036 -0.419247  0.398624 -0.236926  0.695302  0.800079  1.158102 -0.040593 -0.815004  0.035225 -0.181721\n",
       "287 -0.126151 -0.254167  0.038050 -0.115036  0.809558  0.016565  0.240643 -0.988137 -0.413017 -0.421660  0.813048  0.259511  0.035225 -0.181721\n",
       "288  0.259511  0.825907  0.335700 -0.115036 -0.419247  0.016565 -0.236926 -0.577530 -0.413017  1.158102  0.813048  0.259511  0.747435 -0.181721\n",
       "289 -0.126151  0.825907  0.335700 -0.115036  0.809558  0.016565  0.240643  0.695302  0.800079  1.158102  0.813048  0.259511  0.747435  0.413662\n",
       "290 -0.126151 -0.254167  0.335700 -0.115036 -0.186395  0.016565  0.240643  0.695302 -0.413017 -0.577978  0.813048  0.652073  0.035225 -0.181721\n",
       "291 -0.126151 -0.254167 -0.780261 -0.115036 -0.419247  0.016565 -0.236926 -0.988137 -0.413017 -0.421660 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "292 -0.126151 -0.623581  0.335700 -0.115036 -0.186395  0.016565 -0.236926 -0.988137 -0.413017 -0.577978 -0.741646  0.259511 -0.727875  0.413662\n",
       "293  0.259511  0.825907  0.038050 -0.115036 -0.186395  0.398624  0.240643 -0.577530 -0.413017  1.158102  0.813048 -0.815004  0.035225 -0.181721\n",
       "294  0.259511 -0.254167  0.038050  0.464955 -0.186395  0.398624 -0.236926 -0.577530  0.800079  1.158102  0.813048  0.259511  0.747435 -0.181721\n",
       "295 -0.126151 -0.623581 -0.780261 -0.115036 -0.186395  0.016565 -0.236926 -0.988137  0.800079 -0.421660 -0.040593  0.259511 -0.727875  0.413662\n",
       "296 -0.126151 -0.254167 -0.780261 -0.115036 -0.186395  0.016565 -0.236926  0.695302 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "297 -0.126151 -0.254167  0.335700 -0.115036 -0.186395  0.016565  0.240643  0.695302 -0.413017  1.158102  0.813048  0.652073  0.747435 -0.181721\n",
       "298  0.259511 -0.254167  0.335700 -0.115036  0.809558  0.016565  0.240643 -0.577530 -0.413017  1.158102  0.813048  0.259511  0.747435 -0.181721\n",
       "299  0.259511 -0.254167  0.335700  0.464955 -0.186395  0.016565  0.240643  0.695302  0.800079 -0.577978 -0.040593  0.652073  0.035225  0.413662\n",
       "300  0.259511 -0.623581  0.038050 -0.115036 -0.186395  0.016565  0.240643  0.695302 -0.413017  1.158102 -0.040593 -0.815004 -0.727875 -0.181721\n",
       "301 -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.016565 -0.236926 -0.577530 -0.413017 -0.421660 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "302 -0.126151  0.825907  0.335700 -0.115036 -0.186395  0.016565  0.240643 -0.577530  0.800079  1.158102  0.813048  0.259511  0.035225  0.413662\n",
       "303 -0.126151 -0.623581  0.335700 -0.115036 -0.186395 -0.891287  0.240643 -0.577530 -0.413017 -0.577978 -0.040593 -0.815004 -0.727875 -0.181721\n",
       "304 -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.016565  0.240643  0.695302  0.800079 -0.577978 -0.741646  0.652073 -0.727875  0.413662\n",
       "305  0.259511 -0.623581  0.335700 -0.115036  0.809558 -0.891287 -0.236926  0.695302 -0.413017 -0.421660  0.813048  0.652073  0.035225  0.413662\n",
       "306 -0.126151 -0.623581  0.038050 -0.115036 -0.186395 -0.891287 -0.236926 -0.577530 -0.413017 -0.577978 -0.040593  0.259511  0.035225 -0.181721\n",
       "307  0.259511 -0.254167  0.335700 -0.115036 -0.186395  0.016565  0.240643 -0.577530 -0.413017 -0.421660  0.813048 -0.815004  0.035225 -0.181721\n",
       "308 -0.126151  0.825907 -0.780261 -0.115036 -0.186395  0.016565  0.240643  0.695302 -0.413017 -0.421660 -0.040593  0.652073  0.035225 -0.181721\n",
       "309 -0.126151 -0.254167 -0.780261  0.464955 -0.419247  0.398624 -0.236926  0.695302  0.800079 -0.577978 -0.741646 -0.815004 -0.727875  0.413662\n",
       "310 -0.126151  0.825907  0.335700  0.464955 -0.186395  0.016565  0.240643  0.695302 -0.413017  1.158102  0.813048  0.652073  0.747435  0.413662\n",
       "311 -0.126151  0.825907 -0.780261 -0.115036 -0.186395  0.016565 -0.236926 -0.577530  0.800079 -0.577978 -0.741646 -0.815004 -0.727875  0.413662\n",
       "312 -0.126151 -0.254167  0.038050  0.464955 -0.186395  0.398624 -0.236926 -0.577530  0.800079 -0.577978 -0.741646  0.259511  0.035225 -0.181721\n",
       "313  0.259511 -0.254167  0.335700  0.464955 -0.186395 -0.891287 -0.236926 -0.988137 -0.413017 -0.421660 -0.040593 -0.815004 -0.727875 -0.181721\n",
       "314 -0.126151 -0.623581 -0.780261  0.464955 -0.186395  0.016565 -0.236926 -0.577530 -0.413017 -0.577978 -0.741646  0.652073 -0.727875 -0.181721\n",
       "315  0.259511 -0.254167  0.335700  0.464955  0.809558  0.016565  0.240643 -0.988137  0.800079 -0.421660  0.813048 -0.815004  0.747435 -0.181721\n",
       "316 -0.126151  0.825907  0.038050  0.464955  0.809558  0.398624  0.240643 -0.577530 -0.413017  1.158102 -0.040593 -0.815004  0.747435 -0.181721\n",
       "317 -0.126151  0.825907  0.038050 -0.115036  0.809558 -0.891287 -0.236926  0.695302 -0.413017 -0.577978 -0.040593  0.259511 -0.727875 -0.181721\n",
       "318 -0.126151 -0.254167 -0.780261 -0.115036 -0.186395  0.016565  0.240643  0.695302 -0.413017  1.158102  0.813048  0.652073  0.035225 -0.181721\n",
       "319 -0.126151 -0.254167 -0.780261 -0.115036 -0.419247  0.016565 -0.236926 -0.577530 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875  0.413662\n",
       "320  0.259511 -0.254167  0.335700 -0.115036  0.809558  0.016565  0.240643  0.695302 -0.413017  1.158102  0.813048  0.652073  0.035225  0.413662\n",
       "321 -0.126151 -0.254167 -0.780261 -0.115036  0.809558  0.016565  0.240643  0.695302 -0.413017 -0.577978 -0.040593  0.652073  0.035225 -0.181721\n",
       "322 -0.126151 -0.254167  0.038050 -0.115036 -0.419247  0.016565 -0.236926 -0.988137 -0.413017 -0.421660 -0.741646  0.259511  0.035225 -0.181721\n",
       "323 -0.126151 -0.254167 -0.780261  0.464955  0.809558 -0.891287  0.240643  0.695302  0.800079 -0.577978  0.813048  0.652073  0.747435  0.413662\n",
       "324  0.259511  0.825907  0.038050 -0.115036  0.809558  0.398624 -0.236926 -0.988137 -0.413017  1.158102 -0.040593 -0.815004  0.747435  0.413662\n",
       "325 -0.126151 -0.623581  0.038050 -0.115036 -0.419247 -0.891287  0.240643  0.695302 -0.413017 -0.577978 -0.741646  0.652073  0.035225 -0.181721"
      ]
     },
     "execution_count": 2120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of bin and replacing the original values with woe values based on the values in respective bins. \n",
    "\n",
    "for i in new_data_train.columns:\n",
    "    \n",
    "    if len(woe[i]) == 3:\n",
    "        woe_transformed_train_data[i] = np.where(woe_transformed_train_data[i]<=woe[i].iloc[2][i],woe[i].iloc[2][\"WOE_\"+i],\n",
    "                                  np.where(woe_transformed_train_data[i]<=woe[i].iloc[1][i],woe[i].iloc[1]['WOE_'+i],\n",
    "                                  woe[i].iloc[0]['WOE_'+i]))\n",
    "        \n",
    "    if len(woe[i]) == 2:\n",
    "        woe_transformed_train_data[i] = np.where(woe_transformed_train_data[i]<=woe[i].iloc[1][i],woe[i].iloc[1][\"WOE_\"+i],\n",
    "                                           woe[i].iloc[0][\"WOE_\"+i])\n",
    "    \n",
    "woe_transformed_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2121,
   "id": "fe86810c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M25 bins 2 , M28 bins 3 , M30 bins 3 , M34 bins 2 , M39 bins 3 , M53 bins 3 , M58 bins 2 , M63 bins 3 , M66 bins 2 , M87 bins 3 , M88 bins 3 , M124 bins 3 , M148 bins 3 , M151 bins 2 , "
     ]
    }
   ],
   "source": [
    "for i in new_data_train.columns:\n",
    "    print(i,\"bins\",len(woe[i]),end=\" , \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2122,
   "id": "d529a42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data transformed to woe values\n",
    "X_train5 = woe_transformed_train_data\n",
    "y_train5 = data_woe[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb8c659",
   "metadata": {},
   "source": [
    "* Lets replace the same woe values in validation data as per the bins range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2123,
   "id": "0dc36b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>M25</th>\n",
       "      <th>M28</th>\n",
       "      <th>M30</th>\n",
       "      <th>M34</th>\n",
       "      <th>M39</th>\n",
       "      <th>M53</th>\n",
       "      <th>M58</th>\n",
       "      <th>M63</th>\n",
       "      <th>M66</th>\n",
       "      <th>M87</th>\n",
       "      <th>M88</th>\n",
       "      <th>M124</th>\n",
       "      <th>M148</th>\n",
       "      <th>M151</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.200000e+06</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>1.159180e+05</td>\n",
       "      <td>0.595393</td>\n",
       "      <td>-2.953333e+08</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.632097e+05</td>\n",
       "      <td>-9.567143e+04</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.032424</td>\n",
       "      <td>0.048041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.628869e+07</td>\n",
       "      <td>2.128205</td>\n",
       "      <td>8.120148e+07</td>\n",
       "      <td>0.925216</td>\n",
       "      <td>-2.966667e+05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.393400e+06</td>\n",
       "      <td>-4.652200e+04</td>\n",
       "      <td>-384.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.933704</td>\n",
       "      <td>1.034571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.866667e+07</td>\n",
       "      <td>3.634146</td>\n",
       "      <td>1.483401e+06</td>\n",
       "      <td>5.253068</td>\n",
       "      <td>-2.280000e+07</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000e+05</td>\n",
       "      <td>-5.614219e+07</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.685500</td>\n",
       "      <td>1.730498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.000000e+07</td>\n",
       "      <td>0.344681</td>\n",
       "      <td>8.623085e+07</td>\n",
       "      <td>0.379928</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.923710e+08</td>\n",
       "      <td>-3.126686e+07</td>\n",
       "      <td>-1204892.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.773008</td>\n",
       "      <td>0.923257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.010000e+08</td>\n",
       "      <td>3.081633</td>\n",
       "      <td>1.226902e+08</td>\n",
       "      <td>2.997680</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.000000e+05</td>\n",
       "      <td>2.297120e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.029067</td>\n",
       "      <td>1.044883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        M25         M28         M30         M34         M39         M53    M58       M63           M66         M87      M88  M124    M148      M151  \n",
       "0  4.200000e+06  1.560000  1.159180e+05  0.595393 -2.953333e+08  3.000000  1.0 -2.632097e+05 -9.567143e+04    44000.0  32.0  21.0  1.032424  0.048041\n",
       "1  5.628869e+07  2.128205  8.120148e+07  0.925216 -2.966667e+05  2.000000  0.0 -1.393400e+06 -4.652200e+04     -384.0  65.0   0.0  0.933704  1.034571\n",
       "2  5.866667e+07  3.634146  1.483401e+06  5.253068 -2.280000e+07  1.666667  1.0  5.000000e+05 -5.614219e+07    55000.0  60.0  22.0  3.685500  1.730498\n",
       "3  2.000000e+07  0.344681  8.623085e+07  0.379928  0.000000e+00  0.111111  1.0 -1.923710e+08 -3.126686e+07 -1204892.0  18.0   1.0  0.773008  0.923257\n",
       "4  2.010000e+08  3.081633  1.226902e+08  2.997680  0.000000e+00  4.000000  0.0 -9.000000e+05  2.297120e+06        0.0  55.0   0.0  1.029067  1.044883"
      ]
     },
     "execution_count": 2123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variables chosen using Info.Value\n",
    "new_data_valid = df1_valid_descaled[new_data_train.columns]\n",
    "new_data_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2124,
   "id": "0fece42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Index(['M25', 'M28', 'M30', 'M34', 'M39', 'M53', 'M58', 'M63', 'M66', 'M87', 'M88', 'M124', 'M148', 'M151'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(len(new_data_valid.columns))\n",
    "print(new_data_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2125,
   "id": "7461de41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the validation data in new variable\n",
    "woe_transformed_valid_data = new_data_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2126,
   "id": "3ded8dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>M25</th>\n",
       "      <th>M28</th>\n",
       "      <th>M30</th>\n",
       "      <th>M34</th>\n",
       "      <th>M39</th>\n",
       "      <th>M53</th>\n",
       "      <th>M58</th>\n",
       "      <th>M63</th>\n",
       "      <th>M66</th>\n",
       "      <th>M87</th>\n",
       "      <th>M88</th>\n",
       "      <th>M124</th>\n",
       "      <th>M148</th>\n",
       "      <th>M151</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>1.158102</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.695302</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>0.809558</td>\n",
       "      <td>-0.891287</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.988137</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.815004</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.254167</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.421660</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>-0.780261</td>\n",
       "      <td>-0.115036</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.800079</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.181721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-0.126151</td>\n",
       "      <td>-0.623581</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.464955</td>\n",
       "      <td>-0.186395</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.413017</td>\n",
       "      <td>-0.577978</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>0.652073</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>0.413662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       M25       M28       M30       M34       M39       M53       M58       M63       M66       M87       M88      M124      M148      M151  \n",
       "0   0.259511 -0.254167  0.335700 -0.115036  0.809558 -0.891287 -0.236926 -0.577530 -0.413017 -0.577978 -0.040593 -0.815004  0.035225  0.413662\n",
       "1  -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.016565  0.240643 -0.577530 -0.413017 -0.421660 -0.741646  0.652073  0.035225 -0.181721\n",
       "2  -0.126151 -0.623581  0.335700 -0.115036 -0.186395  0.016565 -0.236926 -0.988137  0.800079 -0.577978 -0.040593 -0.815004 -0.727875 -0.181721\n",
       "3  -0.126151  0.825907  0.038050  0.464955 -0.186395  0.398624 -0.236926  0.695302  0.800079  1.158102  0.813048  0.259511  0.747435  0.413662\n",
       "4  -0.126151 -0.623581  0.038050 -0.115036 -0.186395 -0.891287  0.240643 -0.577530 -0.413017 -0.421660 -0.040593  0.652073  0.035225 -0.181721\n",
       "5  -0.126151 -0.254167 -0.780261 -0.115036 -0.186395  0.398624 -0.236926  0.695302 -0.413017  1.158102 -0.741646  0.259511  0.747435 -0.181721\n",
       "6  -0.126151  0.825907 -0.780261 -0.115036 -0.419247  0.398624 -0.236926  0.695302 -0.413017  1.158102 -0.741646 -0.815004  0.747435 -0.181721\n",
       "7   0.259511 -0.254167  0.038050  0.464955  0.809558  0.016565  0.240643  0.695302  0.800079 -0.421660  0.813048  0.652073 -0.727875 -0.181721\n",
       "8  -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.398624  0.240643 -0.577530 -0.413017  1.158102 -0.040593  0.652073  0.035225 -0.181721\n",
       "9  -0.126151  0.825907  0.335700 -0.115036 -0.186395  0.016565 -0.236926 -0.988137 -0.413017 -0.577978 -0.741646 -0.815004  0.035225 -0.181721\n",
       "10 -0.126151  0.825907  0.335700 -0.115036 -0.186395  0.398624  0.240643  0.695302 -0.413017 -0.577978  0.813048  0.259511  0.035225 -0.181721\n",
       "11 -0.126151 -0.254167 -0.780261 -0.115036 -0.186395  0.398624 -0.236926 -0.988137 -0.413017 -0.577978 -0.741646 -0.815004  0.035225 -0.181721\n",
       "12 -0.126151  0.825907  0.038050 -0.115036 -0.186395  0.398624 -0.236926 -0.988137 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "13 -0.126151  0.825907  0.038050 -0.115036 -0.186395  0.398624  0.240643  0.695302 -0.413017  1.158102  0.813048  0.652073  0.747435 -0.181721\n",
       "14  0.259511 -0.254167  0.335700 -0.115036 -0.186395  0.016565  0.240643  0.695302 -0.413017  1.158102  0.813048  0.652073 -0.727875 -0.181721\n",
       "15 -0.126151 -0.254167  0.038050  0.464955 -0.186395  0.016565  0.240643 -0.577530 -0.413017 -0.577978 -0.741646  0.652073 -0.727875  0.413662\n",
       "16 -0.126151 -0.623581  0.335700 -0.115036 -0.419247  0.398624 -0.236926 -0.577530 -0.413017 -0.577978 -0.741646  0.259511 -0.727875 -0.181721\n",
       "17  0.259511 -0.254167  0.335700 -0.115036  0.809558  0.016565  0.240643  0.695302 -0.413017 -0.577978  0.813048 -0.815004  0.035225 -0.181721\n",
       "18 -0.126151 -0.623581  0.335700 -0.115036 -0.186395  0.016565 -0.236926  0.695302  0.800079 -0.421660 -0.741646  0.259511  0.747435 -0.181721\n",
       "19 -0.126151  0.825907 -0.780261 -0.115036 -0.186395  0.398624 -0.236926 -0.577530 -0.413017 -0.421660 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "20 -0.126151 -0.623581  0.335700 -0.115036 -0.186395  0.016565  0.240643 -0.988137 -0.413017 -0.577978 -0.040593 -0.815004 -0.727875 -0.181721\n",
       "21 -0.126151 -0.623581  0.038050 -0.115036 -0.186395  0.398624  0.240643 -0.577530 -0.413017 -0.577978 -0.741646  0.652073 -0.727875 -0.181721\n",
       "22  0.259511 -0.254167  0.038050 -0.115036 -0.186395  0.016565  0.240643 -0.577530 -0.413017 -0.577978 -0.040593  0.259511  0.035225 -0.181721\n",
       "23  0.259511  0.825907  0.038050 -0.115036  0.809558  0.398624  0.240643  0.695302 -0.413017  1.158102  0.813048  0.652073  0.747435  0.413662\n",
       "24 -0.126151 -0.623581  0.038050 -0.115036 -0.186395  0.016565  0.240643  0.695302 -0.413017 -0.577978  0.813048  0.652073 -0.727875 -0.181721\n",
       "25 -0.126151  0.825907  0.038050 -0.115036 -0.186395  0.398624  0.240643  0.695302 -0.413017  1.158102  0.813048  0.652073  0.747435  0.413662\n",
       "26 -0.126151 -0.254167 -0.780261 -0.115036 -0.186395  0.398624 -0.236926 -0.988137 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "27 -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.016565 -0.236926 -0.988137 -0.413017 -0.577978 -0.741646  0.259511 -0.727875 -0.181721\n",
       "28 -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.016565 -0.236926 -0.988137 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "29  0.259511 -0.623581  0.038050  0.464955 -0.186395  0.016565  0.240643  0.695302 -0.413017 -0.577978 -0.741646  0.652073 -0.727875 -0.181721\n",
       "30 -0.126151 -0.254167 -0.780261 -0.115036 -0.419247  0.016565 -0.236926 -0.988137 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "31 -0.126151 -0.254167  0.038050  0.464955 -0.419247  0.398624 -0.236926 -0.988137 -0.413017 -0.421660 -0.741646  0.259511  0.747435  0.413662\n",
       "32  0.259511 -0.254167  0.335700 -0.115036 -0.186395  0.016565  0.240643 -0.577530 -0.413017 -0.577978  0.813048  0.652073 -0.727875 -0.181721\n",
       "33  0.259511  0.825907  0.335700 -0.115036  0.809558  0.016565  0.240643  0.695302 -0.413017 -0.577978  0.813048  0.652073  0.747435  0.413662\n",
       "34 -0.126151 -0.254167 -0.780261 -0.115036 -0.419247  0.016565 -0.236926 -0.577530 -0.413017 -0.577978 -0.741646 -0.815004  0.035225 -0.181721\n",
       "35  0.259511 -0.254167 -0.780261 -0.115036  0.809558  0.016565  0.240643  0.695302 -0.413017  1.158102 -0.040593  0.652073  0.747435 -0.181721\n",
       "36 -0.126151 -0.623581  0.038050 -0.115036 -0.186395 -0.891287  0.240643 -0.577530  0.800079 -0.577978 -0.040593  0.652073 -0.727875  0.413662\n",
       "37 -0.126151 -0.254167  0.335700 -0.115036 -0.186395  0.016565  0.240643 -0.988137  0.800079 -0.421660  0.813048 -0.815004 -0.727875 -0.181721\n",
       "38 -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.016565  0.240643  0.695302 -0.413017 -0.577978 -0.040593  0.652073 -0.727875 -0.181721\n",
       "39  0.259511  0.825907  0.038050 -0.115036 -0.186395  0.016565  0.240643  0.695302 -0.413017  1.158102  0.813048  0.652073  0.035225 -0.181721\n",
       "40 -0.126151  0.825907  0.335700 -0.115036  0.809558  0.398624 -0.236926 -0.577530 -0.413017  1.158102  0.813048  0.259511  0.747435 -0.181721\n",
       "41 -0.126151 -0.254167  0.335700 -0.115036 -0.419247  0.398624 -0.236926 -0.988137 -0.413017 -0.421660 -0.741646 -0.815004 -0.727875  0.413662\n",
       "42  0.259511 -0.254167  0.335700 -0.115036 -0.186395 -0.891287  0.240643 -0.988137 -0.413017 -0.421660 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "43  0.259511 -0.623581  0.038050 -0.115036 -0.186395  0.016565 -0.236926  0.695302 -0.413017 -0.577978 -0.741646  0.259511 -0.727875 -0.181721\n",
       "44 -0.126151 -0.254167  0.038050 -0.115036 -0.186395  0.398624  0.240643 -0.577530 -0.413017 -0.577978 -0.741646  0.652073  0.747435 -0.181721\n",
       "45 -0.126151 -0.254167 -0.780261 -0.115036 -0.419247  0.398624 -0.236926  0.695302 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "46 -0.126151 -0.254167  0.038050 -0.115036 -0.419247 -0.891287  0.240643 -0.988137 -0.413017 -0.421660 -0.040593 -0.815004  0.035225 -0.181721\n",
       "47 -0.126151  0.825907 -0.780261 -0.115036 -0.186395  0.398624  0.240643 -0.577530  0.800079  1.158102 -0.040593  0.652073  0.747435  0.413662\n",
       "48 -0.126151  0.825907 -0.780261 -0.115036 -0.186395  0.398624 -0.236926 -0.577530 -0.413017 -0.421660 -0.741646 -0.815004  0.747435 -0.181721\n",
       "49  0.259511 -0.254167  0.335700 -0.115036 -0.186395 -0.891287  0.240643 -0.577530 -0.413017  1.158102  0.813048  0.652073  0.035225 -0.181721\n",
       "50 -0.126151 -0.254167 -0.780261  0.464955 -0.419247  0.016565 -0.236926  0.695302 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875  0.413662\n",
       "51  0.259511  0.825907  0.335700 -0.115036  0.809558  0.016565 -0.236926 -0.577530 -0.413017  1.158102  0.813048 -0.815004  0.747435 -0.181721\n",
       "52  0.259511 -0.623581  0.335700 -0.115036 -0.186395 -0.891287  0.240643 -0.577530 -0.413017 -0.421660 -0.040593 -0.815004  0.035225 -0.181721\n",
       "53 -0.126151  0.825907 -0.780261 -0.115036 -0.186395  0.398624 -0.236926  0.695302 -0.413017 -0.421660 -0.741646 -0.815004  0.747435 -0.181721\n",
       "54 -0.126151 -0.623581  0.038050 -0.115036 -0.186395 -0.891287  0.240643  0.695302 -0.413017 -0.577978 -0.741646  0.652073 -0.727875 -0.181721\n",
       "55 -0.126151 -0.623581  0.038050 -0.115036 -0.186395  0.016565 -0.236926  0.695302 -0.413017 -0.577978 -0.741646  0.259511 -0.727875  0.413662\n",
       "56 -0.126151  0.825907  0.335700 -0.115036  0.809558  0.398624  0.240643 -0.577530 -0.413017 -0.421660  0.813048 -0.815004  0.747435 -0.181721\n",
       "57 -0.126151 -0.623581  0.335700 -0.115036 -0.186395  0.016565  0.240643  0.695302 -0.413017 -0.421660 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "58 -0.126151 -0.254167 -0.780261 -0.115036 -0.419247  0.016565 -0.236926 -0.988137 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "59 -0.126151 -0.254167  0.335700 -0.115036 -0.419247  0.398624  0.240643 -0.577530 -0.413017 -0.421660 -0.741646  0.652073  0.035225 -0.181721\n",
       "60 -0.126151 -0.623581 -0.780261 -0.115036 -0.419247  0.016565  0.240643  0.695302  0.800079 -0.577978 -0.741646  0.652073 -0.727875  0.413662\n",
       "61 -0.126151  0.825907  0.038050 -0.115036 -0.186395  0.016565 -0.236926  0.695302  0.800079  1.158102 -0.741646  0.259511  0.035225 -0.181721\n",
       "62 -0.126151  0.825907  0.335700 -0.115036  0.809558  0.016565  0.240643 -0.577530 -0.413017 -0.421660  0.813048  0.259511  0.035225 -0.181721\n",
       "63  0.259511 -0.623581  0.335700 -0.115036 -0.419247 -0.891287  0.240643 -0.577530 -0.413017 -0.577978 -0.040593 -0.815004 -0.727875 -0.181721\n",
       "64 -0.126151 -0.254167  0.335700  0.464955 -0.419247 -0.891287 -0.236926  0.695302 -0.413017 -0.421660 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "65 -0.126151 -0.254167  0.335700 -0.115036 -0.419247  0.016565 -0.236926 -0.577530 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875  0.413662\n",
       "66 -0.126151 -0.623581 -0.780261 -0.115036 -0.419247 -0.891287 -0.236926 -0.988137  0.800079 -0.577978 -0.741646 -0.815004 -0.727875  0.413662\n",
       "67  0.259511  0.825907 -0.780261 -0.115036  0.809558  0.016565  0.240643  0.695302  0.800079  1.158102  0.813048  0.652073  0.035225 -0.181721\n",
       "68 -0.126151 -0.254167  0.038050 -0.115036  0.809558  0.016565  0.240643  0.695302 -0.413017 -0.421660  0.813048 -0.815004 -0.727875 -0.181721\n",
       "69 -0.126151  0.825907  0.038050 -0.115036 -0.186395  0.398624 -0.236926  0.695302 -0.413017  1.158102  0.813048  0.259511  0.747435  0.413662\n",
       "70 -0.126151 -0.623581  0.038050  0.464955 -0.186395  0.398624  0.240643  0.695302 -0.413017 -0.577978 -0.741646  0.652073 -0.727875 -0.181721\n",
       "71 -0.126151 -0.254167 -0.780261 -0.115036 -0.186395  0.016565 -0.236926 -0.577530  0.800079 -0.577978 -0.741646  0.259511  0.035225 -0.181721\n",
       "72  0.259511 -0.254167  0.335700 -0.115036  0.809558  0.016565  0.240643 -0.577530 -0.413017 -0.421660 -0.040593  0.652073  0.747435 -0.181721\n",
       "73  0.259511 -0.254167  0.335700 -0.115036  0.809558  0.398624  0.240643  0.695302 -0.413017 -0.421660  0.813048  0.652073  0.035225 -0.181721\n",
       "74  0.259511 -0.254167  0.335700 -0.115036 -0.186395  0.016565 -0.236926  0.695302 -0.413017 -0.577978  0.813048  0.259511  0.035225 -0.181721\n",
       "75  0.259511 -0.254167  0.335700 -0.115036  0.809558  0.016565  0.240643  0.695302  0.800079  1.158102  0.813048  0.652073  0.035225 -0.181721\n",
       "76 -0.126151 -0.254167 -0.780261  0.464955 -0.186395  0.398624 -0.236926 -0.577530 -0.413017 -0.577978 -0.741646 -0.815004 -0.727875 -0.181721\n",
       "77  0.259511 -0.623581  0.038050 -0.115036 -0.186395  0.398624  0.240643  0.695302 -0.413017 -0.577978 -0.741646  0.652073 -0.727875 -0.181721\n",
       "78 -0.126151 -0.254167  0.335700 -0.115036 -0.186395  0.016565 -0.236926 -0.577530  0.800079  1.158102 -0.741646 -0.815004  0.747435 -0.181721\n",
       "79 -0.126151  0.825907  0.038050 -0.115036 -0.419247 -0.891287  0.240643 -0.577530 -0.413017 -0.577978 -0.741646  0.259511 -0.727875 -0.181721\n",
       "80  0.259511 -0.254167  0.038050 -0.115036 -0.186395 -0.891287  0.240643 -0.988137 -0.413017 -0.421660 -0.040593 -0.815004 -0.727875 -0.181721\n",
       "81  0.259511  0.825907  0.335700 -0.115036  0.809558  0.016565  0.240643  0.695302 -0.413017  1.158102  0.813048  0.259511  0.747435 -0.181721\n",
       "82 -0.126151  0.825907  0.335700 -0.115036  0.809558  0.398624  0.240643  0.695302  0.800079 -0.421660  0.813048  0.259511  0.035225 -0.181721\n",
       "83  0.259511 -0.623581  0.038050 -0.115036  0.809558 -0.891287  0.240643 -0.988137  0.800079 -0.421660  0.813048  0.259511 -0.727875 -0.181721\n",
       "84  0.259511 -0.254167  0.038050 -0.115036 -0.419247  0.016565  0.240643 -0.988137 -0.413017 -0.421660 -0.040593 -0.815004 -0.727875 -0.181721\n",
       "85 -0.126151 -0.254167  0.335700 -0.115036 -0.186395  0.398624 -0.236926 -0.577530 -0.413017 -0.421660 -0.741646  0.259511  0.747435  0.413662\n",
       "86 -0.126151 -0.623581 -0.780261 -0.115036 -0.186395  0.016565 -0.236926 -0.577530  0.800079 -0.577978 -0.741646  0.259511 -0.727875 -0.181721\n",
       "87 -0.126151 -0.623581  0.038050  0.464955 -0.186395  0.016565  0.240643 -0.577530 -0.413017 -0.577978 -0.040593  0.652073 -0.727875  0.413662"
      ]
     },
     "execution_count": 2126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of bin and replacing the original values with woe values based on the values in respective bins. \n",
    "\n",
    "for i in new_data_valid.columns:\n",
    "    \n",
    "    if len(woe[i]) == 3:\n",
    "        woe_transformed_valid_data[i] = np.where(woe_transformed_valid_data[i]<=woe[i].iloc[2][i],woe[i].iloc[2][\"WOE_\"+i],\n",
    "                                  np.where(woe_transformed_valid_data[i]<=woe[i].iloc[1][i],woe[i].iloc[1]['WOE_'+i],\n",
    "                                  woe[i].iloc[0]['WOE_'+i]))\n",
    "        \n",
    "    if len(woe[i]) == 2:\n",
    "        woe_transformed_valid_data[i] = np.where(woe_transformed_valid_data[i]<=woe[i].iloc[1][i],woe[i].iloc[1][\"WOE_\"+i],\n",
    "                                           woe[i].iloc[0][\"WOE_\"+i])\n",
    "    \n",
    "woe_transformed_valid_data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bfb54757",
   "metadata": {},
   "source": [
    "# If bin size is greater than 3\n",
    "woe_transformed_valid_data['M69']=woe_transformed_valid_data['M69'].apply(lambda x: woe['M69'].iloc[3].WOE_M69 if x<= woe['M69'].iloc[3].M69 \n",
    "                   else (woe['M69'].iloc[2].WOE_M69 if x<= woe['M69'].iloc[2].M69 \n",
    "                   else (woe['M69'].iloc[1].WOE_M69 if x<= woe['M69'].iloc[1].M69\n",
    "                   else woe['M69'].iloc[0].WOE_M69)))\n",
    "woe_transformed_valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2127,
   "id": "93dab108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data transformed to woe values\n",
    "y_valid5 = df1_valid_descaled[\"target\"]\n",
    "X_valid5 = woe_transformed_valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2128,
   "id": "8aaa96dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the train data with only 17potential variables \n",
    "\n",
    "# initializing the scaler object\n",
    "scaler_new2 = StandardScaler()\n",
    "\n",
    "# fit and transform the train data\n",
    "data_woe_scaled_trans = scaler_new2.fit_transform(X_train5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2129,
   "id": "79c6f648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the validation data using the fit of train data(mean and standard deviation)\n",
    "X_valid5_scaled = scaler_new2.transform(X_valid5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2130,
   "id": "52784c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 Count: 245 Percentage: 50.0\n",
      "Class: 1 Count: 245 Percentage: 50.0\n"
     ]
    }
   ],
   "source": [
    "# Lets increase the sample size of the minority class before training the model\n",
    "\n",
    "#Initialize smote object - Sythetic Minority Oversampling Technique\n",
    "oversample = SMOTE(random_state=50)\n",
    "\n",
    "#oversampling the classes (Note:using the same scaled data from previous trial)\n",
    "X_train_psmt_trans, y_train_psmt_trans = oversample.fit_resample(data_woe_scaled_trans, y_train5)\n",
    "\n",
    "# Summarizing the distribution\n",
    "counter = Counter(y_train_psmt_trans)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_train_psmt_trans) * 100\n",
    "    print(\"Class:\",k,\"Count:\",v,\"Percentage:\", per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2131,
   "id": "b6afb370",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "LogisticRegression(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.60      0.58        25\n",
      "           1       0.84      0.81      0.82        63\n",
      "\n",
      "    accuracy                           0.75        88\n",
      "   macro avg       0.70      0.70      0.70        88\n",
      "weighted avg       0.76      0.75      0.75        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         51                 12        \n",
      "Actual -ve [0]         10                 15        \n",
      "____________________________________________________________________________________________________\n",
      "LinearDiscriminantAnalysis()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63        25\n",
      "           1       0.85      0.84      0.85        63\n",
      "\n",
      "    accuracy                           0.78        88\n",
      "   macro avg       0.74      0.74      0.74        88\n",
      "weighted avg       0.79      0.78      0.79        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         53                 10        \n",
      "Actual -ve [0]          9                 16        \n",
      "____________________________________________________________________________________________________\n",
      "AdaBoostClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.48      0.53        25\n",
      "           1       0.81      0.87      0.84        63\n",
      "\n",
      "    accuracy                           0.76        88\n",
      "   macro avg       0.70      0.68      0.69        88\n",
      "weighted avg       0.75      0.76      0.75        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         55                  8        \n",
      "Actual -ve [0]         13                 12        \n",
      "____________________________________________________________________________________________________\n",
      "GradientBoostingClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.52      0.62        25\n",
      "           1       0.83      0.94      0.88        63\n",
      "\n",
      "    accuracy                           0.82        88\n",
      "   macro avg       0.80      0.73      0.75        88\n",
      "weighted avg       0.81      0.82      0.81        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         59                  4        \n",
      "Actual -ve [0]         12                 13        \n",
      "____________________________________________________________________________________________________\n",
      "RandomForestClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.40      0.48        25\n",
      "           1       0.79      0.89      0.84        63\n",
      "\n",
      "    accuracy                           0.75        88\n",
      "   macro avg       0.69      0.64      0.66        88\n",
      "weighted avg       0.73      0.75      0.73        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         56                  7        \n",
      "Actual -ve [0]         15                 10        \n",
      "____________________________________________________________________________________________________\n",
      "BaggingClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.52      0.57        25\n",
      "           1       0.82      0.87      0.85        63\n",
      "\n",
      "    accuracy                           0.77        88\n",
      "   macro avg       0.72      0.70      0.71        88\n",
      "weighted avg       0.76      0.77      0.77        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         55                  8        \n",
      "Actual -ve [0]         12                 13        \n",
      "____________________________________________________________________________________________________\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=50, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.36      0.45        25\n",
      "           1       0.78      0.90      0.84        63\n",
      "\n",
      "    accuracy                           0.75        88\n",
      "   macro avg       0.69      0.63      0.64        88\n",
      "weighted avg       0.73      0.75      0.73        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         57                  6        \n",
      "Actual -ve [0]         16                  9        \n"
     ]
    }
   ],
   "source": [
    "# Classification report of multiple models over scaled - oversampled - chosen 17 potential variables from Info Value\n",
    "for i in L1:\n",
    "    multiple_model(i,X_train_psmt_trans, y_train_psmt_trans,X_valid5_scaled,y_valid5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2132,
   "id": "6c962097",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.40      0.50        25\n",
      "           1       0.79      0.92      0.85        63\n",
      "\n",
      "    accuracy                           0.77        88\n",
      "   macro avg       0.73      0.66      0.68        88\n",
      "weighted avg       0.76      0.77      0.75        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         58                  5        \n",
      "Actual -ve [0]         15                 10        \n"
     ]
    }
   ],
   "source": [
    "# Based on the individual performance we will choose the best classifiers as our voting classifiers\n",
    "\n",
    "m1,m2,m3 = xgb,ab,gb # xgboost,gradient,adaboost\n",
    "\n",
    "voting_classifier(m1,m2,m3,X_train_psmt_trans, y_train_psmt_trans,X_valid5_scaled,y_valid5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2133,
   "id": "4e7fc1c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_52293\" style='display:inline; margin-right:20px;'>\n",
       "  <caption>Model's Performance on Train data</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_52293_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_52293_level0_col1\" class=\"col_heading level0 col1\" >F1_score</th>\n",
       "      <th id=\"T_52293_level0_col2\" class=\"col_heading level0 col2\" >Auroc</th>\n",
       "      <th id=\"T_52293_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_52293_level0_row0\" class=\"row_heading level0 row0\" >LogisticRegression</th>\n",
       "      <td id=\"T_52293_row0_col0\" class=\"data row0 col0\" >0.757143</td>\n",
       "      <td id=\"T_52293_row0_col1\" class=\"data row0 col1\" >0.761523</td>\n",
       "      <td id=\"T_52293_row0_col2\" class=\"data row0 col2\" >0.757143</td>\n",
       "      <td id=\"T_52293_row0_col3\" class=\"data row0 col3\" >0.775510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52293_level0_row1\" class=\"row_heading level0 row1\" >LinearDiscriminantClassifier</th>\n",
       "      <td id=\"T_52293_row1_col0\" class=\"data row1 col0\" >0.757143</td>\n",
       "      <td id=\"T_52293_row1_col1\" class=\"data row1 col1\" >0.760563</td>\n",
       "      <td id=\"T_52293_row1_col2\" class=\"data row1 col2\" >0.757143</td>\n",
       "      <td id=\"T_52293_row1_col3\" class=\"data row1 col3\" >0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52293_level0_row2\" class=\"row_heading level0 row2\" >AdaptiveBoosting</th>\n",
       "      <td id=\"T_52293_row2_col0\" class=\"data row2 col0\" >0.873469</td>\n",
       "      <td id=\"T_52293_row2_col1\" class=\"data row2 col1\" >0.875502</td>\n",
       "      <td id=\"T_52293_row2_col2\" class=\"data row2 col2\" >0.873469</td>\n",
       "      <td id=\"T_52293_row2_col3\" class=\"data row2 col3\" >0.889796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52293_level0_row3\" class=\"row_heading level0 row3\" >Gradient_Boosting</th>\n",
       "      <td id=\"T_52293_row3_col0\" class=\"data row3 col0\" >0.951020</td>\n",
       "      <td id=\"T_52293_row3_col1\" class=\"data row3 col1\" >0.952191</td>\n",
       "      <td id=\"T_52293_row3_col2\" class=\"data row3 col2\" >0.951020</td>\n",
       "      <td id=\"T_52293_row3_col3\" class=\"data row3 col3\" >0.975510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52293_level0_row4\" class=\"row_heading level0 row4\" >RandomForest</th>\n",
       "      <td id=\"T_52293_row4_col0\" class=\"data row4 col0\" >0.995918</td>\n",
       "      <td id=\"T_52293_row4_col1\" class=\"data row4 col1\" >0.995918</td>\n",
       "      <td id=\"T_52293_row4_col2\" class=\"data row4 col2\" >0.995918</td>\n",
       "      <td id=\"T_52293_row4_col3\" class=\"data row4 col3\" >0.995918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52293_level0_row5\" class=\"row_heading level0 row5\" >Bagging classifier</th>\n",
       "      <td id=\"T_52293_row5_col0\" class=\"data row5 col0\" >0.989796</td>\n",
       "      <td id=\"T_52293_row5_col1\" class=\"data row5 col1\" >0.989733</td>\n",
       "      <td id=\"T_52293_row5_col2\" class=\"data row5 col2\" >0.989796</td>\n",
       "      <td id=\"T_52293_row5_col3\" class=\"data row5 col3\" >0.983673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52293_level0_row6\" class=\"row_heading level0 row6\" >Xg boost</th>\n",
       "      <td id=\"T_52293_row6_col0\" class=\"data row6 col0\" >0.995918</td>\n",
       "      <td id=\"T_52293_row6_col1\" class=\"data row6 col1\" >0.995902</td>\n",
       "      <td id=\"T_52293_row6_col2\" class=\"data row6 col2\" >0.995918</td>\n",
       "      <td id=\"T_52293_row6_col3\" class=\"data row6 col3\" >0.991837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52293_level0_row7\" class=\"row_heading level0 row7\" >VotingClassifier</th>\n",
       "      <td id=\"T_52293_row7_col0\" class=\"data row7 col0\" >0.995918</td>\n",
       "      <td id=\"T_52293_row7_col1\" class=\"data row7 col1\" >0.995902</td>\n",
       "      <td id=\"T_52293_row7_col2\" class=\"data row7 col2\" >0.995918</td>\n",
       "      <td id=\"T_52293_row7_col3\" class=\"data row7 col3\" >0.991837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_375da\" style='display:inline'>\n",
       "  <caption>Model's Performance on Validation data </caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_375da_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_375da_level0_col1\" class=\"col_heading level0 col1\" >F1_score</th>\n",
       "      <th id=\"T_375da_level0_col2\" class=\"col_heading level0 col2\" >Auroc</th>\n",
       "      <th id=\"T_375da_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_375da_level0_row0\" class=\"row_heading level0 row0\" >LogisticRegression</th>\n",
       "      <td id=\"T_375da_row0_col0\" class=\"data row0 col0\" >0.750000</td>\n",
       "      <td id=\"T_375da_row0_col1\" class=\"data row0 col1\" >0.822581</td>\n",
       "      <td id=\"T_375da_row0_col2\" class=\"data row0 col2\" >0.704762</td>\n",
       "      <td id=\"T_375da_row0_col3\" class=\"data row0 col3\" >0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_375da_level0_row1\" class=\"row_heading level0 row1\" >LinearDiscriminantClassifier</th>\n",
       "      <td id=\"T_375da_row1_col0\" class=\"data row1 col0\" >0.784091</td>\n",
       "      <td id=\"T_375da_row1_col1\" class=\"data row1 col1\" >0.848000</td>\n",
       "      <td id=\"T_375da_row1_col2\" class=\"data row1 col2\" >0.740635</td>\n",
       "      <td id=\"T_375da_row1_col3\" class=\"data row1 col3\" >0.841270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_375da_level0_row2\" class=\"row_heading level0 row2\" >AdaptiveBoosting</th>\n",
       "      <td id=\"T_375da_row2_col0\" class=\"data row2 col0\" >0.761364</td>\n",
       "      <td id=\"T_375da_row2_col1\" class=\"data row2 col1\" >0.839695</td>\n",
       "      <td id=\"T_375da_row2_col2\" class=\"data row2 col2\" >0.676508</td>\n",
       "      <td id=\"T_375da_row2_col3\" class=\"data row2 col3\" >0.873016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_375da_level0_row3\" class=\"row_heading level0 row3\" >Gradient_Boosting</th>\n",
       "      <td id=\"T_375da_row3_col0\" class=\"data row3 col0\" >0.818182</td>\n",
       "      <td id=\"T_375da_row3_col1\" class=\"data row3 col1\" >0.880597</td>\n",
       "      <td id=\"T_375da_row3_col2\" class=\"data row3 col2\" >0.728254</td>\n",
       "      <td id=\"T_375da_row3_col3\" class=\"data row3 col3\" >0.936508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_375da_level0_row4\" class=\"row_heading level0 row4\" >RandomForest</th>\n",
       "      <td id=\"T_375da_row4_col0\" class=\"data row4 col0\" >0.750000</td>\n",
       "      <td id=\"T_375da_row4_col1\" class=\"data row4 col1\" >0.835821</td>\n",
       "      <td id=\"T_375da_row4_col2\" class=\"data row4 col2\" >0.644444</td>\n",
       "      <td id=\"T_375da_row4_col3\" class=\"data row4 col3\" >0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_375da_level0_row5\" class=\"row_heading level0 row5\" >Bagging classifier</th>\n",
       "      <td id=\"T_375da_row5_col0\" class=\"data row5 col0\" >0.772727</td>\n",
       "      <td id=\"T_375da_row5_col1\" class=\"data row5 col1\" >0.846154</td>\n",
       "      <td id=\"T_375da_row5_col2\" class=\"data row5 col2\" >0.696508</td>\n",
       "      <td id=\"T_375da_row5_col3\" class=\"data row5 col3\" >0.873016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_375da_level0_row6\" class=\"row_heading level0 row6\" >Xg boost</th>\n",
       "      <td id=\"T_375da_row6_col0\" class=\"data row6 col0\" >0.750000</td>\n",
       "      <td id=\"T_375da_row6_col1\" class=\"data row6 col1\" >0.838235</td>\n",
       "      <td id=\"T_375da_row6_col2\" class=\"data row6 col2\" >0.632381</td>\n",
       "      <td id=\"T_375da_row6_col3\" class=\"data row6 col3\" >0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_375da_level0_row7\" class=\"row_heading level0 row7\" >VotingClassifier</th>\n",
       "      <td id=\"T_375da_row7_col0\" class=\"data row7 col0\" >0.772727</td>\n",
       "      <td id=\"T_375da_row7_col1\" class=\"data row7 col1\" >0.852941</td>\n",
       "      <td id=\"T_375da_row7_col2\" class=\"data row7 col2\" >0.660317</td>\n",
       "      <td id=\"T_375da_row7_col3\" class=\"data row7 col3\" >0.920635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the function to create dataframe\n",
    "\n",
    "result_frame(L2,X_train_psmt_trans, y_train_psmt_trans,X_valid5_scaled,y_valid5,m1,m2,m3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fd6ed6",
   "metadata": {},
   "source": [
    "<b>Remark:\n",
    "\n",
    "* The performance of the model in predicting the outcomes with WOE transformed training values have not improved the prediction much.\n",
    "* The overall performance of the models(Auroc) is lower compared to some of the other trials.    \n",
    "* Lets try increasing the magnitude of potential varibles and see the performance of the model in the next trial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5125fd93",
   "metadata": {},
   "source": [
    "### <font color= BLUE> Experiment 7:\n",
    "\n",
    "* <b> Higher polynomial feature transformation of variables with high Information values and not multicollinear with other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2134,
   "id": "8b2febc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train6 = data_woe[X_train4_col]\n",
    "y_train6 = data_woe[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dafd3c",
   "metadata": {},
   "source": [
    "* Lets try using ensembling method to choose the important varibles and compare the difference between the variable importance given by IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2135,
   "id": "401c2242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Using Random forest algorithm (default parameters)\n",
    "\n",
    "rf.fit(X_train6,y_train6)\n",
    "\n",
    "feat_importances = pd.Series(rf.feature_importances_, index=X_train6.columns)\n",
    "feat_importances.nlargest(20).plot(kind='barh')\n",
    "plt.show()\n",
    "\n",
    "#Random forest identifies the importance of a variable based on the mean decrease in impurity across all the decision tree estimators which are ensembled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2136,
   "id": "c5c1dd99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Info.Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>M87</td>\n",
       "      <td>0.569835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M63</td>\n",
       "      <td>0.501447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>M88</td>\n",
       "      <td>0.430760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M124</td>\n",
       "      <td>0.377283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>M148</td>\n",
       "      <td>0.362911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M28</td>\n",
       "      <td>0.332620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M66</td>\n",
       "      <td>0.321658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>M127</td>\n",
       "      <td>0.218622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M15</td>\n",
       "      <td>0.198591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M39</td>\n",
       "      <td>0.192382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>M69</td>\n",
       "      <td>0.185466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M53</td>\n",
       "      <td>0.180133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M30</td>\n",
       "      <td>0.158189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>M151</td>\n",
       "      <td>0.074704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M58</td>\n",
       "      <td>0.056745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M34</td>\n",
       "      <td>0.053250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M25</td>\n",
       "      <td>0.032649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variable  Info.Value\n",
       "11    M87     0.569835 \n",
       "8     M63     0.501447 \n",
       "12    M88     0.430760 \n",
       "13   M124     0.377283 \n",
       "15   M148     0.362911 \n",
       "2     M28     0.332620 \n",
       "9     M66     0.321658 \n",
       "14   M127     0.218622 \n",
       "0     M15     0.198591 \n",
       "5     M39     0.192382 \n",
       "10    M69     0.185466 \n",
       "6     M53     0.180133 \n",
       "3     M30     0.158189 \n",
       "16   M151     0.074704 \n",
       "7     M58     0.056745 \n",
       "4     M34     0.053250 \n",
       "1     M25     0.032649 "
      ]
     },
     "execution_count": 2136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2137,
   "id": "84bb6b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see the variable importance order made by random forest and Information Value method are not the same.\n",
    "# Lets choose the first three important variable ,then make power transformation and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2138,
   "id": "f7d39c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>M25</th>\n",
       "      <th>M28</th>\n",
       "      <th>M30</th>\n",
       "      <th>M34</th>\n",
       "      <th>M39</th>\n",
       "      <th>M53</th>\n",
       "      <th>M58</th>\n",
       "      <th>M63</th>\n",
       "      <th>M66</th>\n",
       "      <th>M87</th>\n",
       "      <th>M88</th>\n",
       "      <th>M124</th>\n",
       "      <th>M148</th>\n",
       "      <th>M151</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.700000e+07</td>\n",
       "      <td>2.358491</td>\n",
       "      <td>1.278607e+08</td>\n",
       "      <td>0.040450</td>\n",
       "      <td>4.000000e+06</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.800000e+07</td>\n",
       "      <td>-4.826130e+07</td>\n",
       "      <td>596624.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.137554</td>\n",
       "      <td>0.914831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.234333e+07</td>\n",
       "      <td>3.391304</td>\n",
       "      <td>2.199603e+07</td>\n",
       "      <td>1.803985</td>\n",
       "      <td>2.332033e+08</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.608099e+07</td>\n",
       "      <td>5.317400e+04</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.940661</td>\n",
       "      <td>1.016467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.616667e+06</td>\n",
       "      <td>0.582734</td>\n",
       "      <td>4.246794e+06</td>\n",
       "      <td>1.181445</td>\n",
       "      <td>-8.140667e+06</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.821839e+07</td>\n",
       "      <td>-1.120641e+07</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.007713</td>\n",
       "      <td>0.988912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.540000e+07</td>\n",
       "      <td>0.570909</td>\n",
       "      <td>6.375040e+07</td>\n",
       "      <td>1.015880</td>\n",
       "      <td>2.400000e+08</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.543467e+07</td>\n",
       "      <td>2.509527e+07</td>\n",
       "      <td>-3463893.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.504471</td>\n",
       "      <td>0.483688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.000000e+07</td>\n",
       "      <td>6.909091</td>\n",
       "      <td>6.912100e+04</td>\n",
       "      <td>5.559125</td>\n",
       "      <td>-2.500000e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.000000e+06</td>\n",
       "      <td>6.818941e+07</td>\n",
       "      <td>14300.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2815.070183</td>\n",
       "      <td>0.600029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        M25         M28         M30         M34         M39         M53    M58       M63           M66         M87      M88  M124     M148        M151  \n",
       "0  4.700000e+07  2.358491  1.278607e+08  0.040450  4.000000e+06  7.500000  0.0 -7.800000e+07 -4.826130e+07   596624.0  34.0   6.0     1.137554  0.914831\n",
       "1  1.234333e+07  3.391304  2.199603e+07  1.803985  2.332033e+08  1.666667  1.0 -5.608099e+07  5.317400e+04    22000.0  80.0   1.0     0.940661  1.016467\n",
       "2  3.616667e+06  0.582734  4.246794e+06  1.181445 -8.140667e+06  0.066667  0.0 -1.821839e+07 -1.120641e+07     3300.0  22.0   0.0     1.007713  0.988912\n",
       "3  7.540000e+07  0.570909  6.375040e+07  1.015880  2.400000e+08  0.200000  0.0 -7.543467e+07  2.509527e+07 -3463893.0  22.0  12.0     1.504471  0.483688\n",
       "4  3.000000e+07  6.909091  6.912100e+04  5.559125 -2.500000e+07  1.000000  0.0 -4.000000e+06  6.818941e+07    14300.0  65.0  20.0  2815.070183  0.600029"
      ]
     },
     "execution_count": 2138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actual values of varibles before transformation\n",
    "X_train6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2139,
   "id": "91c2e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the varibles to higher power to see if it increases the power of prediction\n",
    "\n",
    "# top three highly significant variable from the random forest and IV variable list\n",
    "X_train6[\"M63\"] = X_train6[\"M63\"]**2\n",
    "X_train6[\"M88\"] = X_train6[\"M88\"]**2\n",
    "X_train6[\"M124\"] = X_train6[\"M124\"]**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2140,
   "id": "207a68e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>M25</th>\n",
       "      <th>M28</th>\n",
       "      <th>M30</th>\n",
       "      <th>M34</th>\n",
       "      <th>M39</th>\n",
       "      <th>M53</th>\n",
       "      <th>M58</th>\n",
       "      <th>M63</th>\n",
       "      <th>M66</th>\n",
       "      <th>M87</th>\n",
       "      <th>M88</th>\n",
       "      <th>M124</th>\n",
       "      <th>M148</th>\n",
       "      <th>M151</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.209000e+15</td>\n",
       "      <td>2.358491</td>\n",
       "      <td>1.278607e+08</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>4.000000e+06</td>\n",
       "      <td>56.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.800000e+07</td>\n",
       "      <td>-4.826130e+07</td>\n",
       "      <td>596624.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.137554</td>\n",
       "      <td>0.914831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.523579e+14</td>\n",
       "      <td>3.391304</td>\n",
       "      <td>2.199603e+07</td>\n",
       "      <td>3.254360</td>\n",
       "      <td>2.332033e+08</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.608099e+07</td>\n",
       "      <td>5.317400e+04</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.940661</td>\n",
       "      <td>1.016467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.308028e+13</td>\n",
       "      <td>0.582734</td>\n",
       "      <td>4.246794e+06</td>\n",
       "      <td>1.395812</td>\n",
       "      <td>-8.140667e+06</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.821839e+07</td>\n",
       "      <td>-1.120641e+07</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.007713</td>\n",
       "      <td>0.988912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.685160e+15</td>\n",
       "      <td>0.570909</td>\n",
       "      <td>6.375040e+07</td>\n",
       "      <td>1.032011</td>\n",
       "      <td>2.400000e+08</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.543467e+07</td>\n",
       "      <td>2.509527e+07</td>\n",
       "      <td>-3463893.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.504471</td>\n",
       "      <td>0.483688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.000000e+14</td>\n",
       "      <td>6.909091</td>\n",
       "      <td>6.912100e+04</td>\n",
       "      <td>30.903867</td>\n",
       "      <td>-2.500000e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.000000e+06</td>\n",
       "      <td>6.818941e+07</td>\n",
       "      <td>14300.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2815.070183</td>\n",
       "      <td>0.600029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        M25         M28         M30         M34          M39         M53     M58       M63           M66         M87      M88  M124      M148        M151  \n",
       "0  2.209000e+15  2.358491  1.278607e+08   0.001636  4.000000e+06  56.250000  0.0 -7.800000e+07 -4.826130e+07   596624.0  34.0   36.0     1.137554  0.914831\n",
       "1  1.523579e+14  3.391304  2.199603e+07   3.254360  2.332033e+08   2.777778  1.0 -5.608099e+07  5.317400e+04    22000.0  80.0    1.0     0.940661  1.016467\n",
       "2  1.308028e+13  0.582734  4.246794e+06   1.395812 -8.140667e+06   0.004444  0.0 -1.821839e+07 -1.120641e+07     3300.0  22.0    0.0     1.007713  0.988912\n",
       "3  5.685160e+15  0.570909  6.375040e+07   1.032011  2.400000e+08   0.040000  0.0 -7.543467e+07  2.509527e+07 -3463893.0  22.0  144.0     1.504471  0.483688\n",
       "4  9.000000e+14  6.909091  6.912100e+04  30.903867 -2.500000e+07   1.000000  0.0 -4.000000e+06  6.818941e+07    14300.0  65.0  400.0  2815.070183  0.600029"
      ]
     },
     "execution_count": 2140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if the transformation has happened\n",
    "X_train6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2141,
   "id": "99016db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take validation data from our previous import and chose only retained variables\n",
    "y_valid6 = df1_valid_descaled[\"target\"]\n",
    "X_valid6 = df1_valid_descaled[X_train4_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2142,
   "id": "3893db18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the specified varibles in validation dataset too\n",
    "\n",
    "# top three highly significant variable from the random forest and IV variable list\n",
    "X_valid6[\"M63\"] = X_valid6[\"M63\"]**2\n",
    "X_valid6[\"M88\"] = X_valid6[\"M88\"]**2\n",
    "X_valid6[\"M124\"] = X_valid6[\"M124\"]**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2143,
   "id": "7d7e4deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the train data with only 14potential variables \n",
    "\n",
    "# initializing the scaler object\n",
    "scaler_new3 = StandardScaler()\n",
    "\n",
    "# fit and transform the train data\n",
    "data_woe_scaled_vif_transf = scaler_new3.fit_transform(X_train6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2144,
   "id": "b71f86f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the validation data using the fit of train data(mean and standard deviation)\n",
    "X_valid6_scaled = scaler_new3.transform(X_valid6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2145,
   "id": "32f97a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 Count: 245 Percentage: 50.0\n",
      "Class: 1 Count: 245 Percentage: 50.0\n"
     ]
    }
   ],
   "source": [
    "# Lets increase the sample size of the minority class before training the model\n",
    "\n",
    "#Initialize smote object - Sythetic Minority Oversampling Technique\n",
    "oversample = SMOTE(random_state=50)\n",
    "\n",
    "#oversampling the classes (Note:using the same scaled data from previous trial)\n",
    "X_train_transf, y_train_transf = oversample.fit_resample(data_woe_scaled_vif_transf, y_train6)\n",
    "\n",
    "# Summarizing the distribution\n",
    "counter = Counter(y_train_transf)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_train_transf) * 100\n",
    "    print(\"Class:\",k,\"Count:\",v,\"Percentage:\", per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2146,
   "id": "f8458598",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "LogisticRegression(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.76      0.57        25\n",
      "           1       0.87      0.63      0.73        63\n",
      "\n",
      "    accuracy                           0.67        88\n",
      "   macro avg       0.66      0.70      0.65        88\n",
      "weighted avg       0.75      0.67      0.69        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         40                 23        \n",
      "Actual -ve [0]          6                 19        \n",
      "____________________________________________________________________________________________________\n",
      "LinearDiscriminantAnalysis()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.76      0.58        25\n",
      "           1       0.88      0.67      0.76        63\n",
      "\n",
      "    accuracy                           0.69        88\n",
      "   macro avg       0.68      0.71      0.67        88\n",
      "weighted avg       0.76      0.69      0.71        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         42                 21        \n",
      "Actual -ve [0]          6                 19        \n",
      "____________________________________________________________________________________________________\n",
      "AdaBoostClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68        25\n",
      "           1       0.87      0.87      0.87        63\n",
      "\n",
      "    accuracy                           0.82        88\n",
      "   macro avg       0.78      0.78      0.78        88\n",
      "weighted avg       0.82      0.82      0.82        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         55                  8        \n",
      "Actual -ve [0]          8                 17        \n",
      "____________________________________________________________________________________________________\n",
      "GradientBoostingClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.60      0.61        25\n",
      "           1       0.84      0.86      0.85        63\n",
      "\n",
      "    accuracy                           0.78        88\n",
      "   macro avg       0.73      0.73      0.73        88\n",
      "weighted avg       0.78      0.78      0.78        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         54                  9        \n",
      "Actual -ve [0]         10                 15        \n",
      "____________________________________________________________________________________________________\n",
      "RandomForestClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.56      0.62        25\n",
      "           1       0.84      0.90      0.87        63\n",
      "\n",
      "    accuracy                           0.81        88\n",
      "   macro avg       0.77      0.73      0.75        88\n",
      "weighted avg       0.80      0.81      0.80        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         57                  6        \n",
      "Actual -ve [0]         11                 14        \n",
      "____________________________________________________________________________________________________\n",
      "BaggingClassifier(random_state=50)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.48      0.53        25\n",
      "           1       0.81      0.87      0.84        63\n",
      "\n",
      "    accuracy                           0.76        88\n",
      "   macro avg       0.70      0.68      0.69        88\n",
      "weighted avg       0.75      0.76      0.75        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         55                  8        \n",
      "Actual -ve [0]         13                 12        \n",
      "____________________________________________________________________________________________________\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=50, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.56      0.57        25\n",
      "           1       0.83      0.84      0.83        63\n",
      "\n",
      "    accuracy                           0.76        88\n",
      "   macro avg       0.71      0.70      0.70        88\n",
      "weighted avg       0.76      0.76      0.76        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         53                 10        \n",
      "Actual -ve [0]         11                 14        \n"
     ]
    }
   ],
   "source": [
    "# Classification report of multiple models over scaled - oversampled \n",
    "for i in L1:\n",
    "    multiple_model(i,X_train_transf, y_train_transf,X_valid6_scaled,y_valid6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2147,
   "id": "2522cd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64        25\n",
      "           1       0.86      0.86      0.86        63\n",
      "\n",
      "    accuracy                           0.80        88\n",
      "   macro avg       0.75      0.75      0.75        88\n",
      "weighted avg       0.80      0.80      0.80        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         54                  9        \n",
      "Actual -ve [0]          9                 16        \n"
     ]
    }
   ],
   "source": [
    "# Based on the individual performance we will choose the best classifiers as our voting classifiers\n",
    "\n",
    "m1,m2,m3 = xgb,ab,gb # xgboost,gradient,adaboost\n",
    "\n",
    "voting_classifier(m1,m2,m3,X_train_transf, y_train_transf,X_valid6_scaled,y_valid6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2148,
   "id": "85b8a138",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_c3b4b\" style='display:inline; margin-right:20px;'>\n",
       "  <caption>Model's Performance on Train data</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c3b4b_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_c3b4b_level0_col1\" class=\"col_heading level0 col1\" >F1_score</th>\n",
       "      <th id=\"T_c3b4b_level0_col2\" class=\"col_heading level0 col2\" >Auroc</th>\n",
       "      <th id=\"T_c3b4b_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c3b4b_level0_row0\" class=\"row_heading level0 row0\" >LogisticRegression</th>\n",
       "      <td id=\"T_c3b4b_row0_col0\" class=\"data row0 col0\" >0.677551</td>\n",
       "      <td id=\"T_c3b4b_row0_col1\" class=\"data row0 col1\" >0.659483</td>\n",
       "      <td id=\"T_c3b4b_row0_col2\" class=\"data row0 col2\" >0.677551</td>\n",
       "      <td id=\"T_c3b4b_row0_col3\" class=\"data row0 col3\" >0.624490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3b4b_level0_row1\" class=\"row_heading level0 row1\" >LinearDiscriminantClassifier</th>\n",
       "      <td id=\"T_c3b4b_row1_col0\" class=\"data row1 col0\" >0.683673</td>\n",
       "      <td id=\"T_c3b4b_row1_col1\" class=\"data row1 col1\" >0.668094</td>\n",
       "      <td id=\"T_c3b4b_row1_col2\" class=\"data row1 col2\" >0.683673</td>\n",
       "      <td id=\"T_c3b4b_row1_col3\" class=\"data row1 col3\" >0.636735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3b4b_level0_row2\" class=\"row_heading level0 row2\" >AdaptiveBoosting</th>\n",
       "      <td id=\"T_c3b4b_row2_col0\" class=\"data row2 col0\" >0.922449</td>\n",
       "      <td id=\"T_c3b4b_row2_col1\" class=\"data row2 col1\" >0.920833</td>\n",
       "      <td id=\"T_c3b4b_row2_col2\" class=\"data row2 col2\" >0.922449</td>\n",
       "      <td id=\"T_c3b4b_row2_col3\" class=\"data row2 col3\" >0.902041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3b4b_level0_row3\" class=\"row_heading level0 row3\" >Gradient_Boosting</th>\n",
       "      <td id=\"T_c3b4b_row3_col0\" class=\"data row3 col0\" >0.977551</td>\n",
       "      <td id=\"T_c3b4b_row3_col1\" class=\"data row3 col1\" >0.977688</td>\n",
       "      <td id=\"T_c3b4b_row3_col2\" class=\"data row3 col2\" >0.977551</td>\n",
       "      <td id=\"T_c3b4b_row3_col3\" class=\"data row3 col3\" >0.983673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3b4b_level0_row4\" class=\"row_heading level0 row4\" >RandomForest</th>\n",
       "      <td id=\"T_c3b4b_row4_col0\" class=\"data row4 col0\" >1.000000</td>\n",
       "      <td id=\"T_c3b4b_row4_col1\" class=\"data row4 col1\" >1.000000</td>\n",
       "      <td id=\"T_c3b4b_row4_col2\" class=\"data row4 col2\" >1.000000</td>\n",
       "      <td id=\"T_c3b4b_row4_col3\" class=\"data row4 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3b4b_level0_row5\" class=\"row_heading level0 row5\" >Bagging classifier</th>\n",
       "      <td id=\"T_c3b4b_row5_col0\" class=\"data row5 col0\" >0.993878</td>\n",
       "      <td id=\"T_c3b4b_row5_col1\" class=\"data row5 col1\" >0.993840</td>\n",
       "      <td id=\"T_c3b4b_row5_col2\" class=\"data row5 col2\" >0.993878</td>\n",
       "      <td id=\"T_c3b4b_row5_col3\" class=\"data row5 col3\" >0.987755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3b4b_level0_row6\" class=\"row_heading level0 row6\" >Xg boost</th>\n",
       "      <td id=\"T_c3b4b_row6_col0\" class=\"data row6 col0\" >1.000000</td>\n",
       "      <td id=\"T_c3b4b_row6_col1\" class=\"data row6 col1\" >1.000000</td>\n",
       "      <td id=\"T_c3b4b_row6_col2\" class=\"data row6 col2\" >1.000000</td>\n",
       "      <td id=\"T_c3b4b_row6_col3\" class=\"data row6 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3b4b_level0_row7\" class=\"row_heading level0 row7\" >VotingClassifier</th>\n",
       "      <td id=\"T_c3b4b_row7_col0\" class=\"data row7 col0\" >1.000000</td>\n",
       "      <td id=\"T_c3b4b_row7_col1\" class=\"data row7 col1\" >1.000000</td>\n",
       "      <td id=\"T_c3b4b_row7_col2\" class=\"data row7 col2\" >1.000000</td>\n",
       "      <td id=\"T_c3b4b_row7_col3\" class=\"data row7 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_98e9c\" style='display:inline'>\n",
       "  <caption>Model's Performance on Validation data </caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_98e9c_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_98e9c_level0_col1\" class=\"col_heading level0 col1\" >F1_score</th>\n",
       "      <th id=\"T_98e9c_level0_col2\" class=\"col_heading level0 col2\" >Auroc</th>\n",
       "      <th id=\"T_98e9c_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_98e9c_level0_row0\" class=\"row_heading level0 row0\" >LogisticRegression</th>\n",
       "      <td id=\"T_98e9c_row0_col0\" class=\"data row0 col0\" >0.670455</td>\n",
       "      <td id=\"T_98e9c_row0_col1\" class=\"data row0 col1\" >0.733945</td>\n",
       "      <td id=\"T_98e9c_row0_col2\" class=\"data row0 col2\" >0.697460</td>\n",
       "      <td id=\"T_98e9c_row0_col3\" class=\"data row0 col3\" >0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_98e9c_level0_row1\" class=\"row_heading level0 row1\" >LinearDiscriminantClassifier</th>\n",
       "      <td id=\"T_98e9c_row1_col0\" class=\"data row1 col0\" >0.693182</td>\n",
       "      <td id=\"T_98e9c_row1_col1\" class=\"data row1 col1\" >0.756757</td>\n",
       "      <td id=\"T_98e9c_row1_col2\" class=\"data row1 col2\" >0.713333</td>\n",
       "      <td id=\"T_98e9c_row1_col3\" class=\"data row1 col3\" >0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_98e9c_level0_row2\" class=\"row_heading level0 row2\" >AdaptiveBoosting</th>\n",
       "      <td id=\"T_98e9c_row2_col0\" class=\"data row2 col0\" >0.818182</td>\n",
       "      <td id=\"T_98e9c_row2_col1\" class=\"data row2 col1\" >0.873016</td>\n",
       "      <td id=\"T_98e9c_row2_col2\" class=\"data row2 col2\" >0.776508</td>\n",
       "      <td id=\"T_98e9c_row2_col3\" class=\"data row2 col3\" >0.873016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_98e9c_level0_row3\" class=\"row_heading level0 row3\" >Gradient_Boosting</th>\n",
       "      <td id=\"T_98e9c_row3_col0\" class=\"data row3 col0\" >0.784091</td>\n",
       "      <td id=\"T_98e9c_row3_col1\" class=\"data row3 col1\" >0.850394</td>\n",
       "      <td id=\"T_98e9c_row3_col2\" class=\"data row3 col2\" >0.728571</td>\n",
       "      <td id=\"T_98e9c_row3_col3\" class=\"data row3 col3\" >0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_98e9c_level0_row4\" class=\"row_heading level0 row4\" >RandomForest</th>\n",
       "      <td id=\"T_98e9c_row4_col0\" class=\"data row4 col0\" >0.806818</td>\n",
       "      <td id=\"T_98e9c_row4_col1\" class=\"data row4 col1\" >0.870229</td>\n",
       "      <td id=\"T_98e9c_row4_col2\" class=\"data row4 col2\" >0.732381</td>\n",
       "      <td id=\"T_98e9c_row4_col3\" class=\"data row4 col3\" >0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_98e9c_level0_row5\" class=\"row_heading level0 row5\" >Bagging classifier</th>\n",
       "      <td id=\"T_98e9c_row5_col0\" class=\"data row5 col0\" >0.761364</td>\n",
       "      <td id=\"T_98e9c_row5_col1\" class=\"data row5 col1\" >0.839695</td>\n",
       "      <td id=\"T_98e9c_row5_col2\" class=\"data row5 col2\" >0.676508</td>\n",
       "      <td id=\"T_98e9c_row5_col3\" class=\"data row5 col3\" >0.873016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_98e9c_level0_row6\" class=\"row_heading level0 row6\" >Xg boost</th>\n",
       "      <td id=\"T_98e9c_row6_col0\" class=\"data row6 col0\" >0.761364</td>\n",
       "      <td id=\"T_98e9c_row6_col1\" class=\"data row6 col1\" >0.834646</td>\n",
       "      <td id=\"T_98e9c_row6_col2\" class=\"data row6 col2\" >0.700635</td>\n",
       "      <td id=\"T_98e9c_row6_col3\" class=\"data row6 col3\" >0.841270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_98e9c_level0_row7\" class=\"row_heading level0 row7\" >VotingClassifier</th>\n",
       "      <td id=\"T_98e9c_row7_col0\" class=\"data row7 col0\" >0.795455</td>\n",
       "      <td id=\"T_98e9c_row7_col1\" class=\"data row7 col1\" >0.857143</td>\n",
       "      <td id=\"T_98e9c_row7_col2\" class=\"data row7 col2\" >0.748571</td>\n",
       "      <td id=\"T_98e9c_row7_col3\" class=\"data row7 col3\" >0.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the function to create dataframe\n",
    "result_frame(L2,X_train_transf,y_train_transf,X_valid6_scaled,y_valid6,m1,m2,m3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91674ff2",
   "metadata": {},
   "source": [
    "<b> Remarks:\n",
    "\n",
    "* Variable transformation over the chosen variable with higher power(2,3,5) didnt show any significant rise in the performance of the model\n",
    "* We have dropped suspecious variables(iv>0.5) too but the performance didnt improve much.   \n",
    "* Lets try using different method to check the variable importance and see the performance of the model in prediction in our next trial using lasso regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd472bd",
   "metadata": {},
   "source": [
    "### <font color= BLUE> Experiment 8\n",
    "    \n",
    "* <b> Use Lasso Regularization to identify feature importance / feature reduction in predicting the target   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2149,
   "id": "a9b58b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use Logistic Regression to idetify the varible importance using Lasso regularization\n",
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2150,
   "id": "18523ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lasso = pd.read_csv(\"Null Variables dropped denormalized and Knn_imputed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2151,
   "id": "acc7679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating X and Y\n",
    "X_train7 = data_lasso.iloc[:,:-1]\n",
    "y_train7 = data_lasso[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2152,
   "id": "00757aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize # initializing the scaler object\n",
    "scaler_lasso = StandardScaler()\n",
    "\n",
    "# fit and transform the train data\n",
    "data_lasso_scaled = scaler_lasso.fit_transform(X_train7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2153,
   "id": "8fe857d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(cv=5, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 2153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using logistic regression model to fit lasso penalty\n",
    "lasso = LogisticRegressionCV(penalty='l1', solver='liblinear', cv=5)\n",
    "lasso.fit(data_lasso_scaled, y_train7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2154,
   "id": "0b448eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 2154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Coefficients of each variable\n",
    "len(lasso.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2155,
   "id": "12b7cd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Variables  Lasso_coeff\n",
      "0        M1     0.000000  \n",
      "1        M2     0.203512  \n",
      "2        M3     0.000000  \n",
      "3        M4     0.000000  \n",
      "4        M6     0.000000  \n",
      "5        M7    -0.088175  \n",
      "6        M8     0.000000  \n",
      "7        M9     0.000000  \n",
      "8       M10     0.003454  \n",
      "9       M11     0.000000  \n",
      "10      M12     0.000000  \n",
      "11      M13     0.000000  \n",
      "12      M14     0.000000  \n",
      "13      M15     0.000000  \n",
      "14      M16     0.000000  \n",
      "15      M17    -0.046771  \n",
      "16      M18     0.000000  \n",
      "17      M19     0.000000  \n",
      "18      M20     0.000000  \n",
      "19      M21     0.000000  \n",
      "20      M22     0.000000  \n",
      "21      M23     0.000000  \n",
      "22      M24     0.000000  \n",
      "23      M25     0.000000  \n",
      "24      M26     0.000000  \n",
      "25      M27     0.000000  \n",
      "26      M28     0.196948  \n",
      "27      M29    -0.319959  \n",
      "28      M30     0.065543  \n",
      "29      M31    -0.026610  \n",
      "30      M32     0.000000  \n",
      "31      M33     0.000000  \n",
      "32      M34     0.000000  \n",
      "33      M35     0.021993  \n",
      "34      M37     0.000000  \n",
      "35      M38    -0.020501  \n",
      "36      M39     0.014805  \n",
      "37      M40     0.000000  \n",
      "38      M41     0.000000  \n",
      "39      M42     0.000000  \n",
      "40      M43     0.000000  \n",
      "41      M44     0.000000  \n",
      "42      M45     0.000000  \n",
      "43      M46    -0.110492  \n",
      "44      M47     0.006240  \n",
      "45      M48     0.000000  \n",
      "46      M50     0.000000  \n",
      "47      M51     0.000000  \n",
      "48      M52     0.000000  \n",
      "49      M53     0.159373  \n",
      "50      M54     0.000000  \n",
      "51      M55     0.000000  \n",
      "52      M56     0.000000  \n",
      "53      M57     0.000000  \n",
      "54      M58     0.000000  \n",
      "55      M59     0.000000  \n",
      "56      M60     0.000000  \n",
      "57      M61    -0.111828  \n",
      "58      M62     0.017015  \n",
      "59      M63     0.000000  \n",
      "60      M64     0.000000  \n",
      "61      M65     0.000000  \n",
      "62      M66     0.000000  \n",
      "63      M67     0.012852  \n",
      "64      M68    -0.334644  \n",
      "65      M69     0.000000  \n",
      "66      M70     0.000000  \n",
      "67      M71     0.197545  \n",
      "68      M73     0.000000  \n",
      "69      M74     0.000000  \n",
      "70      M75     0.000000  \n",
      "71      M76     0.000000  \n",
      "72      M77     0.000000  \n",
      "73      M78     0.000000  \n",
      "74      M79     0.000000  \n",
      "75      M80     0.200118  \n",
      "76      M81     0.000000  \n",
      "77      M82     0.000000  \n",
      "78      M83    -0.400720  \n",
      "79      M84     0.000000  \n",
      "80      M85     0.000000  \n",
      "81      M86     0.000000  \n",
      "82      M87     0.132138  \n",
      "83      M88     0.572238  \n",
      "84      M89     0.000000  \n",
      "85      M90     0.000000  \n",
      "86      M91     0.000000  \n",
      "87      M92     0.000000  \n",
      "88      M93     0.000000  \n",
      "89      M94    -0.129995  \n",
      "90      M95     0.012540  \n",
      "91      M96     0.000000  \n",
      "92      M97     0.002819  \n",
      "93      M98     0.000000  \n",
      "94      M99     0.000000  \n",
      "95     M100     0.000000  \n",
      "96     M101     0.000000  \n",
      "97     M102     0.000000  \n",
      "98     M103     0.000000  \n",
      "99     M104     0.000000  \n",
      "100    M105     0.000000  \n",
      "101    M106     0.071603  \n",
      "102    M107    -0.073599  \n",
      "103    M108     0.000000  \n",
      "104    M109     0.000000  \n",
      "105    M110     0.000000  \n",
      "106    M111     0.000000  \n",
      "107    M112     0.000000  \n",
      "108    M113     0.000000  \n",
      "109    M114     0.000000  \n",
      "110    M115    -0.019572  \n",
      "111    M116     0.000000  \n",
      "112    M117     0.000000  \n",
      "113    M118     0.000000  \n",
      "114    M119     0.000000  \n",
      "115    M120     0.000000  \n",
      "116    M121     0.000000  \n",
      "117    M122     0.000000  \n",
      "118    M123     0.000000  \n",
      "119    M124     0.387410  \n",
      "120    M125     0.000000  \n",
      "121    M126     0.000000  \n",
      "122    M127     0.000000  \n",
      "123    M128     0.000000  \n",
      "124    M129     0.000000  \n",
      "125    M130     0.000000  \n",
      "126    M131     0.000000  \n",
      "127    M132     0.000000  \n",
      "128    M133    -0.117771  \n",
      "129    M134     0.000000  \n",
      "130    M135    -0.312478  \n",
      "131    M136     0.000000  \n",
      "132    M137     0.000000  \n",
      "133    M138     0.000000  \n",
      "134    M139     0.000000  \n",
      "135    M140     0.000000  \n",
      "136    M141     0.259973  \n",
      "137    M142     0.240262  \n",
      "138    M143     0.000000  \n",
      "139    M144     0.000000  \n",
      "140    M145     0.000000  \n",
      "141    M146     0.000000  \n",
      "142    M147    -0.203520  \n",
      "143    M148     0.026436  \n",
      "144    M149    -0.337007  \n",
      "145    M150    -0.037902  \n",
      "146    M151     0.041928  \n"
     ]
    }
   ],
   "source": [
    "#Creating dataframe for all coefficients wrt to variables \n",
    "lasso_coeff_frame = pd.DataFrame({\"Variables\":X_train7.columns,\"Lasso_coeff\":lasso.coef_[0]})\n",
    "print(lasso_coeff_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2156,
   "id": "20bc83f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 2156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variables without null coefficients\n",
    "lasso_coeff_frame = lasso_coeff_frame.drop(lasso_coeff_frame[lasso_coeff_frame['Lasso_coeff'] ==0].index)\n",
    "len(lasso_coeff_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2305ea28",
   "metadata": {},
   "source": [
    "* From lasso regularization ,it has nullified 108 variables coefficient (147-39=108) stating it as insignificant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2157,
   "id": "d0c2f3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take validation data from our previous import and chose only the selected variables with lasso\n",
    "y_valid7 = df1_valid_descaled[\"target\"]\n",
    "X_valid7 = df1_valid_descaled.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2158,
   "id": "1e16a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the validation data using the fit of train data(mean and standard deviation)\n",
    "X_valid7_scaled = scaler_lasso.transform(X_valid7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2159,
   "id": "368adde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "LogisticRegressionCV(cv=5, penalty='l1', solver='liblinear')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.24      0.36        25\n",
      "           1       0.76      0.97      0.85        63\n",
      "\n",
      "    accuracy                           0.76        88\n",
      "   macro avg       0.76      0.60      0.61        88\n",
      "weighted avg       0.76      0.76      0.71        88\n",
      "\n",
      "                Predicted +ve [1]  Predicted -ve [0]\n",
      "Actual +ve [1]         61                  2        \n",
      "Actual -ve [0]         19                  6        \n"
     ]
    }
   ],
   "source": [
    "for i in [lasso]:\n",
    "    multiple_model(i,data_lasso_scaled, y_train7,X_valid7_scaled,y_valid7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f1d9cd",
   "metadata": {},
   "source": [
    "<b> Remarks:\n",
    "* Lasso helps to nullify the co-efficients of the variables which have no significant effect over the target.In our case it has nullified 108 variables.However the important variables stated by others methods like IV and Ensembling are different.\n",
    "* We can try to identify the Multicollinear variables followed by one after the other and check the change in performance of the models.\n",
    "* The results from Logistic reg using Lasso Regularization are not satisfactory because it could not classify the minority classes well.Apply oversampling techniques is dfficult in this case because oversampling changes the property of the data which could be misleading for lasso method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc3fd0c",
   "metadata": {},
   "source": [
    "### 6.TEST PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3968829c",
   "metadata": {},
   "source": [
    "<b> Model and Method for final prediction,\n",
    "* The method which gave the best result in prediction for the given dataset  \n",
    "              {\"EXPERIMENT 4\" : [Feature selection using Information Value --> Standardized --> Oversampled]} \n",
    "* We will use Voting classifiers which was performing better than other individual models in most of the trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2022,
   "id": "8fa17424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing test data\n",
    "test_data = pd.read_csv(\"OOT_data_Jenfi_assessment_070423.csv\")\n",
    "\n",
    "# dropping all variables which we dropped in train data\n",
    "test_data.drop(['M5', 'M36', 'M49', 'M72',\"Unnamed: 0\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2023,
   "id": "0caf3e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M1       0\n",
       "M2       1\n",
       "M3      35\n",
       "M4       0\n",
       "M6       0\n",
       "M7      49\n",
       "M8       3\n",
       "M9       1\n",
       "M10      3\n",
       "M11      0\n",
       "M12      9\n",
       "M13      0\n",
       "M14      2\n",
       "M15      0\n",
       "M16      1\n",
       "M17      0\n",
       "M18      0\n",
       "M19      0\n",
       "M20      1\n",
       "M21      1\n",
       "M22      1\n",
       "M23      0\n",
       "M24      0\n",
       "M25     51\n",
       "M26      0\n",
       "M27      0\n",
       "M28      0\n",
       "M29      1\n",
       "M30     50\n",
       "M31      1\n",
       "M32      6\n",
       "M33     44\n",
       "M34     18\n",
       "M35      3\n",
       "M37      1\n",
       "M38      1\n",
       "M39     48\n",
       "M40     52\n",
       "M41     16\n",
       "M42      7\n",
       "M43      1\n",
       "M44      1\n",
       "M45      0\n",
       "M46     55\n",
       "M47      0\n",
       "M48      1\n",
       "M50      3\n",
       "M51      1\n",
       "M52     37\n",
       "M53     10\n",
       "M54      0\n",
       "M55      4\n",
       "M56      2\n",
       "M57      0\n",
       "M58      0\n",
       "M59      0\n",
       "M60      0\n",
       "M61      0\n",
       "M62      7\n",
       "M63     12\n",
       "M64     55\n",
       "M65      0\n",
       "M66      0\n",
       "M67      1\n",
       "M68      0\n",
       "M69      0\n",
       "M70      0\n",
       "M71     35\n",
       "M73      1\n",
       "M74      7\n",
       "M75      0\n",
       "M76      0\n",
       "M77      0\n",
       "M78      2\n",
       "M79      0\n",
       "M80      1\n",
       "M81     11\n",
       "M82      1\n",
       "M83      1\n",
       "M84      1\n",
       "M85      0\n",
       "M86     12\n",
       "M87      1\n",
       "M88      0\n",
       "M89      0\n",
       "M90      6\n",
       "M91      1\n",
       "M92      1\n",
       "M93      0\n",
       "M94      2\n",
       "M95     24\n",
       "M96     15\n",
       "M97     11\n",
       "M98      0\n",
       "M99      0\n",
       "M100     1\n",
       "M101     1\n",
       "M102    14\n",
       "M103    12\n",
       "M104     0\n",
       "M105     2\n",
       "M106     1\n",
       "M107    12\n",
       "M108     7\n",
       "M109     8\n",
       "M110     0\n",
       "M111     1\n",
       "M112     3\n",
       "M113    12\n",
       "M114     0\n",
       "M115     0\n",
       "M116     1\n",
       "M117     1\n",
       "M118     0\n",
       "M119     0\n",
       "M120     0\n",
       "M121     0\n",
       "M122     0\n",
       "M123     0\n",
       "M124     1\n",
       "M125     1\n",
       "M126     1\n",
       "M127     0\n",
       "M128     0\n",
       "M129     1\n",
       "M130     1\n",
       "M131     0\n",
       "M132     1\n",
       "M133     7\n",
       "M134     1\n",
       "M135    12\n",
       "M136     0\n",
       "M137    12\n",
       "M138     0\n",
       "M139     0\n",
       "M140     0\n",
       "M141     0\n",
       "M142     1\n",
       "M143     1\n",
       "M144     0\n",
       "M145     0\n",
       "M146     0\n",
       "M147     1\n",
       "M148     0\n",
       "M149    20\n",
       "M150    31\n",
       "M151     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2023,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "test_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2024,
   "id": "3e00421a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M1      float64\n",
       "M2      float64\n",
       "M3      float64\n",
       "M4      float64\n",
       "M6      float64\n",
       "M7      float64\n",
       "M8      float64\n",
       "M9      float64\n",
       "M10     float64\n",
       "M11     float64\n",
       "M12     float64\n",
       "M13     float64\n",
       "M14     float64\n",
       "M15       int64\n",
       "M16     float64\n",
       "M17     float64\n",
       "M18     float64\n",
       "M19     float64\n",
       "M20     float64\n",
       "M21     float64\n",
       "M22     float64\n",
       "M23     float64\n",
       "M24     float64\n",
       "M25     float64\n",
       "M26       int64\n",
       "M27       int64\n",
       "M28     float64\n",
       "M29     float64\n",
       "M30     float64\n",
       "M31     float64\n",
       "M32     float64\n",
       "M33     float64\n",
       "M34     float64\n",
       "M35     float64\n",
       "M37     float64\n",
       "M38     float64\n",
       "M39     float64\n",
       "M40     float64\n",
       "M41     float64\n",
       "M42     float64\n",
       "M43     float64\n",
       "M44     float64\n",
       "M45     float64\n",
       "M46     float64\n",
       "M47       int64\n",
       "M48     float64\n",
       "M50     float64\n",
       "M51     float64\n",
       "M52     float64\n",
       "M53     float64\n",
       "M54     float64\n",
       "M55     float64\n",
       "M56     float64\n",
       "M57     float64\n",
       "M58       int64\n",
       "M59     float64\n",
       "M60     float64\n",
       "M61     float64\n",
       "M62     float64\n",
       "M63     float64\n",
       "M64     float64\n",
       "M65     float64\n",
       "M66     float64\n",
       "M67     float64\n",
       "M68     float64\n",
       "M69       int64\n",
       "M70       int64\n",
       "M71     float64\n",
       "M73     float64\n",
       "M74     float64\n",
       "M75     float64\n",
       "M76     float64\n",
       "M77     float64\n",
       "M78     float64\n",
       "M79     float64\n",
       "M80     float64\n",
       "M81     float64\n",
       "M82     float64\n",
       "M83     float64\n",
       "M84     float64\n",
       "M85     float64\n",
       "M86     float64\n",
       "M87     float64\n",
       "M88       int64\n",
       "M89     float64\n",
       "M90     float64\n",
       "M91     float64\n",
       "M92     float64\n",
       "M93     float64\n",
       "M94     float64\n",
       "M95     float64\n",
       "M96     float64\n",
       "M97     float64\n",
       "M98     float64\n",
       "M99     float64\n",
       "M100    float64\n",
       "M101    float64\n",
       "M102    float64\n",
       "M103    float64\n",
       "M104    float64\n",
       "M105    float64\n",
       "M106    float64\n",
       "M107    float64\n",
       "M108    float64\n",
       "M109    float64\n",
       "M110    float64\n",
       "M111    float64\n",
       "M112    float64\n",
       "M113    float64\n",
       "M114    float64\n",
       "M115    float64\n",
       "M116    float64\n",
       "M117    float64\n",
       "M118    float64\n",
       "M119    float64\n",
       "M120    float64\n",
       "M121    float64\n",
       "M122    float64\n",
       "M123    float64\n",
       "M124    float64\n",
       "M125    float64\n",
       "M126    float64\n",
       "M127    float64\n",
       "M128      int64\n",
       "M129    float64\n",
       "M130    float64\n",
       "M131    float64\n",
       "M132    float64\n",
       "M133    float64\n",
       "M134    float64\n",
       "M135    float64\n",
       "M136    float64\n",
       "M137    float64\n",
       "M138    float64\n",
       "M139    float64\n",
       "M140    float64\n",
       "M141    float64\n",
       "M142    float64\n",
       "M143    float64\n",
       "M144    float64\n",
       "M145    float64\n",
       "M146    float64\n",
       "M147    float64\n",
       "M148    float64\n",
       "M149    float64\n",
       "M150    float64\n",
       "M151    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2024,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check variable type\n",
    "test_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2025,
   "id": "ec3e3aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace inf with nan to overcome errors\n",
    "test_data.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2026,
   "id": "257aab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the dataset, only transforming because we will use the same fit of train data\n",
    "test_data_norm = mm_scaler.transform(test_data)\n",
    "\n",
    "# imputing the test dataset using knn method \"3\" neighbours\n",
    "test_data_imputed = imputer.transform(test_data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2027,
   "id": "21df47f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denormalizing the imputed values into original scale and converting to dataframe \n",
    "test_descaled = pd.DataFrame(mm_scaler.inverse_transform(test_data_imputed))\n",
    "test_descaled.set_axis(df1_valid_col[:-1], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2028,
   "id": "c77a0f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>M6</th>\n",
       "      <th>M7</th>\n",
       "      <th>M8</th>\n",
       "      <th>M9</th>\n",
       "      <th>M10</th>\n",
       "      <th>M11</th>\n",
       "      <th>M12</th>\n",
       "      <th>M13</th>\n",
       "      <th>M14</th>\n",
       "      <th>M15</th>\n",
       "      <th>M16</th>\n",
       "      <th>M17</th>\n",
       "      <th>M18</th>\n",
       "      <th>M19</th>\n",
       "      <th>M20</th>\n",
       "      <th>M21</th>\n",
       "      <th>M22</th>\n",
       "      <th>M23</th>\n",
       "      <th>M24</th>\n",
       "      <th>M25</th>\n",
       "      <th>M26</th>\n",
       "      <th>M27</th>\n",
       "      <th>M28</th>\n",
       "      <th>M29</th>\n",
       "      <th>M30</th>\n",
       "      <th>M31</th>\n",
       "      <th>M32</th>\n",
       "      <th>M33</th>\n",
       "      <th>M34</th>\n",
       "      <th>M35</th>\n",
       "      <th>M37</th>\n",
       "      <th>M38</th>\n",
       "      <th>M39</th>\n",
       "      <th>M40</th>\n",
       "      <th>M41</th>\n",
       "      <th>M42</th>\n",
       "      <th>M43</th>\n",
       "      <th>M44</th>\n",
       "      <th>M45</th>\n",
       "      <th>M46</th>\n",
       "      <th>M47</th>\n",
       "      <th>M48</th>\n",
       "      <th>M50</th>\n",
       "      <th>M51</th>\n",
       "      <th>M52</th>\n",
       "      <th>M53</th>\n",
       "      <th>M54</th>\n",
       "      <th>M55</th>\n",
       "      <th>M56</th>\n",
       "      <th>M57</th>\n",
       "      <th>M58</th>\n",
       "      <th>M59</th>\n",
       "      <th>M60</th>\n",
       "      <th>M61</th>\n",
       "      <th>M62</th>\n",
       "      <th>M63</th>\n",
       "      <th>M64</th>\n",
       "      <th>M65</th>\n",
       "      <th>M66</th>\n",
       "      <th>M67</th>\n",
       "      <th>M68</th>\n",
       "      <th>M69</th>\n",
       "      <th>M70</th>\n",
       "      <th>M71</th>\n",
       "      <th>M73</th>\n",
       "      <th>M74</th>\n",
       "      <th>M75</th>\n",
       "      <th>M76</th>\n",
       "      <th>M77</th>\n",
       "      <th>M78</th>\n",
       "      <th>M79</th>\n",
       "      <th>M80</th>\n",
       "      <th>M81</th>\n",
       "      <th>M82</th>\n",
       "      <th>M83</th>\n",
       "      <th>M84</th>\n",
       "      <th>M85</th>\n",
       "      <th>M86</th>\n",
       "      <th>M87</th>\n",
       "      <th>M88</th>\n",
       "      <th>M89</th>\n",
       "      <th>M90</th>\n",
       "      <th>M91</th>\n",
       "      <th>M92</th>\n",
       "      <th>M93</th>\n",
       "      <th>M94</th>\n",
       "      <th>M95</th>\n",
       "      <th>M96</th>\n",
       "      <th>M97</th>\n",
       "      <th>M98</th>\n",
       "      <th>M99</th>\n",
       "      <th>M100</th>\n",
       "      <th>M101</th>\n",
       "      <th>M102</th>\n",
       "      <th>M103</th>\n",
       "      <th>M104</th>\n",
       "      <th>M105</th>\n",
       "      <th>M106</th>\n",
       "      <th>M107</th>\n",
       "      <th>M108</th>\n",
       "      <th>M109</th>\n",
       "      <th>M110</th>\n",
       "      <th>M111</th>\n",
       "      <th>M112</th>\n",
       "      <th>M113</th>\n",
       "      <th>M114</th>\n",
       "      <th>M115</th>\n",
       "      <th>M116</th>\n",
       "      <th>M117</th>\n",
       "      <th>M118</th>\n",
       "      <th>M119</th>\n",
       "      <th>M120</th>\n",
       "      <th>M121</th>\n",
       "      <th>M122</th>\n",
       "      <th>M123</th>\n",
       "      <th>M124</th>\n",
       "      <th>M125</th>\n",
       "      <th>M126</th>\n",
       "      <th>M127</th>\n",
       "      <th>M128</th>\n",
       "      <th>M129</th>\n",
       "      <th>M130</th>\n",
       "      <th>M131</th>\n",
       "      <th>M132</th>\n",
       "      <th>M133</th>\n",
       "      <th>M134</th>\n",
       "      <th>M135</th>\n",
       "      <th>M136</th>\n",
       "      <th>M137</th>\n",
       "      <th>M138</th>\n",
       "      <th>M139</th>\n",
       "      <th>M140</th>\n",
       "      <th>M141</th>\n",
       "      <th>M142</th>\n",
       "      <th>M143</th>\n",
       "      <th>M144</th>\n",
       "      <th>M145</th>\n",
       "      <th>M146</th>\n",
       "      <th>M147</th>\n",
       "      <th>M148</th>\n",
       "      <th>M149</th>\n",
       "      <th>M150</th>\n",
       "      <th>M151</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.794286e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.113188e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.557256e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.257300e+08</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.797325e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.468956e+06</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>2.205000e+14</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.123875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-500000000.0</td>\n",
       "      <td>1.033925e+08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.073184e+06</td>\n",
       "      <td>1.285714e+05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8755428.0</td>\n",
       "      <td>956000.0</td>\n",
       "      <td>7.177382e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.204300e+07</td>\n",
       "      <td>2.142857e+06</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-2.291686e+04</td>\n",
       "      <td>1.336887e+17</td>\n",
       "      <td>-3.552769e+07</td>\n",
       "      <td>9.523810e+06</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.465011e+05</td>\n",
       "      <td>1501091.0</td>\n",
       "      <td>6434310.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.893583e+05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1471091.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.489016e+05</td>\n",
       "      <td>6.354857e+08</td>\n",
       "      <td>178.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>956682.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.759622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>5019704.0</td>\n",
       "      <td>2.144416e+05</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>3.028764e+05</td>\n",
       "      <td>7.900245e+15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.554369e+06</td>\n",
       "      <td>6.829441e+06</td>\n",
       "      <td>1.680639e+06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>4.286591e+05</td>\n",
       "      <td>6.663588e+06</td>\n",
       "      <td>3.550145e+06</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>2.854730e+05</td>\n",
       "      <td>1.888868e+07</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>2.291686e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.018747e+06</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1471091.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.471091e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35243117.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.600193e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.245265</td>\n",
       "      <td>0.237600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.543407e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>1.172131</td>\n",
       "      <td>5.587033e+06</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.609760e+07</td>\n",
       "      <td>14191650.0</td>\n",
       "      <td>1.165804e+07</td>\n",
       "      <td>6.857143</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>325.0</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>1.404086e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>5.044710e+06</td>\n",
       "      <td>62143844.0</td>\n",
       "      <td>5.500000e+04</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092462</td>\n",
       "      <td>2639437.0</td>\n",
       "      <td>1.659751e+07</td>\n",
       "      <td>1007127.0</td>\n",
       "      <td>6.289461e+14</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9.972064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.571429</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4900000.0</td>\n",
       "      <td>2.996722e+07</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.498189e+07</td>\n",
       "      <td>1.885714e+06</td>\n",
       "      <td>80.0</td>\n",
       "      <td>24259987.0</td>\n",
       "      <td>1006378.0</td>\n",
       "      <td>2.245893e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>3905022.0</td>\n",
       "      <td>5.766667</td>\n",
       "      <td>4.580667e+07</td>\n",
       "      <td>5.520570e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>3.586779e+05</td>\n",
       "      <td>7.221932e+13</td>\n",
       "      <td>-4.775762e+06</td>\n",
       "      <td>1.100000e+06</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-1.681813e+06</td>\n",
       "      <td>2892661.0</td>\n",
       "      <td>13483963.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.857143</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>33.142857</td>\n",
       "      <td>13511819.0</td>\n",
       "      <td>9.592868e+06</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.431868e+06</td>\n",
       "      <td>82.0</td>\n",
       "      <td>15.285714</td>\n",
       "      <td>4515097.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.087866e+06</td>\n",
       "      <td>1.864471e+13</td>\n",
       "      <td>-1124458.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>33.571429</td>\n",
       "      <td>11067848.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>29.142857</td>\n",
       "      <td>1007127.0</td>\n",
       "      <td>26.811720</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>6.809834e+06</td>\n",
       "      <td>1340300.0</td>\n",
       "      <td>6.411309e+06</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>4.283151e+06</td>\n",
       "      <td>1.097304e+13</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>40.428571</td>\n",
       "      <td>83.200000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>78.142857</td>\n",
       "      <td>13.5</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1.916434e+07</td>\n",
       "      <td>1.278329e+07</td>\n",
       "      <td>7.545009e+06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>71.571429</td>\n",
       "      <td>4.681515e+06</td>\n",
       "      <td>3.647328e+06</td>\n",
       "      <td>1.056140e+07</td>\n",
       "      <td>46.285714</td>\n",
       "      <td>4.893895e+06</td>\n",
       "      <td>5.758583e+06</td>\n",
       "      <td>39.720000</td>\n",
       "      <td>8.601064e+06</td>\n",
       "      <td>1024754.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.428571</td>\n",
       "      <td>4.983020e+06</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>162.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>6516128.0</td>\n",
       "      <td>51.857708</td>\n",
       "      <td>11.571429</td>\n",
       "      <td>3.786031e+06</td>\n",
       "      <td>16834478.0</td>\n",
       "      <td>3866209.0</td>\n",
       "      <td>64.142857</td>\n",
       "      <td>83.285714</td>\n",
       "      <td>30.428571</td>\n",
       "      <td>3236363.0</td>\n",
       "      <td>4.135060e+06</td>\n",
       "      <td>11.285714</td>\n",
       "      <td>57.142857</td>\n",
       "      <td>4.361425e+06</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.011859</td>\n",
       "      <td>0.896424</td>\n",
       "      <td>0.956242</td>\n",
       "      <td>2.577387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.012459e+08</td>\n",
       "      <td>1134035.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>9.885223e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.795683e+06</td>\n",
       "      <td>127916014.0</td>\n",
       "      <td>1.331600e+07</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.178193e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.046667e+07</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.157895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.376695e+07</td>\n",
       "      <td>310766.0</td>\n",
       "      <td>9.046273e+13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.253068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15070000.0</td>\n",
       "      <td>4.543338e+06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.310748e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34916014.0</td>\n",
       "      <td>927400.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>332610063.0</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>6.323682e+08</td>\n",
       "      <td>5.714770e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17716621.0</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>-3.882796e+06</td>\n",
       "      <td>2.179054e+14</td>\n",
       "      <td>1.070333e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.627143e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137016014.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>19019676.0</td>\n",
       "      <td>3.503660e+05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11529063.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.985567e+07</td>\n",
       "      <td>5.167185e+08</td>\n",
       "      <td>39600.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>2651570.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>310766.0</td>\n",
       "      <td>1.333433</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>8.655591e+06</td>\n",
       "      <td>85406063.0</td>\n",
       "      <td>1.500651e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.843871e+05</td>\n",
       "      <td>2.430042e+14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.601037e+07</td>\n",
       "      <td>1.172782e+06</td>\n",
       "      <td>2.664463e+06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.353150e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.891014e+05</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2.136710e+07</td>\n",
       "      <td>7.838148e+07</td>\n",
       "      <td>1.170213</td>\n",
       "      <td>5.001665e+07</td>\n",
       "      <td>7155903.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.688426e+06</td>\n",
       "      <td>4.265823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>19990563.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.339770e+06</td>\n",
       "      <td>85916014.0</td>\n",
       "      <td>1577886.0</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>4.980363e+07</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.567944</td>\n",
       "      <td>0.567978</td>\n",
       "      <td>0.011124</td>\n",
       "      <td>1644.004255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.225474e+06</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>1.002975</td>\n",
       "      <td>2.081377e+07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.579175e+09</td>\n",
       "      <td>124444316.0</td>\n",
       "      <td>3.944277e+09</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>3.170632e+08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>1.708905e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000e+07</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.366197</td>\n",
       "      <td>604619504.0</td>\n",
       "      <td>3.518295e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.123793e+15</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-40000000.0</td>\n",
       "      <td>1.256615e+06</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.008919e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38193571.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.214482e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1595295.0</td>\n",
       "      <td>3.366667</td>\n",
       "      <td>1.100105e+10</td>\n",
       "      <td>1.882292e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2687095.0</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>-1.146829e+04</td>\n",
       "      <td>2.669180e+17</td>\n",
       "      <td>-3.924670e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-6.914751e+05</td>\n",
       "      <td>968009.0</td>\n",
       "      <td>22267461.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>13875412.0</td>\n",
       "      <td>2.266471e+09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.577113e+09</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>978209.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.980420e+07</td>\n",
       "      <td>3.470651e+13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>8232632.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000043</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>1.577993e+07</td>\n",
       "      <td>3235975.0</td>\n",
       "      <td>7.739459e+06</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.496992e+07</td>\n",
       "      <td>3.369973e+14</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>6.571429</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.785714</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.946436e+07</td>\n",
       "      <td>6.554614e+07</td>\n",
       "      <td>4.788840e+08</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>4.531227e+07</td>\n",
       "      <td>7.409697e+06</td>\n",
       "      <td>8.745908e+07</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>2.904543e+07</td>\n",
       "      <td>8.145848e+06</td>\n",
       "      <td>3.936170</td>\n",
       "      <td>2.519615e+08</td>\n",
       "      <td>1916384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>1.646083e+08</td>\n",
       "      <td>1.295775</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>3662970.0</td>\n",
       "      <td>7.719368</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>3.662970e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>5312567.0</td>\n",
       "      <td>1.583906e+09</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>3.542267e+06</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.001406</td>\n",
       "      <td>0.688247</td>\n",
       "      <td>1.000989</td>\n",
       "      <td>0.676825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.729485e+08</td>\n",
       "      <td>64920402.0</td>\n",
       "      <td>1.196457e+07</td>\n",
       "      <td>6.285714</td>\n",
       "      <td>8.428571</td>\n",
       "      <td>1.063923</td>\n",
       "      <td>2.310918e+08</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.460352e+08</td>\n",
       "      <td>279911624.0</td>\n",
       "      <td>1.528770e+09</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.857143</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.571429</td>\n",
       "      <td>10.857143</td>\n",
       "      <td>9.966037e+07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.441646e+08</td>\n",
       "      <td>109633600.0</td>\n",
       "      <td>5.000000e+06</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.751572</td>\n",
       "      <td>961110758.0</td>\n",
       "      <td>5.075818e+06</td>\n",
       "      <td>732060.0</td>\n",
       "      <td>5.306241e+16</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>4.128299</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-200000000.0</td>\n",
       "      <td>1.935521e+07</td>\n",
       "      <td>81.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.663644e+08</td>\n",
       "      <td>9.043607e+06</td>\n",
       "      <td>5.0</td>\n",
       "      <td>518476925.0</td>\n",
       "      <td>10383896.0</td>\n",
       "      <td>9.980783e+07</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>35465171.0</td>\n",
       "      <td>227.809524</td>\n",
       "      <td>3.028163e+08</td>\n",
       "      <td>1.485740e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3494160.0</td>\n",
       "      <td>8.428571</td>\n",
       "      <td>-2.554114e+07</td>\n",
       "      <td>2.150557e+16</td>\n",
       "      <td>-1.711082e+08</td>\n",
       "      <td>2.242759e+07</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-5.809210e+06</td>\n",
       "      <td>40898024.0</td>\n",
       "      <td>346754863.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.857143</td>\n",
       "      <td>13.714286</td>\n",
       "      <td>211333404.0</td>\n",
       "      <td>9.611108e+08</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.634677e+08</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>1661268.0</td>\n",
       "      <td>6.428571</td>\n",
       "      <td>3.536520e+08</td>\n",
       "      <td>6.592732e+16</td>\n",
       "      <td>-22908000.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.285714</td>\n",
       "      <td>431783173.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>732060.0</td>\n",
       "      <td>1.125225</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>3.819818e+08</td>\n",
       "      <td>194215920.0</td>\n",
       "      <td>4.993935e+07</td>\n",
       "      <td>10.571429</td>\n",
       "      <td>2.097739e+08</td>\n",
       "      <td>4.927524e+15</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>10.428571</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.888889</td>\n",
       "      <td>12.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.429480e+08</td>\n",
       "      <td>1.232215e+08</td>\n",
       "      <td>2.881400e+08</td>\n",
       "      <td>57.0</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>4.998138e+08</td>\n",
       "      <td>1.571393e+08</td>\n",
       "      <td>1.734076e+08</td>\n",
       "      <td>8.571429</td>\n",
       "      <td>3.683402e+08</td>\n",
       "      <td>1.176948e+08</td>\n",
       "      <td>9.931034</td>\n",
       "      <td>2.319186e+08</td>\n",
       "      <td>76438343.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.142857</td>\n",
       "      <td>2.689057e+08</td>\n",
       "      <td>0.937429</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.714286</td>\n",
       "      <td>101847045.0</td>\n",
       "      <td>55.531183</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>1.018470e+08</td>\n",
       "      <td>569246307.0</td>\n",
       "      <td>73893623.0</td>\n",
       "      <td>8.285714</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>213957347.0</td>\n",
       "      <td>1.775612e+08</td>\n",
       "      <td>6.857143</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>3.942189e+08</td>\n",
       "      <td>8.571429</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.525406</td>\n",
       "      <td>1.626870</td>\n",
       "      <td>1.076617</td>\n",
       "      <td>1.541884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        M1           M2           M3          M4        M6        M7          M8        M9        M10          M11           M12         M13     M14   M15     M16     M17      M18        M19          M20      M21     M22         M23          M24           M25       M26  M27     M28        M29           M30      \\\n",
       "0  2.794286e+05         0.0  0.000000e+00  0.142857  0.142857  4.666667  2.113188e+06   0.0  4.557256e+07          0.0  1.257300e+08  1.571429   2.0  14.0  0.000000    3.0   0.142857   0.428571  0.000000e+00  0.0  0.000000  0.000000e+00          0.0  1.797325e+08   0.0  0.0  2.428571          0.0  2.468956e+06   \n",
       "1  2.543407e+07         0.0  0.000000e+00  3.285714  2.571429  1.172131  5.587033e+06   8.0  5.609760e+07   14191650.0  1.165804e+07  6.857143   3.0   0.0  0.285714  325.0   4.428571   1.571429  1.404086e+06  0.0  0.714286  5.044710e+06   62143844.0  5.500000e+04  30.0  0.0  0.092462    2639437.0  1.659751e+07   \n",
       "2  1.012459e+08   1134035.0  0.000000e+00  3.571429  1.285714  0.333333  9.885223e+06   0.0  2.795683e+06  127916014.0  1.331600e+07  1.571429   4.0   0.0  0.000000   17.0   7.285714   4.428571  0.000000e+00  0.0  0.000000  9.178193e+07          0.0  1.046667e+07   3.0  1.0  3.157895          0.0  1.376695e+07   \n",
       "3  7.225474e+06   1000000.0  0.000000e+00  4.857143  2.285714  1.002975  2.081377e+07   2.0  5.579175e+09  124444316.0  3.944277e+09  2.571429  23.0   0.0  2.571429   11.0   3.142857   2.428571  3.170632e+08  2.0  4.142857  1.708905e+07          0.0  3.000000e+07  16.0  1.0  1.366197  604619504.0  3.518295e+06   \n",
       "4  1.729485e+08  64920402.0  1.196457e+07  6.285714  8.428571  1.063923  2.310918e+08  11.0  4.460352e+08  279911624.0  1.528770e+09  5.714286  55.0   0.0  7.857143   26.0  12.571429  10.857143  9.966037e+07  2.0  5.000000  1.441646e+08  109633600.0  5.000000e+06  15.0  0.0  0.751572  961110758.0  5.075818e+06   \n",
       "\n",
       "      M31          M32         M33        M34       M35       M37     M38      M39           M40       M41   M42   M43   M44       M45           M46       M47      M48          M50          M51       M52     M53        M54          M55          M56           M57      M58      M59        M60         M61      \\\n",
       "0  1000000.0  2.205000e+14   0.500000  1.123875       0.0  0.000000   0.0 -500000000.0  1.033925e+08   2.0   7.0   7.0   6.0  2.073184e+06  1.285714e+05   1.0    8755428.0    956000.0  7.177382e+06   0.0  1.444444          0.0    8.000000  1.204300e+07  2.142857e+06  4.0         0.0  0.142857 -2.291686e+04   \n",
       "1  1007127.0  6.289461e+14  25.000000  9.972064       0.0  8.571429  29.0    4900000.0  2.996722e+07   7.0   5.0  14.0  11.0  3.498189e+07  1.885714e+06  80.0   24259987.0   1006378.0  2.245893e+06   1.0  0.037037    3905022.0    5.766667  4.580667e+07  5.520570e+07  0.0         0.0  2.285714  3.586779e+05   \n",
       "2   310766.0  9.046273e+13   1.000000  5.253068       0.0  0.428571   0.0  -15070000.0  4.543338e+06   2.0   1.0   2.0   2.0  3.310748e+07  0.000000e+00   0.0   34916014.0    927400.0  0.000000e+00   0.0  2.000000  332610063.0    1.200000  6.323682e+08  5.714770e+06  1.0  17716621.0  1.285714 -3.882796e+06   \n",
       "3        0.0  3.123793e+15   2.000000  0.999250       0.0  1.571429   2.0  -40000000.0  1.256615e+06  23.0  29.0  11.0   7.0  5.008919e+08  0.000000e+00   0.0   38193571.0         0.0  1.214482e+07   0.0  0.000000    1595295.0    3.366667  1.100105e+10  1.882292e+09  1.0   2687095.0  2.285714 -1.146829e+04   \n",
       "4   732060.0  5.306241e+16   6.166667  4.128299  250000.0  4.285714   3.0 -200000000.0  1.935521e+07  81.0  66.0  14.0   9.0  3.663644e+08  9.043607e+06   5.0  518476925.0  10383896.0  9.980783e+07  12.0  0.529412   35465171.0  227.809524  3.028163e+08  1.485740e+08  0.0   3494160.0  8.428571 -2.554114e+07   \n",
       "\n",
       "        M62           M63           M64       M65       M66          M67         M68      M69   M70   M71   M73     M74        M75        M76         M77           M78       M79       M80       M81     M82         M83        M84         M85           M86          M87      M88      M89         M90      M91   M92  \\\n",
       "0  1.336887e+17 -3.552769e+07  9.523810e+06   8.0  4.465011e+05   1501091.0    6434310.0  6.0   0.0   4.0   0.0   0.666667   0.142857   0.428571          0.0  1.000000e+06   1.0  5.893583e+05   2.0   0.000000   1471091.0  0.142857  1.489016e+05  6.354857e+08       178.0  125.0   0.000000     956682.0  0.0   2.0   \n",
       "1  7.221932e+13 -4.775762e+06  1.100000e+06  15.0 -1.681813e+06   2892661.0   13483963.0  0.0  77.0  33.0   5.0   9.857143  31.000000  33.142857   13511819.0  9.592868e+06  32.0  4.431868e+06  82.0  15.285714   4515097.0  9.000000  4.087866e+06  1.864471e+13  -1124458.5    7.0  33.571429   11067848.0  0.0  13.0   \n",
       "2  2.179054e+14  1.070333e+06  0.000000e+00   7.0  1.627143e+06         0.0  137016014.0  2.0   1.0   3.0   0.0   1.000000   0.714286   1.428571   19019676.0  3.503660e+05   1.0  0.000000e+00   1.0   0.000000  11529063.0  0.000000  1.985567e+07  5.167185e+08     39600.0   82.0   1.142857    2651570.0  0.0   2.0   \n",
       "3  2.669180e+17 -3.924670e+05  0.000000e+00  21.0 -6.914751e+05    968009.0   22267461.0  1.0   7.0   5.0   1.0   5.750000   2.428571   1.142857   13875412.0  2.266471e+09   3.0  1.577113e+09  16.0   3.714286    978209.0  7.000000  2.980420e+07  3.470651e+13         0.0   33.0   3.142857    8232632.0  1.0  12.0   \n",
       "4  2.150557e+16 -1.711082e+08  2.242759e+07  31.0 -5.809210e+06  40898024.0  346754863.0  0.0   9.0  60.0  17.0  12.000000   7.857143  13.714286  211333404.0  9.611108e+08  10.0  1.634677e+08  54.0   7.571429   1661268.0  6.428571  3.536520e+08  6.592732e+16 -22908000.0   15.0   9.285714  431783173.0  3.0  11.0   \n",
       "\n",
       "      M93        M94        M95        M96          M97          M98           M99        M100         M101          M102        M103       M104       M105     M106    M107     M108  M109      M110          M111          M112      M113    M114         M115          M116          M117        M118         M119      \\\n",
       "0   0.000000  1000000.0   0.759622   1.000000  1.000000e+06    5019704.0  2.144416e+05   0.142857  3.028764e+05  7.900245e+15   1.000000   0.000000   0.666667   0.0   1.333333   1.0   0.0  3.554369e+06  6.829441e+06  1.680639e+06   2.0   0.285714  4.286591e+05  6.663588e+06  3.550145e+06   0.142857  2.854730e+05   \n",
       "1  29.142857  1007127.0  26.811720  13.200000  6.809834e+06    1340300.0  6.411309e+06   6.714286  4.283151e+06  1.097304e+13  11.800000  40.428571  83.200000   5.0  78.142857  13.5  10.5  1.916434e+07  1.278329e+07  7.545009e+06   2.0  71.571429  4.681515e+06  3.647328e+06  1.056140e+07  46.285714  4.893895e+06   \n",
       "2   0.571429   310766.0   1.333433   0.333333  8.655591e+06   85406063.0  1.500651e+08   0.000000  3.843871e+05  2.430042e+14   1.000000   1.714286   0.666667   0.0   0.388889   0.0   0.5  1.601037e+07  1.172782e+06  2.664463e+06   2.0   0.285714  1.353150e+07  0.000000e+00  3.891014e+05   0.428571  2.136710e+07   \n",
       "3   1.285714        0.0   1.000043   3.166667  1.577993e+07    3235975.0  7.739459e+06   1.428571  1.496992e+07  3.369973e+14   3.600000   6.571429   1.500000   4.0  64.785714   1.5   2.0  4.946436e+07  6.554614e+07  4.788840e+08  19.0   3.142857  4.531227e+07  7.409697e+06  8.745908e+07   5.857143  2.904543e+07   \n",
       "4   6.000000   732060.0   1.125225   7.285714  3.819818e+08  194215920.0  4.993935e+07  10.571429  2.097739e+08  4.927524e+15   7.571429  10.428571   6.666667   6.0  14.888889  12.5   6.0  1.429480e+08  1.232215e+08  2.881400e+08  57.0   7.142857  4.998138e+08  1.571393e+08  1.734076e+08   8.571429  3.683402e+08   \n",
       "\n",
       "       M120        M121         M122         M123     M124    M125        M126        M127    M128   M129  M130    M131        M132        M133       M134         M135         M136         M137       M138       M139       M140        M141          M142        M143       M144         M145        M146     M147  \\\n",
       "0  1.888868e+07   0.900000  2.291686e+04         0.0   8.0  0.285714  1.018747e+06  2.526316    0.0   0.0   0.0   0.285714    1471091.0   0.333333   0.000000  1.471091e+06          0.0  35243117.5   0.000000   0.285714   0.285714          0.0  1.600193e+05   0.000000   0.428571  0.000000e+00   1.000000   2.0   \n",
       "1  5.758583e+06  39.720000  8.601064e+06   1024754.0   2.0  9.428571  4.983020e+06  0.069767  162.0  13.0  13.0  99.000000    6516128.0  51.857708  11.571429  3.786031e+06   16834478.0   3866209.0  64.142857  83.285714  30.428571    3236363.0  4.135060e+06  11.285714  57.142857  4.361425e+06  37.000000  14.0   \n",
       "2  7.838148e+07   1.170213  5.001665e+07   7155903.0  20.0  0.000000  2.688426e+06  4.265823    0.0   0.0   0.0   0.428571   19990563.0   0.300000   0.000000  4.339770e+06   85916014.0   1577886.0   1.142857   0.571429   0.428571          0.0  0.000000e+00   2.285714   0.285714  4.980363e+07   1.166667   2.0   \n",
       "3  8.145848e+06   3.936170  2.519615e+08   1916384.0   1.0  7.714286  1.646083e+08  1.295775    3.0   3.0   0.0   2.428571    3662970.0   7.719368   2.142857  3.662970e+06          0.0   1000000.0   2.000000   1.428571   1.571429    5312567.0  1.583906e+09   1.571429   1.714286  3.542267e+06   2.800000  12.0   \n",
       "4  1.176948e+08   9.931034  2.319186e+08  76438343.0   0.0  6.142857  2.689057e+08  0.937429   20.0   9.0  10.0  11.714286  101847045.0  55.531183   7.571429  1.018470e+08  569246307.0  73893623.0   8.285714   7.142857   8.000000  213957347.0  1.775612e+08   6.857143   5.857143  3.942189e+08   8.571429  12.0   \n",
       "\n",
       "     M148      M149      M150       M151      \n",
       "0  1.245265  0.237600  0.000000     0.999761  \n",
       "1  1.011859  0.896424  0.956242     2.577387  \n",
       "2  1.567944  0.567978  0.011124  1644.004255  \n",
       "3  1.001406  0.688247  1.000989     0.676825  \n",
       "4  0.525406  1.626870  1.076617     1.541884  "
      ]
     },
     "execution_count": 2028,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_descaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2029,
   "id": "80a60a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the variables in test data as per Info.value\n",
    "test_descaled = test_descaled[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2030,
   "id": "c0042cb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Standardizing the test data using the fit of train data(mean and standard deviation)\n",
    "X_test_scaled = scaler_new.transform(test_descaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2031,
   "id": "099593c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test sample\n",
    "\n",
    "# We are using xgboost,adaboost,gradientboost as our classifiers since there performed consistently in majority of the trials at different seeds.\n",
    "model1 = xgb  \n",
    "model2 = ab  \n",
    "model3 = gb\n",
    "\n",
    "# Define the voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[('m1', model1), ('m2', model2), ('m3', model3)], voting='soft')\n",
    "\n",
    "# Train the voting classifier on the training data (from experiment-4)\n",
    "voting_clf.fit(X_train_psmt, y_train_psmt)  \n",
    "\n",
    "# Evaluate the performance of the voting classifier on the test data\n",
    "pred = voting_clf.predict_proba(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2032,
   "id": "40ef2f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Savings the results to excel file\n",
    "df_final = pd.DataFrame({\"predicted_target_probability\":pred[:,1]})\n",
    "df_final.index.name = 'S.No'\n",
    "df_final.to_excel(\"Bharath_Bommeeshwar_07042023.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2162,
   "id": "a036d33e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>predicted_target_probability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.No</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.730971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.609938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.876146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.790776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.162852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.717402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.780642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.248025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.822823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.805398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.254578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.513128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.664879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.182686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.812340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.703545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.459421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.759500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.322337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.833948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.691960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.833229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.215860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.627112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.533575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.417609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.241782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.773843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.869367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.721856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.865857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.793520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.547013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.792711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.680122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.749979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.674445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.801742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.784240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.874788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.571972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.586599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.628472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.706235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.313099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.235567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.645310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.762757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.497082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.708787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.444457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.726513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.442694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.753525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.865593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.348327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.608870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.774673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.750189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.556311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.295282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.810437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.820699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.204458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.851970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.662806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.874790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.736739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.874547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.726919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.782318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.795684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.793930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.809061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.783483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.857543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.755395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.587438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.306157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.751874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.239417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.492918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.788916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.628394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.816380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.628975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.180656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.807905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      predicted_target_probability\n",
       "S.No                              \n",
       "0               0.730971          \n",
       "1               0.609938          \n",
       "2               0.876146          \n",
       "3               0.790776          \n",
       "4               0.162852          \n",
       "5               0.717402          \n",
       "6               0.780642          \n",
       "7               0.248025          \n",
       "8               0.822823          \n",
       "9               0.805398          \n",
       "10              0.254578          \n",
       "11              0.513128          \n",
       "12              0.664879          \n",
       "13              0.182686          \n",
       "14              0.812340          \n",
       "15              0.703545          \n",
       "16              0.459421          \n",
       "17              0.759500          \n",
       "18              0.322337          \n",
       "19              0.833948          \n",
       "20              0.691960          \n",
       "21              0.833229          \n",
       "22              0.215860          \n",
       "23              0.627112          \n",
       "24              0.533575          \n",
       "25              0.417609          \n",
       "26              0.241782          \n",
       "27              0.773843          \n",
       "28              0.869367          \n",
       "29              0.721856          \n",
       "30              0.865857          \n",
       "31              0.793520          \n",
       "32              0.547013          \n",
       "33              0.792711          \n",
       "34              0.680122          \n",
       "35              0.749979          \n",
       "36              0.674445          \n",
       "37              0.801742          \n",
       "38              0.784240          \n",
       "39              0.874788          \n",
       "40              0.571972          \n",
       "41              0.586599          \n",
       "42              0.628472          \n",
       "43              0.706235          \n",
       "44              0.313099          \n",
       "45              0.235567          \n",
       "46              0.645310          \n",
       "47              0.762757          \n",
       "48              0.497082          \n",
       "49              0.708787          \n",
       "50              0.444457          \n",
       "51              0.726513          \n",
       "52              0.442694          \n",
       "53              0.753525          \n",
       "54              0.865593          \n",
       "55              0.348327          \n",
       "56              0.608870          \n",
       "57              0.774673          \n",
       "58              0.750189          \n",
       "59              0.556311          \n",
       "60              0.295282          \n",
       "61              0.810437          \n",
       "62              0.820699          \n",
       "63              0.204458          \n",
       "64              0.851970          \n",
       "65              0.662806          \n",
       "66              0.874790          \n",
       "67              0.736739          \n",
       "68              0.874547          \n",
       "69              0.726919          \n",
       "70              0.782318          \n",
       "71              0.795684          \n",
       "72              0.793930          \n",
       "73              0.809061          \n",
       "74              0.783483          \n",
       "75              0.857543          \n",
       "76              0.755395          \n",
       "77              0.587438          \n",
       "78              0.306157          \n",
       "79              0.751874          \n",
       "80              0.239417          \n",
       "81              0.492918          \n",
       "82              0.788916          \n",
       "83              0.628394          \n",
       "84              0.816380          \n",
       "85              0.628975          \n",
       "86              0.180656          \n",
       "87              0.807905          "
      ]
     },
     "execution_count": 2162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464b45ec",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
